<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>PR #10: Decision persistence: cumulative log after merge acceptance</title>
<style>
  :root {
    --green: #22c55e; --green-bg: #f0fdf4; --green-border: #86efac;
    --yellow: #eab308; --yellow-bg: #fefce8;
    --orange: #f97316; --orange-bg: #fff7ed;
    --red: #ef4444; --red-bg: #fef2f2;
    --gray: #6b7280; --gray-bg: #f9fafb; --gray-border: #e5e7eb;
    --blue: #3b82f6; --blue-bg: #eff6ff;
    --purple: #8b5cf6; --purple-bg: #f5f3ff;
    --text: #1f2937; --text-secondary: #6b7280; --text-muted: #9ca3af;
    --border: #e5e7eb; --bg: #f3f4f6;
    --mono: 'SF Mono', 'Fira Code', 'Cascadia Code', monospace;
  }
  /* ‚îÄ‚îÄ Dark theme overrides ‚îÄ‚îÄ */
  [data-theme="dark"] {
    --text: #e5e7eb; --text-secondary: #9ca3af; --text-muted: #6b7280;
    --border: #374151; --bg: #111827;
    --gray-bg: #1f2937; --gray-border: #374151; --gray: #9ca3af;
    --green-bg: #064e3b; --green-border: #10b981;
    --yellow-bg: #713f12; --red-bg: #7f1d1d; --orange-bg: #7c2d12;
    --blue-bg: #1e3a5f; --purple-bg: #2e1065;
  }
  [data-theme="dark"] .header,
  [data-theme="dark"] .section,
  [data-theme="dark"] .gate,
  [data-theme="dark"] .tab-panel,
  [data-theme="dark"] .tab-bar { background: #1f2937; }
  [data-theme="dark"] .tab-btn { color: #9ca3af; }
  [data-theme="dark"] .tab-btn:hover { background: #374151; }
  [data-theme="dark"] .tab-btn.active { color: #60a5fa; background: #1f2937; }
  [data-theme="dark"] th { background: #1f2937; color: #9ca3af; }
  [data-theme="dark"] tr:nth-child(even) td { background: rgba(255,255,255,0.02); }
  [data-theme="dark"] tr.expandable:hover,
  [data-theme="dark"] .section-header:hover,
  [data-theme="dark"] .decision-header:hover,
  [data-theme="dark"] .pm-header:hover,
  [data-theme="dark"] .scenario-card:hover { background: #374151; }
  [data-theme="dark"] .history-event { background: #1f2937; border-color: #374151; }
  [data-theme="dark"] tr.detail-row td,
  [data-theme="dark"] .adv-detail-row td { background: #1a2332; }
  [data-theme="dark"] .arch-legend { background: #1f2937; }
  [data-theme="dark"] .conv-card { border-color: #374151; }
  [data-theme="dark"] .decision-card { border-color: #374151; }
  [data-theme="dark"] .pm-item { border-color: #374151; }
  [data-theme="dark"] .scenario-card { border-color: #374151; }
  [data-theme="dark"] .arch-floating { background: rgba(31,41,55,0.95); }
  [data-theme="dark"] .code-block { background: #0f172a; }
  [data-theme="dark"] .gate-popover { background: #1f2937; border-color: #374151; }
  [data-theme="dark"] .badge.pass { background: #064e3b; color: #34d399; }
  [data-theme="dark"] .badge.fail { background: #7f1d1d; color: #fca5a5; }
  [data-theme="dark"] .health-tag.normal { background: #064e3b; color: #34d399; }
  [data-theme="dark"] .health-tag.acceptable { background: #713f12; color: #fde047; }
  [data-theme="dark"] .health-tag.watch { background: #7c2d12; color: #fdba74; }
  [data-theme="dark"] .health-tag.refactor { background: #7f1d1d; color: #fca5a5; }
  [data-theme="dark"] .grade.a { background: #064e3b; color: #34d399; }
  [data-theme="dark"] .grade.b { background: #713f12; color: #fde047; }
  [data-theme="dark"] .grade.c { background: #7c2d12; color: #fdba74; }
  [data-theme="dark"] .grade.f { background: #7f1d1d; color: #fca5a5; }
  [data-theme="dark"] .grade.na { background: #374151; color: #9ca3af; }
  [data-theme="dark"] .priority.low { background: #1e3a5f; color: #93c5fd; }
  [data-theme="dark"] .priority.medium { background: #713f12; color: #fde047; }
  [data-theme="dark"] .priority.cosmetic { background: #374151; color: #9ca3af; }
  [data-theme="dark"] .status-badge.pass { background: #064e3b; color: #34d399; }
  [data-theme="dark"] .status-badge.info { background: #1e3a5f; color: #93c5fd; }
  [data-theme="dark"] .status-badge.warn { background: #713f12; color: #fde047; }
  [data-theme="dark"] .status-badge.fail { background: #7f1d1d; color: #fca5a5; }
  [data-theme="dark"] .zone-tag { background: #1e3a5f; color: #93c5fd; }
  [data-theme="dark"] .zone-tag.factory { background: #1e3a5f; color: #93c5fd; }
  [data-theme="dark"] .zone-tag.product { background: #064e3b; color: #6ee7b7; }
  [data-theme="dark"] .zone-tag.infra { background: #2e1065; color: #c4b5fd; }
  [data-theme="dark"] .scenario-box.failure { background: #3b1111; border-left-color: #ef4444; }
  [data-theme="dark"] .scenario-box.success { background: #052e16; border-left-color: #22c55e; }
  [data-theme="dark"] .ci-check-item:hover { background: #374151; }
  [data-theme="dark"] .conv-card:hover { box-shadow: 0 2px 8px rgba(0,0,0,0.3); }
  [data-theme="dark"] .history-event:hover { box-shadow: 0 2px 8px rgba(0,0,0,0.25); }
  [data-theme="dark"] .file-path-link { border-bottom-color: #6b7280; }
  [data-theme="dark"] .file-path-link:hover { border-bottom-color: #60a5fa; color: #60a5fa; }
  [data-theme="dark"] .stat { background: #1f2937; }
  [data-theme="dark"] .stat.green { background: #064e3b; color: #34d399; }
  [data-theme="dark"] .stat.red { background: #7f1d1d; color: #fca5a5; }
  [data-theme="dark"] #arch-diagram { background: #1a2332; border-color: #374151; }
  [data-theme="dark"] .history-timeline::before { background: #374151; }
  [data-theme="dark"] .history-legend { background: #1f2937; }
  [data-theme="dark"] .conv-card-detail { border-top-color: #374151; }

  /* ‚îÄ‚îÄ Light theme diff modal overrides ‚îÄ‚îÄ */
  :root:not([data-theme="dark"]) .file-modal { background: #ffffff; }
  :root:not([data-theme="dark"]) .file-modal-header { background: #f5f5f5; border-bottom-color: #e0e0e0; }
  :root:not([data-theme="dark"]) .file-modal-header h3 { color: #333333; }
  :root:not([data-theme="dark"]) .file-modal-toolbar { background: #fafafa; border-bottom-color: #e0e0e0; }
  :root:not([data-theme="dark"]) .file-modal-tab { color: #666666; }
  :root:not([data-theme="dark"]) .file-modal-tab:hover { color: #333333; background: #f0f0f0; }
  :root:not([data-theme="dark"]) .file-modal-tab.active { color: #1d4ed8; background: #ffffff; border-bottom-color: var(--blue); }
  :root:not([data-theme="dark"]) .file-modal-body { background: #ffffff; }
  :root:not([data-theme="dark"]) .file-modal-close { color: #999999; }
  :root:not([data-theme="dark"]) .file-modal-close:hover { background: #e0e0e0; color: #333333; }
  :root:not([data-theme="dark"]) .file-modal-github { background: #f0f0f0; border-color: #e0e0e0; color: #333333; }
  :root:not([data-theme="dark"]) .file-modal-github:hover { background: #e0e0e0; color: #111111; }
  :root:not([data-theme="dark"]) .fm-stats .fm-add { color: #166534; }
  :root:not([data-theme="dark"]) .fm-stats .fm-del { color: #991b1b; }
  :root:not([data-theme="dark"]) .diff-unified .diff-add { background: rgba(34,197,94,0.12); color: #166534; }
  :root:not([data-theme="dark"]) .diff-unified .diff-del { background: rgba(239,68,68,0.12); color: #991b1b; }
  :root:not([data-theme="dark"]) .diff-unified .diff-ctx { color: #333333; }
  :root:not([data-theme="dark"]) .diff-unified .diff-hunk { background: rgba(59,130,246,0.08); color: #2563eb; }
  :root:not([data-theme="dark"]) .diff-unified .diff-ln { color: #999999; border-right-color: #e0e0e0; }
  :root:not([data-theme="dark"]) .diff-split .diff-add { background: rgba(34,197,94,0.12); color: #166534; }
  :root:not([data-theme="dark"]) .diff-split .diff-del { background: rgba(239,68,68,0.12); color: #991b1b; }
  :root:not([data-theme="dark"]) .diff-split .diff-ctx { color: #333333; }
  :root:not([data-theme="dark"]) .diff-split .diff-empty { background: #f9f9f9; }
  :root:not([data-theme="dark"]) .diff-split .diff-ln { color: #999999; }
  :root:not([data-theme="dark"]) .diff-split .diff-sep { background: #e0e0e0; }
  :root:not([data-theme="dark"]) .diff-split .diff-hunk td { background: rgba(59,130,246,0.06); color: #2563eb; }
  :root:not([data-theme="dark"]) .diff-raw td { color: #333333; }
  :root:not([data-theme="dark"]) .diff-raw .diff-ln { color: #999999; border-right-color: #e0e0e0; }
  :root:not([data-theme="dark"]) .diff-new-file-banner { background: rgba(34,197,94,0.08); color: #166534; border-bottom-color: #e0e0e0; }
  :root:not([data-theme="dark"]) .diff-deleted-file-banner { background: rgba(239,68,68,0.08); color: #991b1b; border-bottom-color: #e0e0e0; }
  :root:not([data-theme="dark"]) .diff-loading { color: #999999; }
  :root:not([data-theme="dark"]) .diff-error { color: #991b1b; }

  /* ‚îÄ‚îÄ Theme toggle ‚îÄ‚îÄ */
  .theme-toggle { display: inline-flex; border: 1px solid var(--border); border-radius: 8px; overflow: hidden; margin-left: 12px; vertical-align: middle; }
  .theme-toggle button { border: none; background: transparent; padding: 4px 10px; font-size: 14px; cursor: pointer; color: var(--text-secondary); transition: background 0.15s, color 0.15s; line-height: 1; }
  .theme-toggle button:hover { background: var(--gray-bg); }
  .theme-toggle button.active { background: var(--blue); color: white; }
  .theme-toggle button:not(:last-child) { border-right: 1px solid var(--border); }

  * { box-sizing: border-box; margin: 0; padding: 0; }
  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; color: var(--text); background: var(--bg); line-height: 1.5; font-size: 14px; }
  .container { max-width: 1100px; margin: 0 auto; padding: 24px 16px; }

  /* ‚îÄ‚îÄ Tabs ‚îÄ‚îÄ */
  .tab-bar { display: flex; gap: 0; background: white; border-radius: 12px 12px 0 0; border: 1px solid var(--border); border-bottom: none; overflow: hidden; }
  .tab-btn { padding: 12px 24px; font-size: 13px; font-weight: 600; cursor: pointer; border: none; background: transparent; color: var(--text-secondary); border-bottom: 2px solid transparent; transition: all 0.15s; }
  .tab-btn:hover { background: var(--gray-bg); }
  .tab-btn.active { color: var(--blue); border-bottom-color: var(--blue); background: white; }
  .tab-content { display: none; }
  .tab-content.active { display: block; }
  .tab-panel { background: white; border: 1px solid var(--border); border-top: none; border-radius: 0 0 12px 12px; margin-bottom: 16px; }

  /* ‚îÄ‚îÄ Header ‚îÄ‚îÄ */
  .header { background: white; border-radius: 12px; padding: 24px; margin-bottom: 16px; border: 1px solid var(--border); }
  .header h1 { font-size: 20px; font-weight: 700; margin-bottom: 4px; }
  .header .meta { font-size: 13px; color: var(--text-secondary); font-family: var(--mono); }
  .header .meta a { color: var(--blue); text-decoration: none; }
  .stats { display: flex; gap: 12px; margin-top: 12px; flex-wrap: wrap; }
  .stat { background: var(--gray-bg); border-radius: 8px; padding: 6px 14px; font-size: 13px; font-weight: 500; }
  .stat .num { font-weight: 700; font-size: 15px; }
  .stat.green { background: var(--green-bg); color: #166534; }
  .stat.red { background: #fef2f2; color: #991b1b; }

  /* ‚îÄ‚îÄ Gate (removed ‚Äî readiness info lives in status badges) ‚îÄ‚îÄ */
  .gate .check-row { display: flex; justify-content: space-between; align-items: center; padding: 7px 0; border-bottom: 1px solid var(--border); font-size: 13px; }
  .gate .check-row:last-child { border-bottom: none; }
  .badge { display: inline-flex; align-items: center; gap: 4px; padding: 2px 10px; border-radius: 12px; font-size: 12px; font-weight: 600; }
  .badge.pass { background: var(--green-bg); color: #166534; }
  .badge.fail { background: var(--red-bg); color: #991b1b; }

  /* ‚îÄ‚îÄ Sections ‚îÄ‚îÄ */
  .section { background: white; border-radius: 12px; margin-bottom: 16px; border: 1px solid var(--border); overflow: hidden; }
  .section-header { padding: 14px 24px; cursor: pointer; display: flex; justify-content: space-between; align-items: center; user-select: none; transition: background 0.15s; }
  .section-header:hover { background: var(--gray-bg); }
  .section-header h2 { font-size: 14px; font-weight: 700; }
  .section-header .chevron { font-size: 16px; color: var(--text-secondary); transition: transform 0.2s; }
  .section.collapsed .section-body { display: none; }
  .section.collapsed .chevron { transform: rotate(-90deg); }
  .section-body { padding: 0 24px 20px; font-size: 13px; }

  /* ‚îÄ‚îÄ Architecture Diagram ‚îÄ‚îÄ */
  .arch-controls { display: flex; gap: 8px; margin-bottom: 12px; align-items: center; }
  .arch-toggle { padding: 5px 14px; border-radius: 6px; font-size: 12px; font-weight: 600; cursor: pointer; border: 1px solid var(--border); background: white; color: var(--text-secondary); }
  .arch-toggle.active { background: var(--blue); color: white; border-color: var(--blue); }
  .arch-hint { font-size: 11px; color: var(--text-muted); margin-left: 8px; }
  .zone-box { cursor: pointer; transition: opacity 0.3s, filter 0.3s; }
  .zone-box:hover { filter: brightness(0.95); }
  .zone-box.dimmed { opacity: 0.12; }
  .zone-box.highlighted { stroke-width: 3; filter: brightness(0.92); }
  .zone-label { font-size: 11px; font-weight: 600; pointer-events: none; }
  .zone-sublabel { font-size: 9px; fill: #6b7280; pointer-events: none; }
  .zone-file-count { font-size: 10px; font-weight: 700; fill: white; pointer-events: none; }
  .zone-count-bg { pointer-events: none; }
  .arch-row-label { font-size: 10px; font-weight: 700; fill: #9ca3af; text-transform: uppercase; letter-spacing: 1px; }

  /* ‚îÄ‚îÄ Tables ‚îÄ‚îÄ */
  table { width: 100%; border-collapse: collapse; font-size: 13px; }
  th { text-align: left; padding: 8px 12px; background: var(--gray-bg); font-weight: 600; font-size: 11px; text-transform: uppercase; letter-spacing: 0.3px; color: var(--text-secondary); border-bottom: 2px solid var(--border); }
  td { padding: 8px 12px; border-bottom: 1px solid var(--border); vertical-align: top; }
  tr:last-child td { border-bottom: none; }
  tr.expandable { cursor: pointer; }
  tr.expandable:hover { background: var(--gray-bg); }
  tr.detail-row { display: none; }
  tr.detail-row.open { display: table-row; }
  tr.detail-row td { background: #fafbfc; padding: 12px 20px; }

  /* ‚îÄ‚îÄ Grade pills ‚îÄ‚îÄ */
  .grade { display: inline-block; width: 28px; height: 28px; line-height: 28px; text-align: center; border-radius: 6px; font-weight: 700; font-size: 12px; }
  .grade.a { background: var(--green-bg); color: #166534; }
  .grade.b { background: var(--yellow-bg); color: #854d0e; }
  .grade.c { background: var(--orange-bg); color: #9a3412; }
  .grade.f { background: var(--red-bg); color: #991b1b; }
  .grade.na { background: var(--gray-bg); color: var(--gray); }

  /* ‚îÄ‚îÄ Timing ‚îÄ‚îÄ */
  .time-label { font-family: var(--mono); font-size: 15px; font-weight: 700; }
  .time-label.normal { color: #166534; }
  .time-label.acceptable { color: #854d0e; }
  .time-label.watch { color: #f97316; }
  .time-label.refactor { color: #ef4444; }
  [data-theme="dark"] .time-label.normal { color: #34d399; }
  [data-theme="dark"] .time-label.acceptable { color: #fde047; }
  [data-theme="dark"] .time-label.watch { color: #fdba74; }
  [data-theme="dark"] .time-label.refactor { color: #fca5a5; }
  .time-health-sub { font-size: 10px; font-weight: 500; color: var(--text-muted); margin-top: 1px; }
  .health-tag { font-size: 10px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.3px; padding: 2px 8px; border-radius: 4px; }
  .health-tag.normal { background: var(--green-bg); color: #166534; }
  .health-tag.acceptable { background: var(--yellow-bg); color: #854d0e; }
  .health-tag.watch { background: var(--orange-bg); color: #9a3412; }
  .health-tag.refactor { background: var(--red-bg); color: #991b1b; }

  /* ‚îÄ‚îÄ Decision cards ‚îÄ‚îÄ */
  .decision-card { border: 1px solid var(--border); border-radius: 8px; margin-bottom: 10px; overflow: hidden; }
  .decision-header { padding: 12px 16px; cursor: pointer; display: flex; gap: 12px; align-items: flex-start; transition: background 0.15s; }
  .decision-header:hover { background: var(--gray-bg); }
  .decision-num { font-weight: 700; color: var(--blue); font-size: 14px; min-width: 24px; }
  .decision-title { font-weight: 600; font-size: 13px; }
  .decision-rationale { font-size: 12px; color: var(--text-secondary); margin-top: 2px; }
  .decision-body { display: none; padding: 0 16px 16px; border-top: 1px solid var(--border); }
  .decision-card.open .decision-body { display: block; }
  .decision-zones { display: flex; gap: 6px; flex-wrap: wrap; margin: 10px 0; }
  .zone-tag { font-size: 11px; padding: 2px 8px; border-radius: 4px; font-weight: 600; background: var(--blue-bg); color: #1d4ed8; }
  .decision-files { margin-top: 10px; }
  .decision-files table { font-size: 12px; }
  .decision-files td { padding: 4px 8px; }

  /* ‚îÄ‚îÄ Convergence ‚îÄ‚îÄ */
  .convergence-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 12px; }
  .conv-card { border: 1px solid var(--border); border-radius: 8px; padding: 14px; cursor: pointer; transition: box-shadow 0.2s; }
  .conv-card:hover { box-shadow: 0 2px 8px rgba(0,0,0,0.08); }
  .conv-card h4 { font-size: 12px; text-transform: uppercase; letter-spacing: 0.3px; color: var(--text-secondary); margin-bottom: 8px; }
  .conv-status { font-size: 20px; font-weight: 700; }
  .conv-status.passing { color: #166534; }
  .conv-status.warning { color: #854d0e; }
  .conv-status.failing { color: #991b1b; }
  .conv-detail { font-size: 12px; color: var(--text-secondary); margin-top: 4px; }
  .conv-card-detail { display: none; margin-top: 8px; padding-top: 8px; border-top: 1px solid var(--border); font-size: 12px; color: var(--text-secondary); }
  .conv-card.open .conv-card-detail { display: block; }
  .conv-card-detail ul { margin: 4px 0 0 16px; list-style: disc; }
  .conv-card-detail li { margin-bottom: 2px; }

  /* ‚îÄ‚îÄ Post-merge ‚îÄ‚îÄ */
  .pm-item { border: 1px solid var(--border); border-radius: 8px; margin-bottom: 10px; overflow: hidden; }
  .pm-header { padding: 10px 16px; cursor: pointer; display: flex; gap: 10px; align-items: center; transition: background 0.15s; }
  .pm-header:hover { background: var(--gray-bg); }
  .pm-body { display: none; padding: 0 16px 16px; border-top: 1px solid var(--border); }
  .pm-item.open .pm-body { display: block; }
  .priority { font-size: 10px; font-weight: 700; padding: 2px 8px; border-radius: 4px; white-space: nowrap; }
  .priority.low { background: var(--blue-bg); color: #1d4ed8; }
  .priority.medium { background: var(--yellow-bg); color: #854d0e; }
  .priority.cosmetic { background: var(--gray-bg); color: var(--gray); }
  .code-block { background: #1e293b; color: #e2e8f0; padding: 12px 16px; border-radius: 6px; font-family: var(--mono); font-size: 12px; line-height: 1.6; overflow-x: auto; margin: 8px 0; white-space: pre; }
  .scenario-box { padding: 10px 14px; border-radius: 6px; margin: 6px 0; font-size: 12px; }
  .scenario-box.failure { background: var(--red-bg); border-left: 3px solid var(--red); }
  .scenario-box.success { background: var(--green-bg); border-left: 3px solid var(--green); }
  .scenario-label { font-weight: 700; font-size: 11px; text-transform: uppercase; letter-spacing: 0.3px; margin-bottom: 4px; }

  /* ‚îÄ‚îÄ Spec & Scenarios ‚îÄ‚îÄ */
  .spec-list { list-style: none; padding: 0; }
  .spec-list li { padding: 6px 0; border-bottom: 1px solid var(--border); font-size: 13px; display: flex; gap: 8px; align-items: center; }
  .spec-list li:last-child { border-bottom: none; }
  .scenario-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; margin-top: 8px; }
  .scenario-card { border: 1px solid var(--border); border-radius: 6px; padding: 8px 12px; font-size: 12px; cursor: pointer; transition: background 0.15s; }
  .scenario-card:hover { background: var(--gray-bg); }
  .scenario-card .name { font-weight: 600; }
  .scenario-card .status { font-size: 11px; margin-top: 2px; }
  .scenario-card-detail { display: none; margin-top: 6px; padding-top: 6px; border-top: 1px solid var(--border); font-size: 11px; color: var(--text-secondary); }
  .scenario-card.open .scenario-card-detail { display: block; }
  .scenario-card-detail dt { font-weight: 600; color: var(--text); margin-top: 4px; }
  .scenario-card-detail dd { margin-left: 0; margin-bottom: 2px; }
  .scenario-category { display: inline-block; padding: 1px 7px; border-radius: 4px; font-size: 10px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.3px; margin-left: 6px; }
  .scenario-category.cat-environment { background: #dcfce7; color: #166534; }
  .scenario-category.cat-training { background: #dbeafe; color: #1d4ed8; }
  .scenario-category.cat-pipeline { background: #f3e8ff; color: #6d28d9; }
  .scenario-category.cat-integration { background: #fff7ed; color: #9a3412; }
  [data-theme="dark"] .scenario-category.cat-environment { background: #064e3b; color: #6ee7b7; }
  [data-theme="dark"] .scenario-category.cat-training { background: #1e3a5f; color: #93c5fd; }
  [data-theme="dark"] .scenario-category.cat-pipeline { background: #2e1065; color: #c4b5fd; }
  [data-theme="dark"] .scenario-category.cat-integration { background: #7c2d12; color: #fdba74; }
  .scenario-legend { display: flex; flex-wrap: wrap; gap: 12px; margin-bottom: 10px; font-size: 11px; color: var(--text-secondary); }
  .scenario-card.zone-dimmed { opacity: 0.35; }
  .scenario-card.zone-glow { box-shadow: 0 0 0 2px var(--blue); }

  /* ‚îÄ‚îÄ Factory History ‚îÄ‚îÄ */
  .history-timeline { position: relative; padding-left: 24px; }
  .history-timeline::before { content: ''; position: absolute; left: 8px; top: 0; bottom: 0; width: 2px; background: var(--border); }
  .history-event { position: relative; margin-bottom: 16px; padding: 12px 16px; background: white; border: 1px solid var(--border); border-radius: 8px; cursor: pointer; transition: box-shadow 0.2s; }
  .history-event:hover { box-shadow: 0 2px 8px rgba(0,0,0,0.06); }
  .history-event::before { content: ''; position: absolute; left: -20px; top: 16px; width: 10px; height: 10px; border-radius: 50%; background: var(--blue); border: 2px solid white; }
  .history-event.intervention::before { background: var(--orange); }
  .history-event .event-title { font-weight: 600; font-size: 13px; }
  .history-event .event-detail { font-size: 12px; color: var(--text-secondary); margin-top: 4px; }
  .history-event .event-meta { font-size: 11px; color: var(--text-muted); margin-top: 4px; font-family: var(--mono); }
  .history-event-detail { display: none; margin-top: 8px; padding-top: 8px; border-top: 1px solid var(--border); font-size: 12px; color: var(--text-secondary); }
  .history-event.open .history-event-detail { display: block; }
  .event-agent { display: inline-block; padding: 1px 6px; border-radius: 3px; font-size: 10px; font-weight: 600; background: var(--blue-bg); color: #1d4ed8; margin-left: 4px; }
  .event-agent.human { background: var(--orange-bg); color: #9a3412; }
  .history-legend { display: flex; flex-wrap: wrap; gap: 16px; margin-bottom: 16px; padding: 10px 14px; background: var(--gray-bg); border-radius: 6px; font-size: 11px; color: var(--text-secondary); }
  .history-legend-item { display: flex; align-items: center; gap: 6px; }
  .history-legend-dot { width: 10px; height: 10px; border-radius: 50%; }

  /* ‚îÄ‚îÄ Footer ‚îÄ‚îÄ */
  .footer { text-align: center; padding: 16px; font-size: 11px; color: var(--text-muted); }

  /* ‚îÄ‚îÄ Zone tag color variants ‚îÄ‚îÄ */
  .zone-tag.factory { background: var(--blue-bg); color: #1d4ed8; }
  .zone-tag.product { background: #dcfce7; color: #166534; }
  .zone-tag.infra { background: var(--purple-bg); color: #6d28d9; }

  /* ‚îÄ‚îÄ Architecture legend ‚îÄ‚îÄ */
  .arch-legend { display: flex; flex-wrap: wrap; gap: 16px; margin-top: 10px; padding: 10px 14px; background: var(--gray-bg); border-radius: 6px; font-size: 11px; color: var(--text-secondary); }
  .arch-legend-item { display: flex; align-items: center; gap: 6px; }
  .arch-legend-swatch { width: 14px; height: 14px; border-radius: 3px; border: 1px solid rgba(0,0,0,0.1); }
  .arch-legend-circle { width: 14px; height: 14px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 8px; font-weight: 700; color: white; }

  /* ‚îÄ‚îÄ What Changed zone detail blocks ‚îÄ‚îÄ */
  .wc-zone-detail { display: none; padding: 8px 0; }
  .wc-zone-detail.active { display: block; }
  .wc-zone-detail h4 { font-size: 13px; font-weight: 700; margin-bottom: 6px; }

  /* ‚îÄ‚îÄ Adversarial review enhancements ‚îÄ‚îÄ */
  .adv-scroll { max-height: 500px; overflow-y: auto; }
  .adv-row { cursor: pointer; transition: max-height 0.3s ease, opacity 0.3s ease; }
  .adv-row:hover { background: var(--gray-bg); }
  .adv-row.collapsed-row { max-height: 24px; opacity: 0.5; overflow: hidden; }
  .adv-no-match { display: none; padding: 16px; text-align: center; color: var(--text-muted); font-size: 13px; font-style: italic; }
  .adv-no-match.visible { display: block; }
  .adv-detail-row { display: none; }
  .adv-detail-row.open { display: table-row; }
  .adv-detail-row td { background: #fafbfc; padding: 12px 20px; font-size: 12px; border-bottom: 1px solid var(--border); }

  /* ‚îÄ‚îÄ CI sub-check drill-down ‚îÄ‚îÄ */
  .ci-check-item { padding: 6px 0; border-bottom: 1px solid var(--border); cursor: pointer; transition: background 0.15s; }
  .ci-check-item:last-child { border-bottom: none; }
  .ci-check-item:hover { background: #f0f4f8; }
  .ci-check-summary { font-size: 12px; display: flex; align-items: center; gap: 6px; }
  .ci-check-summary .chevron-sm { font-size: 10px; color: var(--text-muted); transition: transform 0.2s; display: inline-block; }
  .ci-check-item.open .chevron-sm { transform: rotate(90deg); }
  .ci-check-detail { display: none; padding: 6px 0 4px 20px; font-size: 11px; color: var(--text-secondary); }
  .ci-check-item.open .ci-check-detail { display: block; }

  /* ‚îÄ‚îÄ Floating architecture diagram ‚îÄ‚îÄ */
  .arch-floating { position: fixed; top: 16px; right: 16px; width: 40%; max-width: 480px; z-index: 100; background: rgba(255,255,255,0.95); border-radius: 10px; border: 1px solid var(--border); box-shadow: 0 8px 32px rgba(0,0,0,0.12); padding: 10px; transition: opacity 0.3s ease, transform 0.3s ease; opacity: 0; transform: translateX(40px); pointer-events: none; }
  .arch-floating.visible { opacity: 1; transform: translateX(0); pointer-events: auto; }
  .arch-floating svg { width: 100%; height: auto; }
  .arch-floating-close { position: absolute; top: 6px; right: 10px; background: none; border: none; font-size: 16px; cursor: pointer; color: var(--text-muted); z-index: 101; padding: 2px 6px; border-radius: 4px; }
  .arch-floating-close:hover { background: var(--gray-bg); color: var(--text); }

  /* ‚îÄ‚îÄ File path modal ‚îÄ‚îÄ */
  .file-modal-overlay { display: none; position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: rgba(0,0,0,0.45); z-index: 200; justify-content: center; align-items: center; }
  .file-modal-overlay.visible { display: flex; }
  .file-modal { background: #1e1e1e; border-radius: 10px; width: 95vw; max-width: 1400px; height: 90vh; overflow: hidden; box-shadow: 0 20px 60px rgba(0,0,0,0.4); display: flex; flex-direction: column; }
  .file-modal-header { display: flex; justify-content: space-between; align-items: center; padding: 10px 16px; background: #2d2d2d; border-bottom: 1px solid #404040; flex-shrink: 0; }
  .file-modal-header h3 { font-size: 13px; font-family: var(--mono); font-weight: 500; color: #cccccc; }
  .file-modal-header .fm-stats { font-size: 11px; font-family: var(--mono); margin-left: 12px; }
  .file-modal-header .fm-stats .fm-add { color: #3fb950; }
  .file-modal-header .fm-stats .fm-del { color: #f85149; }
  .file-modal-close { background: none; border: none; font-size: 18px; cursor: pointer; color: #808080; padding: 2px 8px; border-radius: 4px; }
  .file-modal-close:hover { background: #404040; color: #cccccc; }
  .file-modal-toolbar { display: flex; justify-content: space-between; align-items: center; padding: 6px 16px; background: #252526; border-bottom: 1px solid #404040; flex-shrink: 0; }
  .file-modal-tabs { display: flex; gap: 0; }
  .file-modal-tab { padding: 6px 14px; font-size: 11px; font-weight: 600; cursor: pointer; border: none; background: none; color: #808080; border-bottom: 2px solid transparent; border-radius: 4px 4px 0 0; }
  .file-modal-tab:hover { color: #cccccc; background: #2d2d2d; }
  .file-modal-tab.active { color: #ffffff; border-bottom-color: var(--blue); background: #1e1e1e; }
  .file-modal-github { display: inline-flex; align-items: center; gap: 4px; padding: 4px 10px; background: #2d2d2d; border: 1px solid #404040; border-radius: 4px; color: #cccccc; text-decoration: none; font-size: 11px; font-weight: 500; }
  .file-modal-github:hover { background: #404040; color: white; }
  .file-modal-body { flex: 1; overflow: auto; background: #1e1e1e; }

  /* ‚îÄ‚îÄ Diff rendering ‚îÄ‚îÄ */
  .diff-view { font-family: var(--mono); font-size: 12px; line-height: 1.55; }
  .diff-unified { width: 100%; border-collapse: collapse; }
  .diff-unified td { padding: 0 12px; white-space: pre-wrap; word-break: break-all; vertical-align: top; border: none; }
  .diff-new-file-banner { padding: 8px 16px; background: rgba(63,185,80,0.1); color: #3fb950; font-size: 12px; font-weight: 500; border-bottom: 1px solid #333333; }
  .diff-deleted-file-banner { padding: 8px 16px; background: rgba(248,81,73,0.1); color: #f85149; font-size: 12px; font-weight: 500; border-bottom: 1px solid #333333; }
  .diff-unified .diff-ln { width: 50px; min-width: 50px; text-align: right; color: #636363; user-select: none; padding-right: 8px; font-size: 11px; border-right: 1px solid #333333; }
  .diff-unified .diff-add { background: rgba(63,185,80,0.15); color: #3fb950; }
  .diff-unified .diff-del { background: rgba(248,81,73,0.15); color: #f85149; }
  .diff-unified .diff-ctx { color: #cccccc; }
  .diff-unified .diff-hunk { background: rgba(56,139,253,0.12); color: #58a6ff; padding: 6px 12px; font-style: italic; }
  .diff-split { width: 100%; border-collapse: collapse; }
  .diff-split td { padding: 0 6px; white-space: pre; vertical-align: top; border: none; font-family: var(--mono); font-size: 12px; line-height: 1.55; }
  .diff-split-wrapper { overflow-x: auto; }
  .diff-split .diff-ln { width: 40px; min-width: 40px; text-align: right; color: #636363; user-select: none; padding-right: 6px; font-size: 11px; }
  .diff-split .diff-sep { width: 2px; min-width: 2px; background: #2d2d2d; padding: 0; }
  .diff-split .diff-code-left, .diff-split .diff-code-right { min-width: 0; max-width: 50vw; white-space: pre; overflow-x: auto; }
  .diff-split .diff-add { background: rgba(63,185,80,0.15); color: #3fb950; }
  .diff-split .diff-del { background: rgba(248,81,73,0.15); color: #f85149; }
  .diff-split .diff-ctx { color: #cccccc; }
  .diff-split .diff-empty { background: #161616; }
  .diff-split .diff-hunk td { background: rgba(56,139,253,0.08); color: #58a6ff; font-style: italic; padding: 4px 8px; }
  .diff-raw { color: #cccccc; }
  .diff-raw table { width: 100%; border-collapse: collapse; }
  .diff-raw td { padding: 0 12px; white-space: pre-wrap; word-break: break-all; vertical-align: top; border: none; font-family: var(--mono); font-size: 12px; line-height: 1.55; }
  .diff-raw .diff-ln { width: 50px; min-width: 50px; text-align: right; color: #636363; user-select: none; padding-right: 8px; font-size: 11px; border-right: 1px solid #333333; }
  .diff-loading { color: #808080; text-align: center; padding: 60px 20px; font-size: 13px; }
  .diff-error { color: #f85149; text-align: center; padding: 40px 20px; font-size: 13px; }
  .file-path-link { color: inherit; text-decoration: none; border-bottom: 1px dashed var(--text-muted); cursor: pointer; transition: border-color 0.15s; }
  .file-path-link:hover { border-bottom-color: var(--blue); color: var(--blue); }

  /* ‚îÄ‚îÄ CI Chevron rotation ‚îÄ‚îÄ */
  .ci-chevron { display: inline-block; transition: transform 0.2s; }
  tr.expandable.ci-open .ci-chevron { transform: rotate(180deg); }

  /* ‚îÄ‚îÄ Status badges ‚îÄ‚îÄ */
  .status-row { display: flex; gap: 8px; margin-top: 10px; flex-wrap: wrap; }
  .status-badge { display: inline-flex; align-items: center; gap: 4px; padding: 4px 12px; border-radius: 16px; font-size: 12px; font-weight: 600; }
  .status-badge.pass { background: var(--green-bg); color: #166534; }
  .status-badge.info { background: var(--blue-bg); color: #1d4ed8; }
  .status-badge.warn { background: var(--yellow-bg); color: #854d0e; }
  .status-badge.fail { background: #fef2f2; color: #991b1b; }
  .gate-popover { display: none; position: absolute; background: white; border: 1px solid var(--border); border-radius: 6px; padding: 10px 14px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); font-size: 12px; z-index: 50; max-width: 300px; }
  .gate-popover.visible { display: block; }
  .gate-clickable { cursor: pointer; border-bottom: 1px dashed var(--text-muted); }
  .gate-clickable:hover { color: var(--blue); border-bottom-color: var(--blue); }
  .unverified-flag { display: inline-block; padding: 1px 6px; border-radius: 3px; font-size: 9px; font-weight: 700; background: var(--orange-bg); color: #9a3412; margin-left: 6px; text-transform: uppercase; }

  @media (max-width: 768px) {
    .stats { flex-direction: column; gap: 8px; }
    .convergence-grid { grid-template-columns: 1fr; }
    .scenario-grid { grid-template-columns: 1fr; }
    .container { padding: 12px 8px; }
    .arch-floating { width: 60%; }
    .file-modal { width: 98vw; height: 95vh; }
  }
</style>
</head>
<body>
<div class="container">

  <!-- ‚ïê‚ïê DATA INJECTION POINT ‚ïê‚ïê -->
  <!-- The rendering script injects the ReviewPackData JSON here -->

  <!-- ‚ïê‚ïê HEADER ‚ïê‚ïê -->
  <div class="header">
    <h1 id="pr-title">PR #10: Decision persistence: cumulative log after merge acceptance</h1>
    <div class="meta">
      <a id="pr-url" href="https://github.com/joeyfezster/building_ai_w_ai/pull/10" target="_blank">https://github.com/joeyfezster/building_ai_w_ai/pull/10</a><br>
      <span id="pr-branch-info">worktree-decisions-persistence &rarr; main</span>
      &nbsp;|&nbsp; HEAD: <code id="pr-sha">babed4d</code>
    </div>
    <div class="stats" id="pr-stats">
      <span class="stat green"><span class="num">+338</span> additions</span>
      <span class="stat red"><span class="num">&minus;7</span> deletions</span>
      <span class="stat"><span class="num">6</span> files</span>
      <span class="stat"><span class="num">2</span> commits</span>
    </div>
    <div class="status-row" id="pr-status-row">
      <span class="status-badge pass">‚úì CI 4/4</span>
      <span class="status-badge info">‚Ñπ No Scenarios</span>
      <span class="status-badge pass">‚úì 2/2 comments resolved</span>
      <span class="status-badge info">‚öô Factory internals</span>
      <div class="theme-toggle" style="margin-left:auto">
        <button onclick="setTheme('light')" title="Light theme" data-theme-btn="light">&#x2600;</button>
        <button onclick="setTheme('dark')" title="Dark theme" data-theme-btn="dark">&#x1F319;</button>
        <button onclick="setTheme('system')" title="System theme" data-theme-btn="system">&#x2699;</button>
      </div>
    </div>
  </div>

  <!-- ‚ïê‚ïê TAB BAR ‚ïê‚ïê -->
  <div class="tab-bar" id="tab-bar">
    <button class="tab-btn active" onclick="switchTab('review')">Review</button>
    
  </div>

  <!-- ‚ïê‚ïê TAB 1: REVIEW ‚ïê‚ïê -->
  <div id="tab-review" class="tab-content active">
    <div class="tab-panel" style="padding:20px 24px">

    <!-- Section: Architecture -->
    <div class="section" style="border:none;margin-bottom:0">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2>Architecture</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body">
        <div class="arch-controls">
          <button class="arch-toggle active" onclick="setArchView('update',this)">Update (this PR)</button>
          <button class="arch-toggle" onclick="setArchView('baseline',this)">Baseline (before merge)</button>
          <span class="arch-hint">Click a zone to filter findings &bull; Click background to reset</span>
        </div>
        <svg id="arch-diagram" viewBox="0 0 780 360" style="width:100%;max-width:780px;background:#fafbfc;border-radius:8px;border:1px solid var(--border)">
          <defs><marker id="arrowhead" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto"><path d="M0,0 L8,3 L0,6 Z" fill="#9ca3af"/></marker></defs>
          <text x="700" y="60" text-anchor="end" class="arch-row-label">Factory Infrastructure</text>
          <text x="700" y="170" text-anchor="end" class="arch-row-label">Product Code</text>
          <text x="700" y="280" text-anchor="end" class="arch-row-label">Infrastructure</text>
          <rect class="zone-box" data-zone="factory" x="20" y="20" width="120" height="80" rx="8" fill="#dbeafe" stroke="#3b82f6" stroke-width="1.5" style="cursor:pointer;opacity:1"/>
          <text x="80.0" y="56.0" text-anchor="middle" class="zone-label" fill="#1d4ed8" style="pointer-events:none">Factory</text>
          <text x="80.0" y="70.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">Convergence loop</text>
          <circle class="zone-count-bg" cx="132" cy="28" r="10" fill="#3b82f6"/>
          <text class="zone-file-count" x="132" y="32" text-anchor="middle" fill="white" style="pointer-events:none">5</text>
          <rect class="zone-box" data-zone="environment" x="20" y="130" width="120" height="80" rx="8" fill="#dcfce7" stroke="#22c55e" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="80.0" y="166.0" text-anchor="middle" class="zone-label" fill="#166534" style="pointer-events:none">Environment</text>
          <text x="80.0" y="180.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">MiniPong env</text>
          <rect class="zone-box" data-zone="rl-core" x="160" y="130" width="120" height="80" rx="8" fill="#dcfce7" stroke="#22c55e" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="220.0" y="166.0" text-anchor="middle" class="zone-label" fill="#166534" style="pointer-events:none">RL Core</text>
          <text x="220.0" y="180.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">DQN components</text>
          <rect class="zone-box" data-zone="agent" x="300" y="130" width="120" height="80" rx="8" fill="#dcfce7" stroke="#22c55e" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="360.0" y="166.0" text-anchor="middle" class="zone-label" fill="#166534" style="pointer-events:none">Agent</text>
          <text x="360.0" y="180.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">DQN agent</text>
          <rect class="zone-box" data-zone="training" x="440" y="130" width="120" height="80" rx="8" fill="#dcfce7" stroke="#22c55e" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="500.0" y="166.0" text-anchor="middle" class="zone-label" fill="#166534" style="pointer-events:none">Training</text>
          <text x="500.0" y="180.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">Pipeline, eval, video</text>
          <rect class="zone-box" data-zone="observability" x="580" y="130" width="120" height="80" rx="8" fill="#dcfce7" stroke="#22c55e" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="640.0" y="166.0" text-anchor="middle" class="zone-label" fill="#166534" style="pointer-events:none">Observability</text>
          <text x="640.0" y="180.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">Logging, metrics</text>
          <rect class="zone-box" data-zone="dashboard" x="20" y="240" width="120" height="80" rx="8" fill="#dcfce7" stroke="#22c55e" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="80.0" y="276.0" text-anchor="middle" class="zone-label" fill="#166534" style="pointer-events:none">Dashboard</text>
          <text x="80.0" y="290.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">Streamlit app</text>
          <rect class="zone-box" data-zone="tests" x="160" y="240" width="120" height="80" rx="8" fill="#dcfce7" stroke="#22c55e" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="220.0" y="276.0" text-anchor="middle" class="zone-label" fill="#166534" style="pointer-events:none">Tests</text>
          <text x="220.0" y="290.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">pytest suite</text>
          <rect class="zone-box" data-zone="config" x="300" y="240" width="120" height="80" rx="8" fill="#f3e8ff" stroke="#8b5cf6" stroke-width="1.5" style="cursor:pointer;opacity:1"/>
          <text x="360.0" y="276.0" text-anchor="middle" class="zone-label" fill="#6d28d9" style="pointer-events:none">Config</text>
          <text x="360.0" y="290.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">Build, deps</text>
          <circle class="zone-count-bg" cx="412" cy="248" r="10" fill="#8b5cf6"/>
          <text class="zone-file-count" x="412" y="252" text-anchor="middle" fill="white" style="pointer-events:none">1</text>
          <rect class="zone-box" data-zone="docker" x="440" y="240" width="120" height="80" rx="8" fill="#f3e8ff" stroke="#8b5cf6" stroke-width="1.5" style="cursor:pointer;opacity:0.6"/>
          <text x="500.0" y="276.0" text-anchor="middle" class="zone-label" fill="#6d28d9" style="pointer-events:none">Docker/Infra</text>
          <text x="500.0" y="290.0" text-anchor="middle" class="zone-sublabel" style="pointer-events:none">Containers</text>
          <line x1="80" y1="100" x2="80" y2="130" stroke="#9ca3af" stroke-width="1.5" marker-end="url(#arrowhead)"/>
          <line x1="80" y1="210" x2="160" y2="170" stroke="#9ca3af" stroke-width="1.5" marker-end="url(#arrowhead)"/>
          <line x1="280" y1="170" x2="300" y2="170" stroke="#9ca3af" stroke-width="1.5" marker-end="url(#arrowhead)"/>
          <line x1="420" y1="170" x2="440" y2="170" stroke="#9ca3af" stroke-width="1.5" marker-end="url(#arrowhead)"/>
          <line x1="560" y1="170" x2="580" y2="170" stroke="#9ca3af" stroke-width="1.5" marker-end="url(#arrowhead)"/>
          
          
          
          
          
          
        </svg>
        <div id="zone-filter-info" style="margin-top:8px;font-size:12px;color:var(--blue);font-weight:600;display:none"></div>
        <div class="arch-legend">
          <div class="arch-legend-item"><div class="arch-legend-circle" style="background:#3b82f6">3</div> Blue circle = files changed in zone</div>
          <div class="arch-legend-item"><div class="arch-legend-swatch" style="background:#dbeafe;border-color:#3b82f6"></div> Factory infrastructure</div>
          <div class="arch-legend-item"><div class="arch-legend-swatch" style="background:#dcfce7;border-color:#22c55e"></div> Product code</div>
          <div class="arch-legend-item"><div class="arch-legend-swatch" style="background:#f3e8ff;border-color:#8b5cf6"></div> Infrastructure &amp; docs</div>
          <div class="arch-legend-item" style="margin-left:auto;font-style:italic">Click zone to filter &bull; click background to reset</div>
        </div>
      </div>
    </div>

    </div><!-- end tab-panel -->

    <!-- Section: Spec & Scenarios -->
    <div class="section">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2>Spec &amp; Scenarios</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body">
        <h3 style="font-size:13px;margin-bottom:8px">Specifications</h3>
        <ul class="spec-list" id="spec-list">
          <li>üè≠ <code class="file-path-link" onclick="openFileModal('docs/dark_factory.md')">docs/dark_factory.md</code> &mdash; Dark factory operating model, gates, and convergence loop documentation</li>
        </ul>
        <h3 style="font-size:13px;margin:14px 0 8px">Scenarios</h3>
        <div class="scenario-legend" id="scenario-legend">
          <span class="scenario-category cat-pipeline">pipeline</span>
        </div>
        <div class="scenario-grid" id="scenario-grid">
          <div class="scenario-card" data-zone="factory" onclick="this.classList.toggle('open')">
  <div class="name">No Scenarios (Factory Internals PR)
    <span class="scenario-category cat-pipeline">pipeline</span>
  </div>
  <div class="status" style="color:var(--yellow)">&#x26A0; Advisory</div>
  <div class="scenario-card-detail">
    <dl>
      <dt>What</dt><dd>This PR modifies factory infrastructure only ‚Äî no product code was changed, so no behavioral scenarios apply.</dd>
      <dt>How</dt><dd>N/A ‚Äî no holdout evaluation was run for this PR.</dd>
      <dt>Result</dt><dd>Advisory: factory-internal changes are validated by CI (lint, typecheck, test) and adversarial review, not by holdout scenarios.</dd>
    </dl>
  </div>
</div>
        </div>
      </div>
    </div>

    <!-- Section: What Changed -->
    <div class="section">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2>What Changed</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body" id="what-changed-body">
        <p style="margin-bottom:4px;font-size:11px;color:var(--text-muted)">Generated from <code>git diff</code> by delegated diff-reading agent. Code diffs are ground truth.</p>
        <div class="wc-default" id="wc-default">
          <p><strong>Infrastructure:</strong> New decision persistence infrastructure: <code>scripts/persist_decisions.py</code> extracts decisions from review pack data and appends them to <code>docs/decisions/decision_log.json</code>, a cumulative append-only archive. Factory orchestration skill updated with Step 13 (post-merge persistence). Codex prompt restructured to separate read-only context (specs, decisions) from truly prohibited files. Makefile gains <code>persist-decisions</code> target.</p>
          <p><strong>Product:</strong> No product code changes. All modifications are factory infrastructure.</p>
        </div>
        <div class="wc-zone-detail" data-zone="factory">
  <h4>Factory</h4>
  <p><strong>New script:</strong> <code>scripts/persist_decisions.py</code> (~170 lines) ‚Äî deterministic extraction of decisions from review pack JSON or rendered HTML, with idempotent append to the cumulative log. Uses <code>gh pr view</code> for merge timestamps with <code>git log</code> fallback, hard-fails rather than fabricating timestamps.<br><br><strong>Decision log:</strong> <code>docs/decisions/decision_log.json</code> ‚Äî append-only JSON with version field, backfilled with PR #6's 2 decisions. Each decision gets a compound ID (<code>PR{N}-{seq}</code>), global sequence number, zone mapping, verification status, and lifecycle status (<code>active</code>/<code>superseded</code>/<code>retracted</code>).<br><br><strong>SKILL.md:</strong> Added Step 13 (post-merge persistence) to factory orchestration workflow ‚Äî persist decisions, create post-merge issues, commit, cleanup.<br><br><strong>factory_fix.md:</strong> Restructured constraints to separate read-only context (specs, decisions, agents) from truly prohibited files. Added decision log to Codex's context sources.<br><br><strong>CLAUDE.md:</strong> Added <code>docs/decisions/</code> and <code>scripts/persist_decisions.py</code> to factory-protected file list.</p>
</div>
        <div class="wc-zone-detail" data-zone="config">
  <h4>Config</h4>
  <p><strong>Makefile:</strong> Added <code>persist-decisions</code> target (<code>make persist-decisions PR=N</code>) for convenient post-merge invocation.</p>
</div>
      </div>
    </div>

    <!-- Section: Adversarial Review -->
    <div class="section">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2 id="adv-header">Adversarial Review</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body">
        <div class="adv-scroll">
        <div id="adv-no-match" class="adv-no-match">No adversarial findings in this zone.</div>
        <table id="adv-table">
          <thead><tr><th>File</th><th>Grade</th><th>Zone</th><th>Notable</th></tr></thead>
          <tbody>
            <tr class="adv-row" data-zones="factory" data-grade-sort="3" onclick="toggleAdvDetail(this)">
  <td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('scripts/persist_decisions.py')">scripts/persist_decisions.py</code></td>
  <td><span class="grade a">A</span></td>
  <td><span class="zone-tag product">factory</span></td>
  <td>Clean deterministic script following established patterns</td>
</tr>
<tr class="adv-detail-row" data-zones="factory">
  <td colspan="4">Follows the exact same CLI pattern as <code>create_postmerge_issues.py</code>. No security concerns ‚Äî reads local files, calls <code>gh</code> CLI, writes local JSON. Idempotent via ID set check. HTML extraction uses regex on a known structure (not arbitrary HTML parsing). Hard-fails on missing timestamps rather than fabricating data. No subprocess injection risk ‚Äî all subprocess args are positional, not shell-interpolated.</td>
</tr>
            <tr class="adv-row" data-zones="factory" data-grade-sort="3" onclick="toggleAdvDetail(this)">
  <td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('docs/decisions/decision_log.json')">docs/decisions/decision_log.json</code></td>
  <td><span class="grade a">A</span></td>
  <td><span class="zone-tag product">factory</span></td>
  <td>Well-structured seed data from PR #6 backfill</td>
</tr>
<tr class="adv-detail-row" data-zones="factory">
  <td colspan="4">Contains 2 decisions from PR #6, both verified. Compound IDs (<code>PR6-1</code>, <code>PR6-2</code>), global sequence numbers, merge timestamps from actual GitHub data, correct PR URL and SHA. Schema matches the plan design.</td>
</tr>
            <tr class="adv-row" data-zones="factory" data-grade-sort="3" onclick="toggleAdvDetail(this)">
  <td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('.claude/skills/factory-orchestrate/SKILL.md')">.claude/skills/factory-orchestrate/SKILL.md</code></td>
  <td><span class="grade a">A</span></td>
  <td><span class="zone-tag product">factory</span></td>
  <td>Clean Step 13 addition with no disruption to existing workflow</td>
</tr>
<tr class="adv-detail-row" data-zones="factory">
  <td colspan="4">Post-merge persistence step added between review pack generation (Step 12) and stall protocol. Clear sequencing: persist decisions ‚Üí create issues ‚Üí commit ‚Üí cleanup. No changes to existing steps 1-12.</td>
</tr>
            <tr class="adv-row" data-zones="factory" data-grade-sort="3" onclick="toggleAdvDetail(this)">
  <td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('.github/codex/prompts/factory_fix.md')">.github/codex/prompts/factory_fix.md</code></td>
  <td><span class="grade a">A</span></td>
  <td><span class="zone-tag product">factory</span></td>
  <td>Fixed pre-existing read/prohibit contradiction for specs</td>
</tr>
<tr class="adv-detail-row" data-zones="factory">
  <td colspan="4">Restructured the constraints section into two clear categories: read-only context (specs, decisions, agents) and truly prohibited files (scenarios, factory scripts). This fixes a pre-existing contradiction where <code>/specs/</code> was listed under 'NEVER read' while the file simultaneously told Codex to read specs. The decision log addition was the trigger, but the fix is broader.</td>
</tr>
            <tr class="adv-row" data-zones="factory" data-grade-sort="3" onclick="toggleAdvDetail(this)">
  <td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('CLAUDE.md')">CLAUDE.md</code></td>
  <td><span class="grade a">A</span></td>
  <td><span class="zone-tag product">factory</span></td>
  <td>Minimal additions to factory-protected file list</td>
</tr>
<tr class="adv-detail-row" data-zones="factory">
  <td colspan="4">Added 2 entries: <code>/docs/decisions/</code> (Codex reads but never modifies) and <code>/scripts/persist_decisions.py</code>. Consistent with existing list format. Also added <code>persist-decisions</code> to Quick Commands section.</td>
</tr>
            <tr class="adv-row" data-zones="config" data-grade-sort="3" onclick="toggleAdvDetail(this)">
  <td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('Makefile')">Makefile</code></td>
  <td><span class="grade a">A</span></td>
  <td><span class="zone-tag product">config</span></td>
  <td>Simple target addition following existing patterns</td>
</tr>
<tr class="adv-detail-row" data-zones="config">
  <td colspan="4">Added <code>persist-decisions</code> target using the same <code>python scripts/...</code> pattern as other targets. Added to <code>.PHONY</code> list. Uses <code>$(PR)</code> variable consistent with how other parameterized targets would work.</td>
</tr>
            
          </tbody>
        </table>
        </div>
      </div>
    </div>

    <!-- Section: CI Performance -->
    <div class="section">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2>CI Performance</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body">
        <table>
          <thead><tr><th>Check</th><th>Status</th><th>Time</th><th></th></tr></thead>
          <tbody id="ci-table-body">
            <tr class="expandable" onclick="toggleCIDetail(this)">
  <td><strong>factory-self-test</strong> <small style="color:var(--text-muted)">(push)</small></td>
  <td><span class="badge pass">pass</span></td>
  <td><span class="time-label normal">17s</span><br><span class="time-health-sub">normal</span></td>
  <td class="ci-chevron">&#x25BC;</td>
</tr>
<tr class="detail-row">
  <td colspan="4">
    <p><strong>Coverage:</strong> Factory script validation ‚Äî lint, typecheck, and unit tests for factory infrastructure scripts</p>
    <p><strong>Gates:</strong> Gate 1 (factory scripts)</p>
    <div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Lint factory scripts (ruff check)</div>
  <div class="ci-check-detail">All factory scripts pass ruff linting</div>
</div>
<div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Typecheck factory scripts (mypy)</div>
  <div class="ci-check-detail">mypy passes on all factory script modules</div>
</div>
    <div style="margin-top:6px">Zones: <span class="zone-tag product">factory</span></div>
    
  </td>
</tr>
            <tr class="expandable" onclick="toggleCIDetail(this)">
  <td><strong>factory-self-test</strong> <small style="color:var(--text-muted)">(PR)</small></td>
  <td><span class="badge pass">pass</span></td>
  <td><span class="time-label normal">19s</span><br><span class="time-health-sub">normal</span></td>
  <td class="ci-chevron">&#x25BC;</td>
</tr>
<tr class="detail-row">
  <td colspan="4">
    <p><strong>Coverage:</strong> Factory script validation on PR merge ref</p>
    <p><strong>Gates:</strong> Gate 1 (factory scripts)</p>
    <div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Factory scripts lint + typecheck on PR ref</div>
  <div class="ci-check-detail">Same checks as push trigger, run against the PR merge commit</div>
</div>
    <div style="margin-top:6px">Zones: <span class="zone-tag product">factory</span></div>
    
  </td>
</tr>
            <tr class="expandable" onclick="toggleCIDetail(this)">
  <td><strong>validate</strong> <small style="color:var(--text-muted)">(push)</small></td>
  <td><span class="badge pass">pass</span></td>
  <td><span class="time-label watch">5m 33s</span><br><span class="time-health-sub">watch</span></td>
  <td class="ci-chevron">&#x25BC;</td>
</tr>
<tr class="detail-row">
  <td colspan="4">
    <p><strong>Coverage:</strong> Full product validation: lint, typecheck, pytest, docker builds, env smoke tests</p>
    <p><strong>Gates:</strong> Gate 1 (deterministic)</p>
    <div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Lint (ruff check .)</div>
  <div class="ci-check-detail">All Python files pass ruff linting</div>
</div>
<div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Typecheck (mypy src)</div>
  <div class="ci-check-detail">mypy passes on all source modules</div>
</div>
<div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Tests (pytest -q)</div>
  <div class="ci-check-detail">Full test suite passes</div>
</div>
<div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Docker builds</div>
  <div class="ci-check-detail">Both train and demo images build successfully</div>
</div>
<div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Environment smoke test</div>
  <div class="ci-check-detail">MiniPong env creates, resets, and returns correct observation shape</div>
</div>
    <div style="margin-top:6px">Zones: <span class="zone-tag product">environment</span> <span class="zone-tag product">rl-core</span> <span class="zone-tag product">agent</span> <span class="zone-tag product">training</span> <span class="zone-tag product">tests</span> <span class="zone-tag product">config</span> <span class="zone-tag product">docker</span></div>
    <div>Specs: <code>specs/env.md</code> <code>specs/rl.md</code> <code>specs/training.md</code></div>
    <p style="margin-top:6px;font-style:italic;font-size:12px;color:var(--text-muted)">5m33s is in &#x27;watch&#x27; territory (300-600s). Docker builds dominate runtime.</p>
  </td>
</tr>
            <tr class="expandable" onclick="toggleCIDetail(this)">
  <td><strong>validate</strong> <small style="color:var(--text-muted)">(PR)</small></td>
  <td><span class="badge pass">pass</span></td>
  <td><span class="time-label watch">5m 38s</span><br><span class="time-health-sub">watch</span></td>
  <td class="ci-chevron">&#x25BC;</td>
</tr>
<tr class="detail-row">
  <td colspan="4">
    <p><strong>Coverage:</strong> Same as validate (push), run against PR merge commit</p>
    <p><strong>Gates:</strong> Gate 1 (deterministic)</p>
    <div class="ci-check-item" onclick="event.stopPropagation();this.classList.toggle('open')">
  <div class="ci-check-summary"><span class="ci-sub-chevron">&#x25B6;</span> Full validation suite on PR merge ref</div>
  <div class="ci-check-detail">Lint + typecheck + test + docker + env-smoke on the PR merge commit</div>
</div>
    <div style="margin-top:6px">Zones: <span class="zone-tag product">environment</span> <span class="zone-tag product">rl-core</span> <span class="zone-tag product">agent</span> <span class="zone-tag product">training</span> <span class="zone-tag product">tests</span> <span class="zone-tag product">config</span> <span class="zone-tag product">docker</span></div>
    
  </td>
</tr>
            
          </tbody>
        </table>
        <p style="margin-top:10px;font-size:11px;color:var(--text-muted)">
          <strong>Thresholds:</strong> &#x2713; under 1m = normal &bull; &#x25CB; 1-5m = acceptable &bull; &#x26A0; 5-10m = watch &bull; &#x2716; over 10m = needs refactoring
        </p>
      </div>
    </div>

    <!-- Section: Key Decisions -->
    <div class="section">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2>Key Decisions</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body" id="decisions-container">
        <div class="decision-card" data-zones="factory">
  <div class="decision-header" onclick="toggleDecision(this.parentElement)">
    <span class="decision-num">1</span>
    <div>
      <div class="decision-title">Single append-only JSON file over individual ADR files</div>
      <div class="decision-rationale">Decisions are small machine-generated records, not long-form human prose. A single file enables O(1) loading for both the scaffold script and Codex prompt assembly.</div>
    </div>
  </div>
  <div class="decision-body">
    <p>Considered three options: (1) single JSON log, (2) individual ADR-style markdown files, (3) GitHub issues. The single-file approach wins because: decisions are ~200 bytes each, so even 100 decisions is ~20KB. Individual files create filesystem noise (40+ files after 20 PRs, each under 1KB). GitHub issues live outside git, violating the trust hierarchy (git > external services). The append-only constraint ensures the log is a clean audit trail via <code>git log -- docs/decisions/decision_log.json</code>.</p>
    <div class="decision-zones"><span class="zone-tag product">factory</span></div>
    <div class="decision-files"><table style="width:100%;margin-top:8px"><thead><tr><th>File</th><th>Change</th></tr></thead><tbody><tr><td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('docs/decisions/decision_log.json')">docs/decisions/decision_log.json</code></td><td>Created initial log with version field and empty decisions array, then backfilled PR #6 decisions</td></tr>
<tr><td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('scripts/persist_decisions.py')">scripts/persist_decisions.py</code></td><td>Script writes to this file with idempotent append logic</td></tr>
</tbody></table></div>
  </div>
</div>
        <div class="decision-card" data-zones="factory">
  <div class="decision-header" onclick="toggleDecision(this.parentElement)">
    <span class="decision-num">2</span>
    <div>
      <div class="decision-title">Codex reads the decision log (not stripped with holdout)</div>
      <div class="decision-rationale">Decisions describe why choices were made ‚Äî architectural context, not evaluation criteria. Stripping them forces Codex to re-derive context, risking contradictory decisions across cranks.</div>
    </div>
  </div>
  <div class="decision-body">
    <p>The holdout stripping mechanism (<code>strip_holdout.py</code>) exists to prevent Codex from seeing its evaluation criteria (scenarios). Decisions are categorically different ‚Äî they're analogous to specs (which Codex reads). Hiding past architectural decisions means each crank starts from zero context on <em>why</em> the system is the way it is. This was a deliberate design choice discussed with the project lead during planning.</p>
    <div class="decision-zones"><span class="zone-tag product">factory</span></div>
    <div class="decision-files"><table style="width:100%;margin-top:8px"><thead><tr><th>File</th><th>Change</th></tr></thead><tbody><tr><td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('.github/codex/prompts/factory_fix.md')">.github/codex/prompts/factory_fix.md</code></td><td>Added decision log to Codex&#x27;s context sources, restructured constraints to allow reading</td></tr>
</tbody></table></div>
  </div>
</div>
        <div class="decision-card" data-zones="factory">
  <div class="decision-header" onclick="toggleDecision(this.parentElement)">
    <span class="decision-num">3</span>
    <div>
      <div class="decision-title">Separate read-only context from prohibited files in Codex prompt</div>
      <div class="decision-rationale">The existing factory_fix.md had a pre-existing contradiction: /specs/ was listed under &#x27;NEVER read&#x27; while also instructing Codex to read specs.</div>
    </div>
  </div>
  <div class="decision-body">
    <p>Bot reviewer (codex-connector) flagged that adding <code>/docs/decisions/</code> to the 'NEVER read, modify, or delete' section while telling Codex to read it was contradictory. Investigation revealed the same bug already existed for <code>/specs/</code>. Fixed by splitting into two sections: 'NEVER modify or delete' (read-only context: specs, decisions, agents) and 'NEVER read, modify, or delete' (truly prohibited: scenarios, factory scripts).</p>
    <div class="decision-zones"><span class="zone-tag product">factory</span></div>
    <div class="decision-files"><table style="width:100%;margin-top:8px"><thead><tr><th>File</th><th>Change</th></tr></thead><tbody><tr><td><code class="file-path-link" onclick="event.stopPropagation();openFileModal('.github/codex/prompts/factory_fix.md')">.github/codex/prompts/factory_fix.md</code></td><td>Restructured constraints section into read-only vs prohibited categories</td></tr>
</tbody></table></div>
  </div>
</div>
      </div>
    </div>

    <!-- Section: Convergence Result -->
    <div class="section">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2>Convergence Result</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body">
        <div class="convergence-grid" id="convergence-grid">
          <div class="conv-card" onclick="this.classList.toggle('open')">
  <div class="conv-name">Gate 0 ‚Äî Adversarial Review</div>
  <div class="conv-status passing">CLEAN</div>
  <div class="conv-detail">6 files reviewed, all grade A. No critical or warning findings.</div>
  <div class="conv-card-detail">All changes are factory infrastructure ‚Äî new script follows established patterns, SKILL.md/CLAUDE.md/Makefile additions are mechanical. Bot reviewer found 2 legitimate issues (timestamp fallback, constraint contradiction) which were fixed in commit babed4d before review pack generation.</div>
</div>
          <div class="conv-card" onclick="this.classList.toggle('open')">
  <div class="conv-name">Gate 1 ‚Äî Deterministic</div>
  <div class="conv-status passing">ALL PASS</div>
  <div class="conv-detail">4/4 CI checks pass: factory-self-test (push/PR) + validate (push/PR)</div>
  <div class="conv-card-detail"><strong>factory-self-test:</strong> 17-19s, both pass<br><strong>validate:</strong> 5m33-38s, both pass<br>ruff clean, mypy clean, pytest passes. No product code changes so no behavioral risk.</div>
</div>
          <div class="conv-card" onclick="this.classList.toggle('open')">
  <div class="conv-name">Gate 2 ‚Äî NFR</div>
  <div class="conv-status passing">N/A</div>
  <div class="conv-detail">NFR checks not run separately ‚Äî no product code changes.</div>
  <div class="conv-card-detail">This PR only modifies factory infrastructure files. Gate 2 NFR checks (code quality, complexity, dead code, security) target product code in <code>src/</code>. The new script (<code>scripts/persist_decisions.py</code>) passes ruff + mypy individually.</div>
</div>
          <div class="conv-card" onclick="this.classList.toggle('open')">
  <div class="conv-name">Gate 3 ‚Äî Scenarios</div>
  <div class="conv-status passing">N/A</div>
  <div class="conv-detail">No holdout scenarios apply ‚Äî factory internals PR.</div>
  <div class="conv-card-detail">Holdout scenarios evaluate product behavior (environment, training, pipeline). This PR makes zero changes to product code, so no scenarios were run. CI's full test suite passing confirms no regressions.</div>
</div>
          <div class="conv-card" onclick="this.classList.toggle('open')">
  <div class="conv-name">Overall</div>
  <div class="conv-status passing">READY</div>
  <div class="conv-detail">Factory-internal PR. CI green, adversarial review clean, bot findings addressed.</div>
  <div class="conv-card-detail">All applicable gates pass. This is a factory infrastructure change ‚Äî the decision persistence mechanism ‚Äî with no product code impact. Safe to merge.</div>
</div>
        </div>
      </div>
    </div>

    <!-- Section: Post-Merge Items -->
    <div class="section">
      <div class="section-header" onclick="this.parentElement.classList.toggle('collapsed')">
        <h2>Post-Merge Items</h2>
        <span class="chevron">&#x25BC;</span>
      </div>
      <div class="section-body" id="post-merge-container">
        <div class="pm-item">
  <div class="pm-header" onclick="this.parentElement.classList.toggle('open')">
    <span class="priority low">LOW</span>
    <span>Phase 2: Cross-PR decision context in future review packs</span>
  </div>
  <div class="pm-body">
    <p>The decision log is now being populated, but future review packs don't yet consume it. Phase 2 would add a <code>decisionHistory</code> field to ReviewPackData so the Pass 2 agent can surface relevant prior decisions when generating a new review pack.</p>
    
    <div class="scenario-box failure">
      <div class="scenario-label">Failure scenario</div>
      Without Phase 2, the decision log grows but review packs don&#x27;t reference it. Joey has to manually check the log to understand decision lineage across PRs.
    </div>
    <div class="scenario-box success">
      <div class="scenario-label">Resolution</div>
      Each review pack shows &#x27;Related prior decisions&#x27; within decision cards, linking back to the PR that introduced them. Joey sees continuity without manual lookup.
    </div>
    <div style="margin-top:6px"><span class="zone-tag product">factory</span></div>
  </div>
</div>
        <div class="pm-item">
  <div class="pm-header" onclick="this.parentElement.classList.toggle('open')">
    <span class="priority low">LOW</span>
    <span>Phase 3: Decision lifecycle management (retract/supersede)</span>
  </div>
  <div class="pm-body">
    <p>The <code>status</code> field supports <code>active</code>/<code>superseded</code>/<code>retracted</code> but there's no CLI interface to change status. Currently requires manual JSON editing.</p>
    
    <div class="scenario-box failure">
      <div class="scenario-label">Failure scenario</div>
      If Joey wants to retract a decision, he has to manually edit decision_log.json ‚Äî error-prone and not self-documenting.
    </div>
    <div class="scenario-box success">
      <div class="scenario-label">Resolution</div>
      &lt;code&gt;python scripts/persist_decisions.py --retract PR6-1 --reason &#x27;Replaced by PR12 approach&#x27;&lt;/code&gt; updates the log cleanly with audit trail.
    </div>
    <div style="margin-top:6px"><span class="zone-tag product">factory</span></div>
  </div>
</div>
      </div>
    </div>

  </div><!-- end tab-review -->

  <!-- ‚ïê‚ïê TAB 2: FACTORY HISTORY (conditional) ‚ïê‚ïê -->
  <div id="tab-history" class="tab-content">
    <div class="tab-panel" style="padding:20px 24px">
      <h2 style="font-size:15px;font-weight:700;margin-bottom:16px">Factory Convergence History</h2>
      <div class="history-legend">
        <div class="history-legend-item"><div class="history-legend-dot" style="background:var(--blue)"></div> Automated event</div>
        <div class="history-legend-item"><div class="history-legend-dot" style="background:var(--orange)"></div> Human/agent intervention</div>
        <div class="history-legend-item" style="margin-left:auto;font-style:italic">Click event to expand details</div>
      </div>
      <div class="convergence-grid" style="margin-bottom:20px" id="history-summary-cards">
        <!-- INJECT: iteration count + satisfaction trajectory cards -->
      </div>
      <h3 style="font-size:13px;font-weight:700;margin-bottom:12px">Timeline</h3>
      <div class="history-timeline" id="history-timeline">
        <!-- INJECT: factory history events from DATA.factoryHistory.timeline -->
      </div>
      <h3 style="font-size:13px;font-weight:700;margin:20px 0 12px">Gate Findings by Iteration</h3>
      <table id="gate-findings-table">
        <thead><tr><th>Phase</th><th>Gate 1</th><th>Gate 2</th><th>Gate 3</th><th>Action</th></tr></thead>
        <tbody>
          <!-- INJECT: gate finding rows from DATA.factoryHistory.gateFindings -->
        </tbody>
      </table>
    </div>
  </div>

  <div class="footer">
    Generated by review pack agent &nbsp;|&nbsp; <span id="footer-date">2026-02-27T18:10:00Z</span> &nbsp;|&nbsp; HEAD: <span id="footer-sha">babed4d</span><br>
    <span style="font-size:10px">Deterministic rendering from structured data &bull; Code diffs are ground truth</span>
  </div>

</div>

<!-- Floating architecture diagram (populated by JS) -->
<div id="arch-floating" class="arch-floating">
  <button class="arch-floating-close" onclick="dismissFloatingDiagram()" title="Dismiss floating diagram">&times;</button>
  <div id="arch-floating-content"></div>
</div>

<!-- File diff modal -->
<div id="file-modal-overlay" class="file-modal-overlay" onclick="if(event.target===this)closeFileModal()">
  <div class="file-modal">
    <div class="file-modal-header">
      <div style="display:flex;align-items:center;gap:8px;overflow:hidden">
        <h3 id="file-modal-path" style="white-space:nowrap;overflow:hidden;text-overflow:ellipsis"></h3>
        <span id="file-modal-stats" class="fm-stats"></span>
      </div>
      <button class="file-modal-close" onclick="closeFileModal()">&times;</button>
    </div>
    <div class="file-modal-toolbar">
      <div class="file-modal-tabs">
        <button class="file-modal-tab active" data-view="side-by-side" onclick="setFileModalTab(this,'side-by-side')">Side-by-side</button>
        <button class="file-modal-tab" data-view="integrated" onclick="setFileModalTab(this,'integrated')">Unified</button>
        <button class="file-modal-tab" data-view="raw" onclick="setFileModalTab(this,'raw')">Raw file</button>
      </div>
      <a id="file-modal-github-link" class="file-modal-github" href="#" target="_blank">View on GitHub &rarr;</a>
    </div>
    <div class="file-modal-body" id="file-modal-body">
      <div class="diff-loading">Loading diff data&hellip;</div>
    </div>
  </div>
</div>

<!-- Gate popover -->
<div id="gate-popover" class="gate-popover"></div>

<script>
// Reference file content embedded by render_review_pack.py
// These files are not in the diff but are viewable in raw mode.
const REFERENCE_FILES = {"docs/dark_factory.md": "# Dark Factory \u2014 Operating Manual\n\n## What Is This\n\nThe dark factory is a convergence loop that turns a one-shot AI code generation into working software through automated validation and feedback. Code is never reviewed by humans \u2014 correctness is inferred from externally observable behavior.\n\nThe pattern: **Seed \u2192 Agent \u2192 Validate \u2192 Feedback \u2192 Repeat until satisfied.**\n\n## Cross-References (DRY)\n\nThis file is the **operating manual** \u2014 the \"what\" and \"why\" of the factory. Operational detail lives in the skills:\n\n| Concept | Source of Truth | This File |\n|---------|----------------|-----------|\n| Convergence loop steps | `.claude/skills/factory-orchestrate/SKILL.md` | Summary in ASCII diagram |\n| Gate 0 agent team composition | `factory-orchestrate/SKILL.md` Step 4 | Behavioral contract only |\n| PR review pack pipeline | `.claude/skills/pr-review-pack/SKILL.md` | What the human reviews |\n| Code quality standards | `docs/code_quality_standards.md` | References, doesn't repeat |\n| Adversarial review checklist | `.github/codex/prompts/adversarial_review.md` | References, doesn't repeat |\n\nWhen updating gate behavior or agent composition, update the **skill first**, then check this file's summary still holds.\n\n## Architecture\n\n**Claude Code is the factory orchestrator.** It drives the convergence loop, invokes Codex via browser, runs adversarial review, and makes holistic judgment calls. CI provides background validation on every push \u2014 it validates, it doesn't orchestrate.\n\n### Claude Code as Orchestrator (Primary)\n\nClaude Code runs the convergence loop via the `/factory-orchestrate` skill, using browser automation to invoke Codex through the ChatGPT Plus UI.\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               HUMAN (Project Lead)               \u2502\n\u2502  Authors specs (/specs/) and scenarios           \u2502\n\u2502  Invokes /factory-orchestrate skill              \u2502\n\u2502  Reviews PR at accept/merge gate                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         CLAUDE CODE (Orchestrator)               \u2502\n\u2502         .claude/skills/factory-orchestrate        \u2502\n\u2502                                                   \u2502\n\u2502  for each iteration:                              \u2502\n\u2502    1. Create df-crank-vXX branch                  \u2502\n\u2502    2. strip_holdout.py \u2192 remove /scenarios/       \u2502\n\u2502    3. Push stripped branch to origin               \u2502\n\u2502    4. Invoke Codex via browser (Codex UI)          \u2502\n\u2502       \u2192 Codex creates its own codex-... branch     \u2502\n\u2502    5. Gate 0: Adversarial review (agent team)       \u2502\n\u2502    6. Merge Codex changes onto factory branch      \u2502\n\u2502    7. restore_holdout.py \u2192 restore /scenarios/     \u2502\n\u2502    8. Gate 1: make lint && typecheck && test        \u2502\n\u2502    9. Gate 2: NFR checks (non-blocking)            \u2502\n\u2502   10. Gate 3: Behavioral scenarios                 \u2502\n\u2502   11. LLM-as-judge: holistic evaluation            \u2502\n\u2502   12. If satisfied \u2192 PR. If not \u2192 feedback \u2192 loop  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                  \u25b2\n             \u2502 stripped branch   \u2502 codex-... branch\n             \u25bc                  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              CODEX (Attractor)                    \u2502\n\u2502  Reads: /specs/, feedback_iter_N.md               \u2502\n\u2502  Writes: src/, tests/, configs/, Makefile         \u2502\n\u2502  NEVER sees: /scenarios/ (stripped from branch)    \u2502\n\u2502  NEVER touches: factory infrastructure             \u2502\n\u2502  Creates own branch: codex-...                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### CI Validation on Push (Background)\n\nCI runs validation-only on every push to `factory/**` or `df-crank-**` branches: Gate 1 (lint/typecheck/test), Gate 2 (NFR checks), and Gate 3 (behavioral scenarios). Claude Code reads these CI results as input to its orchestration decisions. If an `OPENAI_API_KEY` secret is available, CI can also run a fallback convergence loop with Codex API \u2014 but browser orchestration is the primary path.\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            CI VALIDATION                          \u2502\n\u2502        .github/workflows/factory.yaml             \u2502\n\u2502                                                   \u2502\n\u2502  On push to factory/** or df-crank-** branches:   \u2502\n\u2502    1. Gate 1: lint + typecheck + test              \u2502\n\u2502    2. Gate 2: NFR checks                           \u2502\n\u2502    3. Gate 3: Behavioral scenarios                 \u2502\n\u2502    4. Compile feedback                             \u2502\n\u2502  Claude Code reads CI results and decides next     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## Validation Gates\n\n### Gate 0: Adversarial Code Review (Agent Team)\n- Runs as a **parallel agent team** before merge \u2014 deterministic tool agents + LLM semantic reviewer, simultaneously\n- **Fail-fast rule:** Any CRITICAL finding from any agent \u2192 stop. Do NOT merge. Compile findings as feedback and loop back to Codex. No point sending to CI or later gates.\n- Clean or WARNING-only across all agents \u2192 proceed to merge + Gate 1\n- Full agent team composition and execution: see `factory-orchestrate/SKILL.md` Step 4\n\n### Gate 1: Deterministic CI\n- `make lint` \u2014 ruff check\n- `make typecheck` \u2014 mypy\n- `make test` \u2014 full pytest suite (including tests the attractor wrote, already reviewed by Gate 0)\n\nIf any fail, Gates 2-3 are skipped. The agent gets the CI errors directly.\n\n### Gate 2: Non-Functional Requirements (NFRs)\n- `make nfr-check` \u2014 extensible framework (`scripts/nfr_checks.py`)\n- **Active checks:** code quality (ruff extended), complexity (radon), dead code (vulture), security (bandit)\n- **Planned checks:** duplication, import hygiene, coverage, maintainability, reliability\n- Non-blocking \u2014 findings feed into feedback and LLM-as-judge evaluation\n- Adding a new check: write a function, register in `NFR_CHECKS` dict\n\n### Gate 3: Behavioral Scenarios\n- `scripts/run_scenarios.py` executes holdout scenarios from `/scenarios/`\n- Each scenario runs an evaluation command and checks pass criteria\n- Results produce a satisfaction score: `passed / total`\n\n### LLM-as-Judge (Claude Code orchestrated)\n- Claude Code reasons holistically through ALL gate outputs\n- Not just \"score >= threshold\" \u2014 considers trajectory, systemic issues, Gate 2 warnings\n- Factors in: Are fixes real or is Codex gaming? Do patterns make sense?\n- Holistic go/no-go decision for creating the PR\n\n## Scenario Isolation (Branch Stripping)\n\nThe factory hides `/scenarios/` from Codex using **branch stripping** \u2014 scenarios are physically removed from the branch Codex works on.\n\n### How it works\n1. `scripts/strip_holdout.py` removes `/scenarios/` and comments out Makefile scenario targets\n2. Commits with marker `[factory:holdout-stripped]`\n3. Verifies no scenario files remain on the branch\n4. Stripped branch is pushed to origin \u2014 Codex only ever sees this branch\n5. After Codex finishes, `scripts/restore_holdout.py` restores from `origin/main`\n\n### Why branch stripping (not filesystem shuffle)\nThe previous approach (`mv scenarios /tmp/`) was security theater \u2014 Codex runs in the same job and can read `/tmp/`. Branch stripping is a real gate: scenarios literally don't exist on the branch Codex sees. There's nothing to read, no path to guess, no hidden directory to discover.\n\n### Scripts\n- `scripts/strip_holdout.py` \u2014 deterministic removal, supports `--dry-run` and `--no-commit`\n- `scripts/restore_holdout.py` \u2014 deterministic restoration from a git ref, supports `--ref` and `--dry-run`\n- Both are factory-protected files (never modified by Codex)\n\n## How to Trigger the Factory\n\n### Claude Code Orchestrated (primary)\n```\n# Invoke the factory orchestration skill:\n/factory-orchestrate\n```\nClaude Code handles the full loop: branch creation, holdout stripping, Codex invocation (via browser), adversarial review, validation, LLM judgment, and PR creation.\n\n### GitHub Actions (CI validation on push)\n```\n# Automatic: push to factory/** or df-crank-** branches triggers CI validation\n# Manual: Actions \u2192 Dark Factory \u2192 Run workflow\ngh workflow run factory.yaml -f max_iterations=5 -f satisfaction_threshold=0.80\n```\nCI runs Gates 1-3 + feedback compilation. Claude Code reads the results.\n\n### Local (testing the plumbing)\n```bash\nmake factory-local    # One iteration: Gate 1 \u2192 Gate 2 \u2192 Gate 3 \u2192 feedback\nmake factory-status   # Show current iteration and satisfaction score\nmake nfr-check        # Just run Gate 2 NFR checks\n```\n\n### Individual components\n```bash\nmake run-scenarios        # Just run scenarios\nmake compile-feedback     # Just compile feedback from latest results\n```\n\n## How to Write a New Scenario\n\nCreate a markdown file in `/scenarios/` with this structure:\n\n```markdown\n# Scenario: [descriptive name]\n\n## Category\n[environment | training | pipeline | dashboard | integration]\n\n## Preconditions\n- [what must be true before evaluation]\n\n## Behavioral Expectation\n[what the system should do, from observer perspective]\n\n## Evaluation Method\n\\```bash\n[command that tests the behavior]\n\\```\n\n## Pass Criteria\n[specific condition for passing]\n\n## Evidence Required\n- [what to capture as proof]\n```\n\nThe evaluation method is a bash command that exits 0 on pass, non-zero on fail. Keep commands self-contained \u2014 they run in the repo root with PYTHONPATH set.\n\n## How to Read Feedback\n\nFeedback files are at `artifacts/factory/feedback_iter_N.md`. Each contains:\n- **Summary** \u2014 satisfaction score and pass/fail counts\n- **Convergence trajectory** \u2014 how scores changed across iterations\n- **Likely root causes** \u2014 pattern-matched from error types\n- **Full error details** \u2014 every failed scenario with complete stdout/stderr\n- **Instructions** \u2014 prioritized fix guidance for the coding agent\n\n## Accept/Merge Gate\n\nThe factory **never auto-merges** to main. When the convergence loop meets the satisfaction threshold, it creates (or updates) a PR with the `factory-converged` and `accept-merge-gate` labels. This is the single human decision point in the entire loop.\n\nAfter creating the PR, the orchestrator generates a **PR review pack** via the `/pr-review-pack` skill \u2014 a self-contained interactive HTML file. The project lead reviews the report, not the code. Build specification and three-pass pipeline: see `pr-review-pack/SKILL.md`.\n\n**What the project lead reviews (via the review pack):**\n- Architecture diagram showing which zones were touched\n- Adversarial findings from the Gate 0 agent team, graded by file\n- CI performance with health classification\n- Key decisions with zone-level traceability\n- Convergence result \u2014 gate-by-gate status and satisfaction score\n- Post-merge items with code snippets and failure/success scenarios\n- Factory history \u2014 iteration timeline, intervention log, gate findings per iteration\n\n**To accept:** Approve and merge the PR. The factory branch can be deleted.\n**To reject:** Close the PR and either adjust scenarios/specs or trigger another factory run.\n\nThe accept/merge gate exists because code produced by the factory was never reviewed by humans during production. The review pack provides structured visibility into what the factory did and why. The merge decision is always human.\n\n## When to Escalate\n\nEscalate to interactive debugging (Claude Code) when:\n- The factory has stalled for 3+ iterations with no score improvement\n- The same scenario keeps failing with the same error pattern\n- Gate 1 failures persist (the code doesn't even pass lint/typecheck)\n- A scenario requires architectural changes the agent can't figure out from error messages alone\n\n## Factory State\n\n```\nartifacts/factory/\n\u251c\u2500\u2500 scenario_results.json    # Latest run results (gitignored)\n\u251c\u2500\u2500 ci_output.log            # Latest CI output (gitignored)\n\u251c\u2500\u2500 iteration_count.txt      # Current iteration number (committed)\n\u2514\u2500\u2500 feedback_iter_*.md       # All feedback files (committed \u2014 Codex reads these)\n```\n\n## Known Evolution Paths\n\nArchitecture decisions that are correct for the current proof-of-concept but should be revisited as the factory matures:\n\n| Decision | Current State | Evolution Trigger | Target |\n|----------|--------------|-------------------|--------|\n| Separate factory-loop + validate CI workflows | Overlap provides redundancy | Factory running regularly with stable gates | Consolidate into single workflow with clear separation |\n| `.devcontainer` setup | Not yet configured | Multiple developers or CI environments diverging | Add devcontainer with pinned Python, deps, hooks |\n| Gate 2 checks are tool-only | Deterministic, reliable | Need for architectural or design-level quality checks | Add LLM-based advisory checks (clearly labeled non-deterministic) |\n| Post-merge items tracked in review pack only | PR review pack captures items | Items getting lost after merge | `scripts/create_postmerge_issues.py` creates GH issues automatically |\n| Manual `make install-hooks` required | Prominent in docs, not enforced | New contributors missing it | `.devcontainer` or CI check that validates hooks are installed |\n\n## Key Files\n\n| File | Owner | Purpose |\n|------|-------|---------|\n| `/specs/*.md` | Human | What the system should do |\n| `/scenarios/*.md` | Human | How to evaluate (holdout) |\n| `/scripts/run_scenarios.py` | Factory | Scenario evaluation engine |\n| `/scripts/compile_feedback.py` | Factory | Feedback generation |\n| `/scripts/strip_holdout.py` | Factory | Holdout stripping (isolation gate) |\n| `/scripts/restore_holdout.py` | Factory | Holdout restoration |\n| `/scripts/nfr_checks.py` | Factory | Gate 0 tool agents + Gate 2 NFR checker |\n| `/scripts/check_test_quality.py` | Factory | Gate 0 tool agent \u2014 vacuous test detection |\n| `/.github/workflows/factory.yaml` | Factory | CI validation on push |\n| `/.github/codex/prompts/factory_fix.md` | Factory | Codex instruction template |\n| `/.github/codex/prompts/adversarial_review.md` | Factory | Gate 0 semantic reviewer checklist |\n| `/.claude/skills/factory-orchestrate/` | Factory | Claude Code orchestration skill |\n| `/.claude/skills/pr-review-pack/` | Factory | PR review pack generation (accept/merge gate) |\n| `/docs/code_quality_standards.md` | Factory | Universal code quality standards |\n| `/docs/factory_architecture.html` | Factory | Interactive architecture diagram |\n| `/CLAUDE.md` | Factory | Repo-level context for Claude Code |\n| `/artifacts/factory/feedback_iter_*.md` | Factory | Iteration feedback (Codex reads) |\n"};
</script>
<script>
// Diff data embedded inline by render_review_pack.py
// Source: generate_diff_data.py (Pass 1, deterministic)
// Trust: raw git diff/show output, zero LLM involvement
const DIFF_DATA_INLINE = {
  "pr": 10,
  "base_branch": "main",
  "head_branch": "worktree-decisions-persistence",
  "head_sha": "babed4d",
  "head_sha_full": "babed4d70da20f23867b9436595dc6fdf49112d2",
  "total_files": 6,
  "total_additions": 340,
  "total_deletions": 3,
  "files": {
    ".claude/skills/factory-orchestrate/SKILL.md": {
      "additions": 29,
      "deletions": 0,
      "status": "modified",
      "binary": false,
      "diff": "diff --git a/.claude/skills/factory-orchestrate/SKILL.md b/.claude/skills/factory-orchestrate/SKILL.md\nindex 1c6b664..449069d 100644\n--- a/.claude/skills/factory-orchestrate/SKILL.md\n+++ b/.claude/skills/factory-orchestrate/SKILL.md\n@@ -200,6 +200,33 @@ The review pack gives the project lead:\n \n The review pack is the artifact that communicates factory status to the human. Without it, the accept/merge gate is a rubber stamp.\n \n+### Step 13: Post-Merge Persistence\n+\n+After the project lead merges the PR:\n+\n+1. **Persist decisions** to the cumulative log:\n+   ```bash\n+   python scripts/persist_decisions.py --pr {PR_NUMBER}\n+   ```\n+   The script extracts decisions from the review pack HTML (or from the JSON intermediate if available via `--data`) and appends them to `docs/decisions/decision_log.json`. It is idempotent \u2014 safe to run multiple times.\n+\n+2. **Create post-merge issues** (if applicable):\n+   ```bash\n+   python scripts/create_postmerge_issues.py --pr {PR_NUMBER}\n+   ```\n+\n+3. **Commit and push** the updated decision log:\n+   ```bash\n+   git add docs/decisions/decision_log.json\n+   git commit -m \"decisions: persist PR #{PR_NUMBER} decisions\"\n+   git push\n+   ```\n+\n+4. **Delete Codex's remote branch** (cleanup):\n+   ```bash\n+   git push origin --delete codex-{branch}\n+   ```\n+\n ### Stall Protocol\n \n If after 3+ iterations:\n@@ -215,6 +242,8 @@ If after 3+ iterations:\n - **NFR checks script**: `scripts/nfr_checks.py` (Gate 0 tool agents + Gate 2)\n - **Test quality scanner**: `scripts/check_test_quality.py` (Gate 0 tool agent)\n - **PR review pack skill**: `.claude/skills/pr-review-pack/SKILL.md` (Step 12)\n+- **Decision log**: `docs/decisions/decision_log.json` (Step 13, cumulative archive)\n+- **Decision persistence**: `scripts/persist_decisions.py` (Step 13)\n - **Specs**: `specs/*.md`\n - **Factory docs**: `docs/dark_factory.md`\n - **Factory architecture**: `docs/factory_architecture.html`\n",
      "raw": "---\nname: factory-orchestrate\ndescription: Run the dark factory convergence loop. Use when the user says \"run a factory crank\", \"start the factory\", \"orchestrate a crank\", or similar. Orchestrates Codex via browser, manages holdout isolation, runs validation gates, and performs LLM-as-judge evaluation.\nallowed-tools: Bash, Read, Write, Glob, Grep, Edit\n---\n\n# Dark Factory Orchestration \u2014 Claude Code as Orchestrator\n\nYou are the factory orchestrator. You run the convergence loop that turns specs into working software through iterative AI coding + validation.\n\n## Prerequisites\n\n- Chrome is logged into Codex (ChatGPT Plus account)\n- Repository: `joeyfezster/building_ai_w_ai`\n- Branch to base work on: confirm with user or default to `factory/v1`\n- Satisfaction threshold: confirm with user or default to 80%\n- Max iterations: confirm with user or default to 5\n\n## The Loop\n\nFor each iteration:\n\n### Step 1: Create Factory Branch\n```bash\n# First crank \u2014 create from base branch\ngit checkout -b df-crank-v01-{descriptor} {base_branch}\ngit push -u origin df-crank-v01-{descriptor}\n```\n\nBranch naming: `df-crank-vXX-{descriptor}` where XX is the crank version.\n\n### Step 2: Strip Holdout\n```bash\npython scripts/strip_holdout.py\ngit push\n```\n\nThis deterministically removes `/scenarios/` and comments out scenario Makefile targets. Codex literally cannot see evaluation criteria.\n\nVerify: `ls scenarios/` should fail (directory gone).\n\n### Step 3: Invoke Codex via Browser\n\nOpen the Codex UI in Chrome. Provide:\n- **Repository**: `joeyfezster/building_ai_w_ai`\n- **Base branch**: `df-crank-vXX-{descriptor}` (the stripped branch)\n- **Prompt**: Contents of `.github/codex/prompts/factory_fix.md` + the latest feedback file (`artifacts/factory/feedback_iter_N.md`)\n- **Versions**: 1\n\nCodex will create its own branch (named `codex-...`). Wait for it to finish.\n\n### Step 4: Gate 0 \u2014 Adversarial Code Review (Agent Team)\n\nBefore merging Codex's changes, run a **full adversarial review via agent teams**. This is the first line of defense \u2014 there is no point sending code to CI or later gates if Gate 0 finds critical issues.\n\n1. Fetch Codex's branch: `git fetch origin`\n2. Get the diff: `git diff df-crank-vXX...origin/codex-{branch}`\n\n3. **Spawn the Gate 0 agent team.** Create a team and launch these agents in parallel:\n\n   **Tool agents** (deterministic, Bash-capable \u2014 run ALL simultaneously):\n   | Agent | What It Runs | What It Catches |\n   |-------|-------------|-----------------|\n   | `ruff-agent` | `python scripts/nfr_checks.py --check code_quality` | Lint violations, style, import issues |\n   | `radon-agent` | `python scripts/nfr_checks.py --check complexity` | Cyclomatic complexity > threshold |\n   | `vulture-agent` | `python scripts/nfr_checks.py --check dead_code` | Unreachable code, unused functions |\n   | `bandit-agent` | `python scripts/nfr_checks.py --check security` | Security vulnerabilities |\n   | `test-quality-agent` | `python scripts/check_test_quality.py` | Vacuous tests, stub assertions, mock abuse |\n\n   **Semantic reviewer** (LLM-based, runs in parallel with tool agents):\n   | Agent | What It Reads | What It Catches |\n   |-------|--------------|-----------------|\n   | `adversarial-reviewer` | The diff + `.github/codex/prompts/adversarial_review.md` + `docs/code_quality_standards.md` + `/specs/*.md` | Gaming, architectural dishonesty, spec violations, integration gaps, subtle patterns the tools miss |\n\n4. **Aggregate findings.** Collect all agent outputs. Each finding has a severity: CRITICAL, WARNING, or NIT.\n\n5. **Fail-fast rule:** If **any agent** reports a CRITICAL finding, Gate 0 fails. Do NOT merge. Compile all findings (from all agents) as feedback and loop back to Step 3 with specific remediation instructions.\n\n**If clean or WARNING-only across all agents**: Proceed to Step 5. WARNING findings are tracked \u2014 they feed into the LLM-as-judge evaluation in Step 10.\n\n**Why agent teams, not a single reviewer:** The tool agents catch cheap, obvious violations in seconds (dead code, complexity, security). The semantic reviewer catches subtle gaming and architectural dishonesty. Running them in parallel means Gate 0 is both fast AND thorough. A single reviewer doing everything sequentially is slower and more likely to miss things.\n\n### Step 5: Merge Codex Changes\n```bash\ngit merge origin/codex-{branch} --no-ff -m \"factory: merge codex iteration N\"\n```\n\n### Step 5b: Check CI Results\n\nAfter pushing, check CI results. CI runs Gates 1-3 on every push to factory/** branches. Use CI results as early signal before running gates locally.\n\n```bash\n# Wait for CI to complete (typically 2-5 minutes)\ngh run list --branch df-crank-vXX --limit 3\n\n# Check the PR's checks (if PR exists)\ngh pr checks <PR_NUMBER>\n```\n\n**Known `gh pr checks` behavior:**\n- `gh pr checks` shows checks associated with the PR's **merge ref**, not the branch HEAD directly\n- If a bot (GITHUB_TOKEN) pushes a commit that becomes PR HEAD, GitHub does NOT re-trigger CI workflows (prevents infinite loops). The PR may show \"0 checks\" even though CI ran fine on the previous commit.\n- Workaround: If you see stale/missing checks, use `gh run list --branch <branch>` instead \u2014 this shows actual workflow runs regardless of the merge ref.\n- Commits pushed by workflows using `GITHUB_TOKEN` do not trigger other workflows. This is a GitHub safety measure.\n- If CI results conflict with your local gate results, investigate \u2014 don't just ignore the discrepancy.\n\n**If CI fails**: Use the github.com's copilot's 'explain errors' as initial reference, check logs to validate and make up your own mind, compile actionable feedback (yourself), and loop back to Step 3.\n\n### Step 6: Restore Holdout\n```bash\npython scripts/restore_holdout.py\ngit add scenarios/ Makefile\ngit commit -m \"factory: restore holdout scenarios for evaluation\"\n```\n\n### Step 7: Gate 1 \u2014 Deterministic Validation\n```bash\nmake lint && make typecheck && make test\n```\n\n\"test\" = *should be* the FULL pytest suite, including any tests Codex wrote (already reviewed in Gate 0).\n\n**If fail**: Compile feedback (use this script as aid, but make sure you intervene if the feedback doesn't make sense: `python scripts/compile_feedback.py --iteration N`), loop to Step 3.\n\n### Step 8: Gate 2 \u2014 Non-Functional Requirements\n```bash\nmake nfr-check\n```\n\nThis runs all implemented NFR checks (code quality, complexity, dead code, security).\n\nGate 2 is **non-blocking** but findings are tracked and feed into:\n- The feedback for the next Codex iteration\n- Your LLM-as-judge evaluation in Step 10\n\n### Step 9: Gate 3 \u2014 Behavioral Scenarios\n```bash\npython scripts/run_scenarios.py --timeout 180\n```\n\nProduces `artifacts/factory/scenario_results.json` with satisfaction score.\n\n### Step 10: LLM-as-Judge \u2014 Holistic Evaluation\n\nYou ARE the judge. Don't just check `satisfaction_score >= threshold`. Reason through:\n\n1. **Satisfaction trajectory**: Is the score improving across iterations? Plateaued? Regressing?\n2. **Failure patterns**: Are the same scenarios failing repeatedly? Different ones each time?\n3. **Fix quality**: Do Codex's changes look like real solutions or gaming attempts? (Gate 0 caught the obvious ones, but look for subtle patterns across iterations)\n4. **Gate 2 NFR findings**: Even though non-blocking, are there concerning patterns? Growing complexity? Dropping coverage?\n5. **Systemic issues**: Is there something the score doesn't capture? An architectural problem that will cause future failures?\n6. **Documentation currency**: Did this iteration's changes affect documented behavior? Check: Are specs in `/specs/` still accurate? Does the README reflect current state? Are factory docs (`dark_factory.md`, `code_quality_standards.md`) still correct? Stale documentation is technical debt \u2014 flag it in feedback if needed.\n\n**If satisfied**: Proceed to Step 11.\n**If not satisfied**: Compile feedback with your holistic assessment, loop to Step 3.\n\n### Step 11: Create PR (Accept/Merge Gate)\n```bash\ngh pr create \\\n  --title \"[Factory] df-crank-vXX converged at {score}%\" \\\n  --body \"$(cat <<'EOF'\n## Dark Factory \u2014 Converged\n\n**Satisfaction score: {score}%**\n**Iterations: {N}**\n**Gate 2 NFR status: {summary}**\n\n### Accept/Merge Gate\nThis PR was produced by the dark factory convergence loop, orchestrated by Claude Code.\n\n**Before merging, verify:**\n- [ ] Satisfaction score meets your quality bar\n- [ ] Review latest feedback for residual warnings\n- [ ] Gate 2 NFR findings are acceptable\n- [ ] No unexpected files or dependencies introduced\n\n**To merge:** Approve and merge. The factory branch can then be deleted.\n**To reject:** Close this PR and either adjust scenarios/specs or trigger another crank.\nEOF\n)\" \\\n  --label factory-converged --label accept-merge-gate\n```\n\n### Step 12: Generate PR Review Pack\n\nAfter creating the PR, invoke the `/pr-review-pack` skill to generate the interactive HTML review pack. This is how the human project lead reviews the factory's output \u2014 they review the report, not the code.\n\nThe review pack gives the project lead:\n- Architecture diagram showing which zones were touched\n- Adversarial findings (from Gate 0 agent team) graded by file\n- CI performance with health classification\n- Key decisions with zone-level traceability\n- Convergence result (gate-by-gate status)\n- Post-merge items with code snippets and failure/success scenarios\n- Factory history (iteration timeline, gate findings per iteration)\n\n```\n/pr-review-pack {PR_NUMBER}\n```\n\nThe review pack is the artifact that communicates factory status to the human. Without it, the accept/merge gate is a rubber stamp.\n\n### Step 13: Post-Merge Persistence\n\nAfter the project lead merges the PR:\n\n1. **Persist decisions** to the cumulative log:\n   ```bash\n   python scripts/persist_decisions.py --pr {PR_NUMBER}\n   ```\n   The script extracts decisions from the review pack HTML (or from the JSON intermediate if available via `--data`) and appends them to `docs/decisions/decision_log.json`. It is idempotent \u2014 safe to run multiple times.\n\n2. **Create post-merge issues** (if applicable):\n   ```bash\n   python scripts/create_postmerge_issues.py --pr {PR_NUMBER}\n   ```\n\n3. **Commit and push** the updated decision log:\n   ```bash\n   git add docs/decisions/decision_log.json\n   git commit -m \"decisions: persist PR #{PR_NUMBER} decisions\"\n   git push\n   ```\n\n4. **Delete Codex's remote branch** (cleanup):\n   ```bash\n   git push origin --delete codex-{branch}\n   ```\n\n### Stall Protocol\n\nIf after 3+ iterations:\n- Same scenario fails with same error \u2192 the spec or scenario may need adjustment. Escalate to the project lead.\n- Score oscillates without converging \u2192 architectural issue. Escalate.\n- Gate 0 keeps finding critical issues \u2192 attractor needs stronger constraints. Update `factory_fix.md`.\n\n## Reference Files\n\n- **Attractor prompt**: `.github/codex/prompts/factory_fix.md`\n- **Adversarial review**: `.github/codex/prompts/adversarial_review.md`\n- **Code quality standards**: `docs/code_quality_standards.md`\n- **NFR checks script**: `scripts/nfr_checks.py` (Gate 0 tool agents + Gate 2)\n- **Test quality scanner**: `scripts/check_test_quality.py` (Gate 0 tool agent)\n- **PR review pack skill**: `.claude/skills/pr-review-pack/SKILL.md` (Step 12)\n- **Decision log**: `docs/decisions/decision_log.json` (Step 13, cumulative archive)\n- **Decision persistence**: `scripts/persist_decisions.py` (Step 13)\n- **Specs**: `specs/*.md`\n- **Factory docs**: `docs/dark_factory.md`\n- **Factory architecture**: `docs/factory_architecture.html`\n\n## Operational Knowledge\n\n### Layered Defense Against Gaming\nThe factory's quality defense is layered \u2014 no single gate is sufficient:\n1. **Gate 0 tool agents** (agent team, parallel) \u2014 deterministic checks via vulture, radon, bandit, ruff, and `check_test_quality.py`. Catches dead code, complexity, security issues, lint violations, and obvious vacuous test patterns. Fast, cheap, runs in seconds. Risk: regex/AST-level analysis can be fooled by sophisticated gaming.\n2. **Gate 0 adversarial reviewer** (agent team, parallel with tool agents) \u2014 LLM-based judgment catches subtle gaming, architectural dishonesty, spec violations, and patterns the static tools miss. Reads the full diff against code quality standards and specs.\n3. **Gate 3 holdout scenarios** \u2014 behavioral evaluation against criteria the attractor never sees (ground truth). If the code actually works, gaming doesn't matter.\n\nThe tool agents and semantic reviewer run in parallel at Gate 0 as an agent team. Any CRITICAL finding from any agent stops the pipeline before merge. No single layer is sufficient. Tool agents catch the cheap stuff fast, the adversarial reviewer catches the clever stuff, and holdout scenarios verify actual behavior.\n\n### Iteration \u2192 Commit Model\nEach factory iteration produces ONE commit from Codex (via merge). This provides a clean diff for adversarial review and clear rollback boundaries. The commit message must include the iteration number for traceability.\n\n### CI vs. Orchestrator Roles\nCI (factory.yaml) runs validation-only on every push \u2014 Gates 1, 2, 3 + feedback compilation. CI does NOT drive the convergence loop. Claude Code drives the loop via this skill. CI results are INPUT to orchestration decisions, not orchestration themselves.\n\n**Current CI structure:**\n- `factory-self-test (push)` \u2014 factory script validation\n- `factory-self-test (PR)` \u2014 PR-specific factory validation\n- `factory-loop` \u2014 fallback convergence via Codex API (only with OPENAI_API_KEY)\n- `validate (push)` \u2014 product code validation\n- `validate (PR)` \u2014 PR-specific product validation\n\n**Future consolidation note:** Once the factory runs regularly, `factory-loop` and `validate` could be consolidated into a single workflow with better separation. Current overlap provides coverage redundancy during proof-of-concept.\n\n### NFR Gate Architecture\nGate 2 runs deterministic tool-based checks. Each check follows the pattern:\n1. Run external tool (ruff, radon, vulture, bandit)\n2. Parse output (JSON preferred, text fallback)\n3. Map findings to severity (CRITICAL/WARNING/NIT/INFO)\n4. Return structured findings\n\nAdding a new check: write `check_<name>(repo_root: Path) -> list[NFRFinding]`, register in `NFR_CHECKS` dict. The factory picks it up automatically.\n\n**Important:** All JSON parsing must include fallback handling for decode errors. Silent `pass` on JSONDecodeError hides tool failures \u2014 always emit at least a WARNING finding.\n\n### Gate 2 and LLM-Based Review\nGate 2 should stay deterministic (tool-based). LLM-based review belongs in Gate 0 (adversarial review) and Step 10 (LLM-as-judge). Mixing deterministic and non-deterministic findings in the same gate creates confusion about what's reliable vs. advisory. If LLM-based checks are added, label findings as \"advisory\" and never let them block convergence alone.\n\n### Holdout Stripping Scope\n`strip_holdout.py` removes `/scenarios/` and Makefile scenario targets. It also strips review pack artifacts (`docs/pr_review_pack.html`, `docs/pr_diff_data.json`) \u2014 the attractor has no business seeing adversarial review findings from previous iterations. The attractor's information boundary is: specs + feedback + its own code. Nothing else.\n\n### Git Hooks vs. CI Enforcement\n`.githooks/pre-commit` runs ruff + mypy on staged Python files \u2014 a local speed bump. It is NOT enforced on clean clone; developers must run `make install-hooks`. CI is the enforcement layer. The hook catches issues before they hit CI, saving iteration time. Both exist because they serve different failure modes.\n",
      "base": "---\nname: factory-orchestrate\ndescription: Run the dark factory convergence loop. Use when the user says \"run a factory crank\", \"start the factory\", \"orchestrate a crank\", or similar. Orchestrates Codex via browser, manages holdout isolation, runs validation gates, and performs LLM-as-judge evaluation.\nallowed-tools: Bash, Read, Write, Glob, Grep, Edit\n---\n\n# Dark Factory Orchestration \u2014 Claude Code as Orchestrator\n\nYou are the factory orchestrator. You run the convergence loop that turns specs into working software through iterative AI coding + validation.\n\n## Prerequisites\n\n- Chrome is logged into Codex (ChatGPT Plus account)\n- Repository: `joeyfezster/building_ai_w_ai`\n- Branch to base work on: confirm with user or default to `factory/v1`\n- Satisfaction threshold: confirm with user or default to 80%\n- Max iterations: confirm with user or default to 5\n\n## The Loop\n\nFor each iteration:\n\n### Step 1: Create Factory Branch\n```bash\n# First crank \u2014 create from base branch\ngit checkout -b df-crank-v01-{descriptor} {base_branch}\ngit push -u origin df-crank-v01-{descriptor}\n```\n\nBranch naming: `df-crank-vXX-{descriptor}` where XX is the crank version.\n\n### Step 2: Strip Holdout\n```bash\npython scripts/strip_holdout.py\ngit push\n```\n\nThis deterministically removes `/scenarios/` and comments out scenario Makefile targets. Codex literally cannot see evaluation criteria.\n\nVerify: `ls scenarios/` should fail (directory gone).\n\n### Step 3: Invoke Codex via Browser\n\nOpen the Codex UI in Chrome. Provide:\n- **Repository**: `joeyfezster/building_ai_w_ai`\n- **Base branch**: `df-crank-vXX-{descriptor}` (the stripped branch)\n- **Prompt**: Contents of `.github/codex/prompts/factory_fix.md` + the latest feedback file (`artifacts/factory/feedback_iter_N.md`)\n- **Versions**: 1\n\nCodex will create its own branch (named `codex-...`). Wait for it to finish.\n\n### Step 4: Gate 0 \u2014 Adversarial Code Review (Agent Team)\n\nBefore merging Codex's changes, run a **full adversarial review via agent teams**. This is the first line of defense \u2014 there is no point sending code to CI or later gates if Gate 0 finds critical issues.\n\n1. Fetch Codex's branch: `git fetch origin`\n2. Get the diff: `git diff df-crank-vXX...origin/codex-{branch}`\n\n3. **Spawn the Gate 0 agent team.** Create a team and launch these agents in parallel:\n\n   **Tool agents** (deterministic, Bash-capable \u2014 run ALL simultaneously):\n   | Agent | What It Runs | What It Catches |\n   |-------|-------------|-----------------|\n   | `ruff-agent` | `python scripts/nfr_checks.py --check code_quality` | Lint violations, style, import issues |\n   | `radon-agent` | `python scripts/nfr_checks.py --check complexity` | Cyclomatic complexity > threshold |\n   | `vulture-agent` | `python scripts/nfr_checks.py --check dead_code` | Unreachable code, unused functions |\n   | `bandit-agent` | `python scripts/nfr_checks.py --check security` | Security vulnerabilities |\n   | `test-quality-agent` | `python scripts/check_test_quality.py` | Vacuous tests, stub assertions, mock abuse |\n\n   **Semantic reviewer** (LLM-based, runs in parallel with tool agents):\n   | Agent | What It Reads | What It Catches |\n   |-------|--------------|-----------------|\n   | `adversarial-reviewer` | The diff + `.github/codex/prompts/adversarial_review.md` + `docs/code_quality_standards.md` + `/specs/*.md` | Gaming, architectural dishonesty, spec violations, integration gaps, subtle patterns the tools miss |\n\n4. **Aggregate findings.** Collect all agent outputs. Each finding has a severity: CRITICAL, WARNING, or NIT.\n\n5. **Fail-fast rule:** If **any agent** reports a CRITICAL finding, Gate 0 fails. Do NOT merge. Compile all findings (from all agents) as feedback and loop back to Step 3 with specific remediation instructions.\n\n**If clean or WARNING-only across all agents**: Proceed to Step 5. WARNING findings are tracked \u2014 they feed into the LLM-as-judge evaluation in Step 10.\n\n**Why agent teams, not a single reviewer:** The tool agents catch cheap, obvious violations in seconds (dead code, complexity, security). The semantic reviewer catches subtle gaming and architectural dishonesty. Running them in parallel means Gate 0 is both fast AND thorough. A single reviewer doing everything sequentially is slower and more likely to miss things.\n\n### Step 5: Merge Codex Changes\n```bash\ngit merge origin/codex-{branch} --no-ff -m \"factory: merge codex iteration N\"\n```\n\n### Step 5b: Check CI Results\n\nAfter pushing, check CI results. CI runs Gates 1-3 on every push to factory/** branches. Use CI results as early signal before running gates locally.\n\n```bash\n# Wait for CI to complete (typically 2-5 minutes)\ngh run list --branch df-crank-vXX --limit 3\n\n# Check the PR's checks (if PR exists)\ngh pr checks <PR_NUMBER>\n```\n\n**Known `gh pr checks` behavior:**\n- `gh pr checks` shows checks associated with the PR's **merge ref**, not the branch HEAD directly\n- If a bot (GITHUB_TOKEN) pushes a commit that becomes PR HEAD, GitHub does NOT re-trigger CI workflows (prevents infinite loops). The PR may show \"0 checks\" even though CI ran fine on the previous commit.\n- Workaround: If you see stale/missing checks, use `gh run list --branch <branch>` instead \u2014 this shows actual workflow runs regardless of the merge ref.\n- Commits pushed by workflows using `GITHUB_TOKEN` do not trigger other workflows. This is a GitHub safety measure.\n- If CI results conflict with your local gate results, investigate \u2014 don't just ignore the discrepancy.\n\n**If CI fails**: Use the github.com's copilot's 'explain errors' as initial reference, check logs to validate and make up your own mind, compile actionable feedback (yourself), and loop back to Step 3.\n\n### Step 6: Restore Holdout\n```bash\npython scripts/restore_holdout.py\ngit add scenarios/ Makefile\ngit commit -m \"factory: restore holdout scenarios for evaluation\"\n```\n\n### Step 7: Gate 1 \u2014 Deterministic Validation\n```bash\nmake lint && make typecheck && make test\n```\n\n\"test\" = *should be* the FULL pytest suite, including any tests Codex wrote (already reviewed in Gate 0).\n\n**If fail**: Compile feedback (use this script as aid, but make sure you intervene if the feedback doesn't make sense: `python scripts/compile_feedback.py --iteration N`), loop to Step 3.\n\n### Step 8: Gate 2 \u2014 Non-Functional Requirements\n```bash\nmake nfr-check\n```\n\nThis runs all implemented NFR checks (code quality, complexity, dead code, security).\n\nGate 2 is **non-blocking** but findings are tracked and feed into:\n- The feedback for the next Codex iteration\n- Your LLM-as-judge evaluation in Step 10\n\n### Step 9: Gate 3 \u2014 Behavioral Scenarios\n```bash\npython scripts/run_scenarios.py --timeout 180\n```\n\nProduces `artifacts/factory/scenario_results.json` with satisfaction score.\n\n### Step 10: LLM-as-Judge \u2014 Holistic Evaluation\n\nYou ARE the judge. Don't just check `satisfaction_score >= threshold`. Reason through:\n\n1. **Satisfaction trajectory**: Is the score improving across iterations? Plateaued? Regressing?\n2. **Failure patterns**: Are the same scenarios failing repeatedly? Different ones each time?\n3. **Fix quality**: Do Codex's changes look like real solutions or gaming attempts? (Gate 0 caught the obvious ones, but look for subtle patterns across iterations)\n4. **Gate 2 NFR findings**: Even though non-blocking, are there concerning patterns? Growing complexity? Dropping coverage?\n5. **Systemic issues**: Is there something the score doesn't capture? An architectural problem that will cause future failures?\n6. **Documentation currency**: Did this iteration's changes affect documented behavior? Check: Are specs in `/specs/` still accurate? Does the README reflect current state? Are factory docs (`dark_factory.md`, `code_quality_standards.md`) still correct? Stale documentation is technical debt \u2014 flag it in feedback if needed.\n\n**If satisfied**: Proceed to Step 11.\n**If not satisfied**: Compile feedback with your holistic assessment, loop to Step 3.\n\n### Step 11: Create PR (Accept/Merge Gate)\n```bash\ngh pr create \\\n  --title \"[Factory] df-crank-vXX converged at {score}%\" \\\n  --body \"$(cat <<'EOF'\n## Dark Factory \u2014 Converged\n\n**Satisfaction score: {score}%**\n**Iterations: {N}**\n**Gate 2 NFR status: {summary}**\n\n### Accept/Merge Gate\nThis PR was produced by the dark factory convergence loop, orchestrated by Claude Code.\n\n**Before merging, verify:**\n- [ ] Satisfaction score meets your quality bar\n- [ ] Review latest feedback for residual warnings\n- [ ] Gate 2 NFR findings are acceptable\n- [ ] No unexpected files or dependencies introduced\n\n**To merge:** Approve and merge. The factory branch can then be deleted.\n**To reject:** Close this PR and either adjust scenarios/specs or trigger another crank.\nEOF\n)\" \\\n  --label factory-converged --label accept-merge-gate\n```\n\n### Step 12: Generate PR Review Pack\n\nAfter creating the PR, invoke the `/pr-review-pack` skill to generate the interactive HTML review pack. This is how the human project lead reviews the factory's output \u2014 they review the report, not the code.\n\nThe review pack gives the project lead:\n- Architecture diagram showing which zones were touched\n- Adversarial findings (from Gate 0 agent team) graded by file\n- CI performance with health classification\n- Key decisions with zone-level traceability\n- Convergence result (gate-by-gate status)\n- Post-merge items with code snippets and failure/success scenarios\n- Factory history (iteration timeline, gate findings per iteration)\n\n```\n/pr-review-pack {PR_NUMBER}\n```\n\nThe review pack is the artifact that communicates factory status to the human. Without it, the accept/merge gate is a rubber stamp.\n\n### Stall Protocol\n\nIf after 3+ iterations:\n- Same scenario fails with same error \u2192 the spec or scenario may need adjustment. Escalate to the project lead.\n- Score oscillates without converging \u2192 architectural issue. Escalate.\n- Gate 0 keeps finding critical issues \u2192 attractor needs stronger constraints. Update `factory_fix.md`.\n\n## Reference Files\n\n- **Attractor prompt**: `.github/codex/prompts/factory_fix.md`\n- **Adversarial review**: `.github/codex/prompts/adversarial_review.md`\n- **Code quality standards**: `docs/code_quality_standards.md`\n- **NFR checks script**: `scripts/nfr_checks.py` (Gate 0 tool agents + Gate 2)\n- **Test quality scanner**: `scripts/check_test_quality.py` (Gate 0 tool agent)\n- **PR review pack skill**: `.claude/skills/pr-review-pack/SKILL.md` (Step 12)\n- **Specs**: `specs/*.md`\n- **Factory docs**: `docs/dark_factory.md`\n- **Factory architecture**: `docs/factory_architecture.html`\n\n## Operational Knowledge\n\n### Layered Defense Against Gaming\nThe factory's quality defense is layered \u2014 no single gate is sufficient:\n1. **Gate 0 tool agents** (agent team, parallel) \u2014 deterministic checks via vulture, radon, bandit, ruff, and `check_test_quality.py`. Catches dead code, complexity, security issues, lint violations, and obvious vacuous test patterns. Fast, cheap, runs in seconds. Risk: regex/AST-level analysis can be fooled by sophisticated gaming.\n2. **Gate 0 adversarial reviewer** (agent team, parallel with tool agents) \u2014 LLM-based judgment catches subtle gaming, architectural dishonesty, spec violations, and patterns the static tools miss. Reads the full diff against code quality standards and specs.\n3. **Gate 3 holdout scenarios** \u2014 behavioral evaluation against criteria the attractor never sees (ground truth). If the code actually works, gaming doesn't matter.\n\nThe tool agents and semantic reviewer run in parallel at Gate 0 as an agent team. Any CRITICAL finding from any agent stops the pipeline before merge. No single layer is sufficient. Tool agents catch the cheap stuff fast, the adversarial reviewer catches the clever stuff, and holdout scenarios verify actual behavior.\n\n### Iteration \u2192 Commit Model\nEach factory iteration produces ONE commit from Codex (via merge). This provides a clean diff for adversarial review and clear rollback boundaries. The commit message must include the iteration number for traceability.\n\n### CI vs. Orchestrator Roles\nCI (factory.yaml) runs validation-only on every push \u2014 Gates 1, 2, 3 + feedback compilation. CI does NOT drive the convergence loop. Claude Code drives the loop via this skill. CI results are INPUT to orchestration decisions, not orchestration themselves.\n\n**Current CI structure:**\n- `factory-self-test (push)` \u2014 factory script validation\n- `factory-self-test (PR)` \u2014 PR-specific factory validation\n- `factory-loop` \u2014 fallback convergence via Codex API (only with OPENAI_API_KEY)\n- `validate (push)` \u2014 product code validation\n- `validate (PR)` \u2014 PR-specific product validation\n\n**Future consolidation note:** Once the factory runs regularly, `factory-loop` and `validate` could be consolidated into a single workflow with better separation. Current overlap provides coverage redundancy during proof-of-concept.\n\n### NFR Gate Architecture\nGate 2 runs deterministic tool-based checks. Each check follows the pattern:\n1. Run external tool (ruff, radon, vulture, bandit)\n2. Parse output (JSON preferred, text fallback)\n3. Map findings to severity (CRITICAL/WARNING/NIT/INFO)\n4. Return structured findings\n\nAdding a new check: write `check_<name>(repo_root: Path) -> list[NFRFinding]`, register in `NFR_CHECKS` dict. The factory picks it up automatically.\n\n**Important:** All JSON parsing must include fallback handling for decode errors. Silent `pass` on JSONDecodeError hides tool failures \u2014 always emit at least a WARNING finding.\n\n### Gate 2 and LLM-Based Review\nGate 2 should stay deterministic (tool-based). LLM-based review belongs in Gate 0 (adversarial review) and Step 10 (LLM-as-judge). Mixing deterministic and non-deterministic findings in the same gate creates confusion about what's reliable vs. advisory. If LLM-based checks are added, label findings as \"advisory\" and never let them block convergence alone.\n\n### Holdout Stripping Scope\n`strip_holdout.py` removes `/scenarios/` and Makefile scenario targets. It also strips review pack artifacts (`docs/pr_review_pack.html`, `docs/pr_diff_data.json`) \u2014 the attractor has no business seeing adversarial review findings from previous iterations. The attractor's information boundary is: specs + feedback + its own code. Nothing else.\n\n### Git Hooks vs. CI Enforcement\n`.githooks/pre-commit` runs ruff + mypy on staged Python files \u2014 a local speed bump. It is NOT enforced on clean clone; developers must run `make install-hooks`. CI is the enforcement layer. The hook catches issues before they hit CI, saving iteration time. Both exist because they serve different failure modes.\n"
    },
    ".github/codex/prompts/factory_fix.md": {
      "additions": 10,
      "deletions": 2,
      "status": "modified",
      "binary": false,
      "diff": "diff --git a/.github/codex/prompts/factory_fix.md b/.github/codex/prompts/factory_fix.md\nindex 09fe049..bfc656a 100644\n--- a/.github/codex/prompts/factory_fix.md\n+++ b/.github/codex/prompts/factory_fix.md\n@@ -15,8 +15,17 @@ Read the component specifications in `/specs/` to understand what the system sho\n Read the feedback file for this iteration to understand what's broken:\n - `artifacts/factory/feedback_iter_*.md` \u2014 latest feedback with full error output\n \n+Read the decision log for architectural context from previous cranks:\n+- `docs/decisions/decision_log.json` \u2014 cumulative log of accepted architectural decisions\n+- These decisions were reviewed and approved by the project lead. Follow them unless specs or feedback explicitly contradict them.\n+\n ## Your Constraints\n \n+**NEVER modify or delete these files** (read-only context for you):\n+- `/specs/` \u2014 your requirements, read them\n+- `/docs/decisions/` \u2014 decision log, read for architectural context\n+- `/agents/` \u2014 pre-factory reference\n+\n **NEVER read, modify, or delete these files:**\n - Anything in `/scenarios/` (you should not even see this directory)\n - `/scripts/run_scenarios.py`\n@@ -24,12 +33,11 @@ Read the feedback file for this iteration to understand what's broken:\n - `/.github/workflows/factory.yaml`\n - `/.github/codex/prompts/factory_fix.md` (this file)\n - `/CLAUDE.md`\n-- `/specs/` (read-only \u2014 these are your requirements)\n-- `/agents/` (pre-factory reference, not product code)\n - `/scripts/strip_holdout.py` (holdout isolation gate)\n - `/scripts/restore_holdout.py` (holdout restoration)\n - `/scripts/nfr_checks.py` (Gate 2 NFR checker)\n - `/scripts/check_test_quality.py` (anti-vacuous scanner)\n+- `/scripts/persist_decisions.py` (decision persistence script)\n \n **DO modify** source code in:\n - `src/` \u2014 all Python source\n",
      "raw": "# Factory Fix \u2014 Codex Prompt Template\n\nYou are the coding agent (Attractor) in a dark factory convergence loop. Your job is to fix failures identified by the factory's validation system.\n\n## Your Context\n\nRead the component specifications in `/specs/` to understand what the system should do:\n- `specs/system.md` \u2014 overall system architecture\n- `specs/env.md` \u2014 MiniPong environment requirements\n- `specs/rl.md` \u2014 DQN algorithm requirements\n- `specs/training.md` \u2014 training pipeline requirements\n- `specs/dashboard.md` \u2014 dashboard requirements\n- `specs/proof.md` \u2014 learning proof and video proof requirements\n\nRead the feedback file for this iteration to understand what's broken:\n- `artifacts/factory/feedback_iter_*.md` \u2014 latest feedback with full error output\n\nRead the decision log for architectural context from previous cranks:\n- `docs/decisions/decision_log.json` \u2014 cumulative log of accepted architectural decisions\n- These decisions were reviewed and approved by the project lead. Follow them unless specs or feedback explicitly contradict them.\n\n## Your Constraints\n\n**NEVER modify or delete these files** (read-only context for you):\n- `/specs/` \u2014 your requirements, read them\n- `/docs/decisions/` \u2014 decision log, read for architectural context\n- `/agents/` \u2014 pre-factory reference\n\n**NEVER read, modify, or delete these files:**\n- Anything in `/scenarios/` (you should not even see this directory)\n- `/scripts/run_scenarios.py`\n- `/scripts/compile_feedback.py`\n- `/.github/workflows/factory.yaml`\n- `/.github/codex/prompts/factory_fix.md` (this file)\n- `/CLAUDE.md`\n- `/scripts/strip_holdout.py` (holdout isolation gate)\n- `/scripts/restore_holdout.py` (holdout restoration)\n- `/scripts/nfr_checks.py` (Gate 2 NFR checker)\n- `/scripts/check_test_quality.py` (anti-vacuous scanner)\n- `/scripts/persist_decisions.py` (decision persistence script)\n\n**DO modify** source code in:\n- `src/` \u2014 all Python source\n- `tests/` \u2014 test files\n- `configs/` \u2014 configuration files\n- `Makefile` \u2014 build targets\n- `requirements.in` / `requirements-dev.in` \u2014 dependencies\n- `infra/docker/` \u2014 Dockerfiles\n- `pyproject.toml` \u2014 project configuration\n\n## Validation Guidelines\n\nBefore considering any change complete, ensure:\n\n### Hard Constraints\n- No proprietary ROM dependencies \u2014 MiniPong is self-contained\n- Policy consumes pixels only (84\u00d784 uint8 observations)\n- `make validate` must pass (lint + typecheck + test + docker + env-smoke)\n- `make verify-learning` must pass for any training-related change\n\n### Definition of Done\n- Functional requirements from `/specs/` are implemented\n- Architectural consistency maintained (no ad-hoc patterns)\n- Integration checks pass end-to-end\n- Required artifacts generated and linked (checkpoints, metrics, videos)\n\n### Quality Checklist\n- [ ] `make lint` passes (ruff check)\n- [ ] `make typecheck` passes (mypy src)\n- [ ] `make test` passes (pytest)\n- [ ] No new dead imports or unused code introduced\n- [ ] Changes are minimal and surgical \u2014 fix what's broken, don't refactor\n\n## Anti-Gaming Rules\n\nYou are evaluated by an external holdout system you cannot see. These rules exist because the factory has adversarial review \u2014 attempts to game the system will be caught and will waste iterations.\n\n### Tests Must Be Real\n- **No vacuous tests.** Every test must exercise real behavior through real code paths. A test that passes by construction proves nothing.\n- **No mocking the system under test.** Mocks are for isolating external dependencies (network, filesystem, third-party APIs) \u2014 never for bypassing the logic you're supposed to be testing.\n- **No stub implementations.** Functions must contain real logic, not `return True`, `return 0`, `pass`, or hardcoded lookup tables that happen to match test cases.\n- **No patching away the thing being tested.** If a test patches the function it claims to test, it tests nothing.\n\n### Implementations Must Be General\n- **No hardcoded special cases** that coincidentally pass known test inputs. Example: `is_prime(x): return x in {2, 3, 5, 7, 11, 13}` is not a prime checker.\n- **No output-matching shortcuts.** If a function is supposed to compute something, it must actually compute it \u2014 not return a cached/hardcoded result.\n- **No overfitting to error messages.** If a scenario fails with a specific assertion, fix the root cause \u2014 don't just make that specific assertion pass while breaking the general case.\n\n### Integration Must Be Honest\n- If a test file requires imports from `src/`, those imports must exercise the real module, not a local redefinition.\n- Configuration files must reflect actual runtime parameters, not test-only shortcuts.\n- Docker builds must include all real dependencies \u2014 don't skip packages to speed up builds if the code needs them at runtime.\n\n## Your Approach\n\n1. Read the latest feedback file to understand all failures\n2. Read the relevant specs to understand expected behavior\n3. Fix failures in priority order:\n   - Import errors and missing modules first\n   - File/artifact production issues next\n   - Behavioral correctness last\n4. Validate locally: run `make lint && make typecheck` before finishing\n5. Do NOT add new test files that duplicate scenario evaluation logic\n6. Do NOT refactor code that isn't related to the current failures\n\n## Success Criteria\n\nThe factory will re-run validation after your changes. Your goal is to increase the satisfaction score (fraction of scenarios passing). Aim for convergence, not perfection in a single iteration.\n",
      "base": "# Factory Fix \u2014 Codex Prompt Template\n\nYou are the coding agent (Attractor) in a dark factory convergence loop. Your job is to fix failures identified by the factory's validation system.\n\n## Your Context\n\nRead the component specifications in `/specs/` to understand what the system should do:\n- `specs/system.md` \u2014 overall system architecture\n- `specs/env.md` \u2014 MiniPong environment requirements\n- `specs/rl.md` \u2014 DQN algorithm requirements\n- `specs/training.md` \u2014 training pipeline requirements\n- `specs/dashboard.md` \u2014 dashboard requirements\n- `specs/proof.md` \u2014 learning proof and video proof requirements\n\nRead the feedback file for this iteration to understand what's broken:\n- `artifacts/factory/feedback_iter_*.md` \u2014 latest feedback with full error output\n\n## Your Constraints\n\n**NEVER read, modify, or delete these files:**\n- Anything in `/scenarios/` (you should not even see this directory)\n- `/scripts/run_scenarios.py`\n- `/scripts/compile_feedback.py`\n- `/.github/workflows/factory.yaml`\n- `/.github/codex/prompts/factory_fix.md` (this file)\n- `/CLAUDE.md`\n- `/specs/` (read-only \u2014 these are your requirements)\n- `/agents/` (pre-factory reference, not product code)\n- `/scripts/strip_holdout.py` (holdout isolation gate)\n- `/scripts/restore_holdout.py` (holdout restoration)\n- `/scripts/nfr_checks.py` (Gate 2 NFR checker)\n- `/scripts/check_test_quality.py` (anti-vacuous scanner)\n\n**DO modify** source code in:\n- `src/` \u2014 all Python source\n- `tests/` \u2014 test files\n- `configs/` \u2014 configuration files\n- `Makefile` \u2014 build targets\n- `requirements.in` / `requirements-dev.in` \u2014 dependencies\n- `infra/docker/` \u2014 Dockerfiles\n- `pyproject.toml` \u2014 project configuration\n\n## Validation Guidelines\n\nBefore considering any change complete, ensure:\n\n### Hard Constraints\n- No proprietary ROM dependencies \u2014 MiniPong is self-contained\n- Policy consumes pixels only (84\u00d784 uint8 observations)\n- `make validate` must pass (lint + typecheck + test + docker + env-smoke)\n- `make verify-learning` must pass for any training-related change\n\n### Definition of Done\n- Functional requirements from `/specs/` are implemented\n- Architectural consistency maintained (no ad-hoc patterns)\n- Integration checks pass end-to-end\n- Required artifacts generated and linked (checkpoints, metrics, videos)\n\n### Quality Checklist\n- [ ] `make lint` passes (ruff check)\n- [ ] `make typecheck` passes (mypy src)\n- [ ] `make test` passes (pytest)\n- [ ] No new dead imports or unused code introduced\n- [ ] Changes are minimal and surgical \u2014 fix what's broken, don't refactor\n\n## Anti-Gaming Rules\n\nYou are evaluated by an external holdout system you cannot see. These rules exist because the factory has adversarial review \u2014 attempts to game the system will be caught and will waste iterations.\n\n### Tests Must Be Real\n- **No vacuous tests.** Every test must exercise real behavior through real code paths. A test that passes by construction proves nothing.\n- **No mocking the system under test.** Mocks are for isolating external dependencies (network, filesystem, third-party APIs) \u2014 never for bypassing the logic you're supposed to be testing.\n- **No stub implementations.** Functions must contain real logic, not `return True`, `return 0`, `pass`, or hardcoded lookup tables that happen to match test cases.\n- **No patching away the thing being tested.** If a test patches the function it claims to test, it tests nothing.\n\n### Implementations Must Be General\n- **No hardcoded special cases** that coincidentally pass known test inputs. Example: `is_prime(x): return x in {2, 3, 5, 7, 11, 13}` is not a prime checker.\n- **No output-matching shortcuts.** If a function is supposed to compute something, it must actually compute it \u2014 not return a cached/hardcoded result.\n- **No overfitting to error messages.** If a scenario fails with a specific assertion, fix the root cause \u2014 don't just make that specific assertion pass while breaking the general case.\n\n### Integration Must Be Honest\n- If a test file requires imports from `src/`, those imports must exercise the real module, not a local redefinition.\n- Configuration files must reflect actual runtime parameters, not test-only shortcuts.\n- Docker builds must include all real dependencies \u2014 don't skip packages to speed up builds if the code needs them at runtime.\n\n## Your Approach\n\n1. Read the latest feedback file to understand all failures\n2. Read the relevant specs to understand expected behavior\n3. Fix failures in priority order:\n   - Import errors and missing modules first\n   - File/artifact production issues next\n   - Behavioral correctness last\n4. Validate locally: run `make lint && make typecheck` before finishing\n5. Do NOT add new test files that duplicate scenario evaluation logic\n6. Do NOT refactor code that isn't related to the current failures\n\n## Success Criteria\n\nThe factory will re-run validation after your changes. Your goal is to increase the satisfaction score (fraction of scenarios passing). Aim for convergence, not perfection in a single iteration.\n"
    },
    "CLAUDE.md": {
      "additions": 3,
      "deletions": 0,
      "status": "modified",
      "binary": false,
      "diff": "diff --git a/CLAUDE.md b/CLAUDE.md\nindex 8c21981..83b26be 100644\n--- a/CLAUDE.md\n+++ b/CLAUDE.md\n@@ -42,6 +42,8 @@ The following files are **never touched by the Attractor (Codex)**. They are fac\n - `/scripts/check_test_quality.py` \u2014 Gate 0 test quality scanner\n - `/.github/codex/prompts/adversarial_review.md` \u2014 Gate 0 adversarial review checklist\n - `/docs/code_quality_standards.md` \u2014 universal quality standards\n+- `/docs/decisions/` \u2014 cumulative decision log (Codex reads but never modifies)\n+- `/scripts/persist_decisions.py` \u2014 decision persistence script\n - `/CLAUDE.md` \u2014 this file\n \n ## Code Quality Standards\n@@ -64,6 +66,7 @@ make compile-feedback      # compile validation results into feedback markdown\n make nfr-check             # run Gate 2 NFR checks (code quality, complexity, dead code, security)\n make factory-local         # run one factory iteration locally (Gate 1 \u2192 Gate 2 \u2192 Gate 3 \u2192 feedback)\n make factory-status        # show current iteration count and satisfaction score\n+make persist-decisions PR=6  # persist PR decisions to cumulative log\n ```\n \n ## Human Decision Log\n",
      "raw": "# MiniPong RL System \u2014 Dark Factory\n\nEnd-to-end proof that a reinforcement learning agent can learn Pong from pixels, built entirely by AI agents orchestrated through a convergence loop.\n\n## First-Time Setup\n\nAfter cloning, run these commands immediately:\n\n```bash\nmake install-hooks    # REQUIRED: sets up git hooks (ruff + mypy on every commit)\nmake deps             # install Python dependencies\n```\n\n`make install-hooks` is non-negotiable \u2014 it's the local quality gate that catches issues before they hit CI. Without it, lint/typecheck failures only surface in CI, wasting iteration time.\n\n## Operating Model\n\nThis repo is built by a **dark factory loop**, not by humans writing code. Code is treated as opaque weights \u2014 correctness is inferred exclusively from externally observable behavior, never from source inspection.\n\nThe loop: **Seed \u2192 Agent \u2192 Validate \u2192 Feedback \u2192 Repeat until satisfied.**\n\n## Source of Truth\n\n- `/specs/` \u2014 Component specifications. This is what the coding agent reads. The specs define what the system should do.\n- `/scenarios/` \u2014 Behavioral holdout evaluation criteria. These are what the system is evaluated against. **Scenarios must NEVER be modified by the coding agent (Codex).** They are the holdout set \u2014 the agent never sees its own evaluation criteria.\n- `/docs/dark_factory.md` \u2014 Full factory documentation: how the loop works, how to trigger it, how to write scenarios, when to escalate.\n\n## Factory-Protected Files\n\nThe following files are **never touched by the Attractor (Codex)**. They are factory infrastructure, not product code. The Codex-facing version of this list lives in `.github/codex/prompts/factory_fix.md` \u2014 keep both in sync when adding protected files.\n\n- `/scenarios/` \u2014 holdout evaluation criteria\n- `/scripts/run_scenarios.py` \u2014 scenario evaluation runner\n- `/scripts/compile_feedback.py` \u2014 feedback compiler\n- `/.github/workflows/factory.yaml` \u2014 factory orchestrator\n- `/.github/codex/prompts/factory_fix.md` \u2014 Codex prompt template\n- `/specs/` \u2014 component specifications (read-only for Codex)\n- `/agents/` \u2014 pre-factory agent definitions (reference only)\n- `/scripts/strip_holdout.py` \u2014 holdout stripping script (isolation gate)\n- `/scripts/restore_holdout.py` \u2014 holdout restoration script\n- `/scripts/nfr_checks.py` \u2014 Gate 2 NFR checker\n- `/scripts/check_test_quality.py` \u2014 Gate 0 test quality scanner\n- `/.github/codex/prompts/adversarial_review.md` \u2014 Gate 0 adversarial review checklist\n- `/docs/code_quality_standards.md` \u2014 universal quality standards\n- `/docs/decisions/` \u2014 cumulative decision log (Codex reads but never modifies)\n- `/scripts/persist_decisions.py` \u2014 decision persistence script\n- `/CLAUDE.md` \u2014 this file\n\n## Code Quality Standards\n\nAll code written in this repository \u2014 by Codex, Claude Code, or humans \u2014 must follow the standards in `docs/code_quality_standards.md`. This includes:\n- Anti-vacuous test rules (no mocking the system under test, no stub assertions)\n- Anti-gaming rules (no hardcoded lookup tables, no overfitting)\n- Implementation honesty (real imports, real configs, real dependencies)\n- Test hygiene and quality gates\n\nThese standards are enforced by Gate 0 (adversarial review), Gate 1 (lint/typecheck/test), Gate 2 (NFR checks), and the LLM-as-judge.\n\n## Quick Commands\n\n```bash\nmake install-hooks         # set up git hooks (ruff + mypy on every commit, no virtualenv needed)\nmake validate              # lint + typecheck + test + docker-build + docker-smoke + env-smoke\nmake run-scenarios         # run holdout scenario evaluation\nmake compile-feedback      # compile validation results into feedback markdown\nmake nfr-check             # run Gate 2 NFR checks (code quality, complexity, dead code, security)\nmake factory-local         # run one factory iteration locally (Gate 1 \u2192 Gate 2 \u2192 Gate 3 \u2192 feedback)\nmake factory-status        # show current iteration count and satisfaction score\nmake persist-decisions PR=6  # persist PR decisions to cumulative log\n```\n\n## Human Decision Log\n\n- `/ProjectLeadAsks.md` \u2014 Open questions and decisions requiring the project lead's input. **Check this file at every session start.** Update it when questions are resolved or new ones arise. This file survives context compaction \u2014 it's the canonical list of what's pending.\n\n## Stack\n\n- Python 3.12, pip-tools for dependency management\n- PyTorch, Gymnasium, NumPy for RL\n- ruff + mypy + pytest for quality\n- GitHub Actions for CI and validation\n- OpenAI Codex as the non-interactive coding agent (attractor)\n- Claude Code as factory orchestrator (skill: `/factory-orchestrate`)\n- PR review pack generator (skill: `/pr-review-pack`) \u2014 `.claude/skills/pr-review-pack/` contains the review pack generation skill with template, scripts, and reference docs\n",
      "base": "# MiniPong RL System \u2014 Dark Factory\n\nEnd-to-end proof that a reinforcement learning agent can learn Pong from pixels, built entirely by AI agents orchestrated through a convergence loop.\n\n## First-Time Setup\n\nAfter cloning, run these commands immediately:\n\n```bash\nmake install-hooks    # REQUIRED: sets up git hooks (ruff + mypy on every commit)\nmake deps             # install Python dependencies\n```\n\n`make install-hooks` is non-negotiable \u2014 it's the local quality gate that catches issues before they hit CI. Without it, lint/typecheck failures only surface in CI, wasting iteration time.\n\n## Operating Model\n\nThis repo is built by a **dark factory loop**, not by humans writing code. Code is treated as opaque weights \u2014 correctness is inferred exclusively from externally observable behavior, never from source inspection.\n\nThe loop: **Seed \u2192 Agent \u2192 Validate \u2192 Feedback \u2192 Repeat until satisfied.**\n\n## Source of Truth\n\n- `/specs/` \u2014 Component specifications. This is what the coding agent reads. The specs define what the system should do.\n- `/scenarios/` \u2014 Behavioral holdout evaluation criteria. These are what the system is evaluated against. **Scenarios must NEVER be modified by the coding agent (Codex).** They are the holdout set \u2014 the agent never sees its own evaluation criteria.\n- `/docs/dark_factory.md` \u2014 Full factory documentation: how the loop works, how to trigger it, how to write scenarios, when to escalate.\n\n## Factory-Protected Files\n\nThe following files are **never touched by the Attractor (Codex)**. They are factory infrastructure, not product code. The Codex-facing version of this list lives in `.github/codex/prompts/factory_fix.md` \u2014 keep both in sync when adding protected files.\n\n- `/scenarios/` \u2014 holdout evaluation criteria\n- `/scripts/run_scenarios.py` \u2014 scenario evaluation runner\n- `/scripts/compile_feedback.py` \u2014 feedback compiler\n- `/.github/workflows/factory.yaml` \u2014 factory orchestrator\n- `/.github/codex/prompts/factory_fix.md` \u2014 Codex prompt template\n- `/specs/` \u2014 component specifications (read-only for Codex)\n- `/agents/` \u2014 pre-factory agent definitions (reference only)\n- `/scripts/strip_holdout.py` \u2014 holdout stripping script (isolation gate)\n- `/scripts/restore_holdout.py` \u2014 holdout restoration script\n- `/scripts/nfr_checks.py` \u2014 Gate 2 NFR checker\n- `/scripts/check_test_quality.py` \u2014 Gate 0 test quality scanner\n- `/.github/codex/prompts/adversarial_review.md` \u2014 Gate 0 adversarial review checklist\n- `/docs/code_quality_standards.md` \u2014 universal quality standards\n- `/CLAUDE.md` \u2014 this file\n\n## Code Quality Standards\n\nAll code written in this repository \u2014 by Codex, Claude Code, or humans \u2014 must follow the standards in `docs/code_quality_standards.md`. This includes:\n- Anti-vacuous test rules (no mocking the system under test, no stub assertions)\n- Anti-gaming rules (no hardcoded lookup tables, no overfitting)\n- Implementation honesty (real imports, real configs, real dependencies)\n- Test hygiene and quality gates\n\nThese standards are enforced by Gate 0 (adversarial review), Gate 1 (lint/typecheck/test), Gate 2 (NFR checks), and the LLM-as-judge.\n\n## Quick Commands\n\n```bash\nmake install-hooks         # set up git hooks (ruff + mypy on every commit, no virtualenv needed)\nmake validate              # lint + typecheck + test + docker-build + docker-smoke + env-smoke\nmake run-scenarios         # run holdout scenario evaluation\nmake compile-feedback      # compile validation results into feedback markdown\nmake nfr-check             # run Gate 2 NFR checks (code quality, complexity, dead code, security)\nmake factory-local         # run one factory iteration locally (Gate 1 \u2192 Gate 2 \u2192 Gate 3 \u2192 feedback)\nmake factory-status        # show current iteration count and satisfaction score\n```\n\n## Human Decision Log\n\n- `/ProjectLeadAsks.md` \u2014 Open questions and decisions requiring the project lead's input. **Check this file at every session start.** Update it when questions are resolved or new ones arise. This file survives context compaction \u2014 it's the canonical list of what's pending.\n\n## Stack\n\n- Python 3.12, pip-tools for dependency management\n- PyTorch, Gymnasium, NumPy for RL\n- ruff + mypy + pytest for quality\n- GitHub Actions for CI and validation\n- OpenAI Codex as the non-interactive coding agent (attractor)\n- Claude Code as factory orchestrator (skill: `/factory-orchestrate`)\n- PR review pack generator (skill: `/pr-review-pack`) \u2014 `.claude/skills/pr-review-pack/` contains the review pack generation skill with template, scripts, and reference docs\n"
    },
    "Makefile": {
      "additions": 4,
      "deletions": 1,
      "status": "modified",
      "binary": false,
      "diff": "diff --git a/Makefile b/Makefile\nindex 57d93ed..edf1781 100644\n--- a/Makefile\n+++ b/Makefile\n@@ -1,4 +1,4 @@\n-.PHONY: deps install-hooks lint typecheck test docker-build docker-smoke whitepapers-acquire whitepapers-verify env-smoke train-smoke eval-smoke verify-learning dashboard validate run-scenarios compile-feedback nfr-check factory-local factory-status\n+.PHONY: deps install-hooks lint typecheck test docker-build docker-smoke whitepapers-acquire whitepapers-verify env-smoke train-smoke eval-smoke verify-learning dashboard validate run-scenarios compile-feedback nfr-check factory-local factory-status persist-decisions\n \n deps:\n \tpip-compile requirements.in\n@@ -95,6 +95,9 @@ factory-local: ## Run one factory iteration locally (Gate 1 \u2192 Gate 2 \u2192 Gate\n \t@echo \"=== Factory iteration complete ===\"\n \t@make factory-status\n \n+persist-decisions: ## Persist PR decisions to cumulative log (usage: make persist-decisions PR=6)\n+\tpython scripts/persist_decisions.py --pr $(PR)\n+\n factory-status: ## Show current iteration count and satisfaction score\n \t@echo \"--- Factory Status ---\"\n \t@if [ -f artifacts/factory/iteration_count.txt ]; then \\\n",
      "raw": ".PHONY: deps install-hooks lint typecheck test docker-build docker-smoke whitepapers-acquire whitepapers-verify env-smoke train-smoke eval-smoke verify-learning dashboard validate run-scenarios compile-feedback nfr-check factory-local factory-status persist-decisions\n\ndeps:\n\tpip-compile requirements.in\n\tpip-compile requirements-dev.in\n\tpip install -r requirements.txt -r requirements-dev.txt\n\ninstall-hooks: ## Set up git hooks (ruff + mypy on every commit, no virtualenv needed)\n\tgit config core.hooksPath .githooks\n\t@echo \"\u2705 Git hooks installed from .githooks/\"\n\n# \u2500\u2500 Quality \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nlint:\n\truff check .\n\ntypecheck:\n\tmypy src\n\ntest:\n\tpytest -q\n\n# \u2500\u2500 Docker \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndocker-build:\n\tdocker build -f infra/docker/Dockerfile.train --build-arg BASE_IMAGE=python:3.12-slim -t minipong-train .\n\tdocker build -f infra/docker/Dockerfile.demo -t minipong-demo .\n\ndocker-smoke:\n\tdocker run --rm minipong-train python -m src.train.train_dqn --help\n\tdocker run --rm minipong-demo python -m src.train.record_video --help\n\n# \u2500\u2500 Whitepapers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nwhitepapers-acquire:\n\tpython scripts/acquire_whitepapers.py\n\nwhitepapers-verify:\n\tpython scripts/verify_whitepapers.py\n\n# \u2500\u2500 Environment \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nenv-smoke:\n\tpython -c \"from src.envs.minipong import MiniPongEnv; env=MiniPongEnv(); obs,_=env.reset(seed=0); assert obs.dtype.name=='uint8'; print(obs.shape)\"\n\n# \u2500\u2500 Training \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntrain-smoke:\n\tpython -m src.train.train_dqn --config configs/dqn_minipong.yaml --run-id smoke_run\n\neval-smoke:\n\tpython -m src.train.evaluate --run-id smoke_run --episodes 2 --seeds 1 2\n\nverify-learning:\n\tpython -m src.train.verify_learning --run-id smoke_run --min-return-gain -0.1 --min-hits-gain -0.1\n\n# \u2500\u2500 Dashboard \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndashboard:\n\tstreamlit run src/dashboard/app.py\n\n# \u2500\u2500 Validation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nvalidate: lint typecheck test docker-build docker-smoke env-smoke whitepapers-verify\n\n# \u2500\u2500 Dark Factory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nrun-scenarios: ## Run holdout scenario evaluation\n\tpython scripts/run_scenarios.py\n\ncompile-feedback: ## Compile validation results into feedback markdown\n\tpython scripts/compile_feedback.py\n\nnfr-check: ## Run Gate 2 NFR checks (non-blocking quality analysis)\n\t@mkdir -p artifacts/factory\n\tpython scripts/nfr_checks.py --output artifacts/factory/nfr_results.json\n\tpython scripts/nfr_checks.py\n\nfactory-local: ## Run one factory iteration locally (Gate 1 \u2192 Gate 2 \u2192 Gate 3 \u2192 feedback)\n\t@mkdir -p artifacts/factory\n\t@echo \"=== Gate 1: lint + typecheck + test ===\"\n\t@make lint 2>&1 | tee -a artifacts/factory/ci_output.log; \\\n\tLINT_EXIT=$$?; \\\n\tmake typecheck 2>&1 | tee -a artifacts/factory/ci_output.log; \\\n\tTYPE_EXIT=$$?; \\\n\tmake test 2>&1 | tee -a artifacts/factory/ci_output.log; \\\n\tTEST_EXIT=$$?; \\\n\tif [ $$LINT_EXIT -ne 0 ] || [ $$TYPE_EXIT -ne 0 ] || [ $$TEST_EXIT -ne 0 ]; then \\\n\t\techo \"Gate 1 FAILED \u2014 skipping Gates 2-3\"; \\\n\t\techo '{\"total\":0,\"passed\":0,\"failed\":0,\"skipped\":0,\"satisfaction_score\":0.0,\"results\":[],\"timestamp\":\"N/A\",\"gate1_failed\":true}' > artifacts/factory/scenario_results.json; \\\n\telse \\\n\t\techo \"\"; \\\n\t\techo \"=== Gate 2: NFR checks (non-blocking) ===\"; \\\n\t\tmake nfr-check 2>&1 | tee -a artifacts/factory/ci_output.log || true; \\\n\t\techo \"\"; \\\n\t\techo \"=== Gate 3: Behavioral scenarios ===\"; \\\n\t\tpython scripts/run_scenarios.py --timeout 180 || true; \\\n\tfi\n\t@echo \"\"\n\t@echo \"=== Compiling feedback ===\"\n\t@python scripts/compile_feedback.py\n\t@echo \"\"\n\t@echo \"=== Factory iteration complete ===\"\n\t@make factory-status\n\npersist-decisions: ## Persist PR decisions to cumulative log (usage: make persist-decisions PR=6)\n\tpython scripts/persist_decisions.py --pr $(PR)\n\nfactory-status: ## Show current iteration count and satisfaction score\n\t@echo \"--- Factory Status ---\"\n\t@if [ -f artifacts/factory/iteration_count.txt ]; then \\\n\t\techo \"Iteration: $$(cat artifacts/factory/iteration_count.txt)\"; \\\n\telse \\\n\t\techo \"Iteration: 0 (not started)\"; \\\n\tfi\n\t@if [ -f artifacts/factory/scenario_results.json ]; then \\\n\t\tpython -c \"import json; r=json.load(open('artifacts/factory/scenario_results.json')); print(f'Satisfaction: {r.get(\\\"satisfaction_score\\\", 0):.0%} ({r.get(\\\"passed\\\", 0)}/{r.get(\\\"total\\\", 0)} scenarios)')\"; \\\n\telse \\\n\t\techo \"Satisfaction: N/A (no results yet)\"; \\\n\tfi\n",
      "base": ".PHONY: deps install-hooks lint typecheck test docker-build docker-smoke whitepapers-acquire whitepapers-verify env-smoke train-smoke eval-smoke verify-learning dashboard validate run-scenarios compile-feedback nfr-check factory-local factory-status\n\ndeps:\n\tpip-compile requirements.in\n\tpip-compile requirements-dev.in\n\tpip install -r requirements.txt -r requirements-dev.txt\n\ninstall-hooks: ## Set up git hooks (ruff + mypy on every commit, no virtualenv needed)\n\tgit config core.hooksPath .githooks\n\t@echo \"\u2705 Git hooks installed from .githooks/\"\n\n# \u2500\u2500 Quality \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nlint:\n\truff check .\n\ntypecheck:\n\tmypy src\n\ntest:\n\tpytest -q\n\n# \u2500\u2500 Docker \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndocker-build:\n\tdocker build -f infra/docker/Dockerfile.train --build-arg BASE_IMAGE=python:3.12-slim -t minipong-train .\n\tdocker build -f infra/docker/Dockerfile.demo -t minipong-demo .\n\ndocker-smoke:\n\tdocker run --rm minipong-train python -m src.train.train_dqn --help\n\tdocker run --rm minipong-demo python -m src.train.record_video --help\n\n# \u2500\u2500 Whitepapers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nwhitepapers-acquire:\n\tpython scripts/acquire_whitepapers.py\n\nwhitepapers-verify:\n\tpython scripts/verify_whitepapers.py\n\n# \u2500\u2500 Environment \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nenv-smoke:\n\tpython -c \"from src.envs.minipong import MiniPongEnv; env=MiniPongEnv(); obs,_=env.reset(seed=0); assert obs.dtype.name=='uint8'; print(obs.shape)\"\n\n# \u2500\u2500 Training \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntrain-smoke:\n\tpython -m src.train.train_dqn --config configs/dqn_minipong.yaml --run-id smoke_run\n\neval-smoke:\n\tpython -m src.train.evaluate --run-id smoke_run --episodes 2 --seeds 1 2\n\nverify-learning:\n\tpython -m src.train.verify_learning --run-id smoke_run --min-return-gain -0.1 --min-hits-gain -0.1\n\n# \u2500\u2500 Dashboard \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndashboard:\n\tstreamlit run src/dashboard/app.py\n\n# \u2500\u2500 Validation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nvalidate: lint typecheck test docker-build docker-smoke env-smoke whitepapers-verify\n\n# \u2500\u2500 Dark Factory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nrun-scenarios: ## Run holdout scenario evaluation\n\tpython scripts/run_scenarios.py\n\ncompile-feedback: ## Compile validation results into feedback markdown\n\tpython scripts/compile_feedback.py\n\nnfr-check: ## Run Gate 2 NFR checks (non-blocking quality analysis)\n\t@mkdir -p artifacts/factory\n\tpython scripts/nfr_checks.py --output artifacts/factory/nfr_results.json\n\tpython scripts/nfr_checks.py\n\nfactory-local: ## Run one factory iteration locally (Gate 1 \u2192 Gate 2 \u2192 Gate 3 \u2192 feedback)\n\t@mkdir -p artifacts/factory\n\t@echo \"=== Gate 1: lint + typecheck + test ===\"\n\t@make lint 2>&1 | tee -a artifacts/factory/ci_output.log; \\\n\tLINT_EXIT=$$?; \\\n\tmake typecheck 2>&1 | tee -a artifacts/factory/ci_output.log; \\\n\tTYPE_EXIT=$$?; \\\n\tmake test 2>&1 | tee -a artifacts/factory/ci_output.log; \\\n\tTEST_EXIT=$$?; \\\n\tif [ $$LINT_EXIT -ne 0 ] || [ $$TYPE_EXIT -ne 0 ] || [ $$TEST_EXIT -ne 0 ]; then \\\n\t\techo \"Gate 1 FAILED \u2014 skipping Gates 2-3\"; \\\n\t\techo '{\"total\":0,\"passed\":0,\"failed\":0,\"skipped\":0,\"satisfaction_score\":0.0,\"results\":[],\"timestamp\":\"N/A\",\"gate1_failed\":true}' > artifacts/factory/scenario_results.json; \\\n\telse \\\n\t\techo \"\"; \\\n\t\techo \"=== Gate 2: NFR checks (non-blocking) ===\"; \\\n\t\tmake nfr-check 2>&1 | tee -a artifacts/factory/ci_output.log || true; \\\n\t\techo \"\"; \\\n\t\techo \"=== Gate 3: Behavioral scenarios ===\"; \\\n\t\tpython scripts/run_scenarios.py --timeout 180 || true; \\\n\tfi\n\t@echo \"\"\n\t@echo \"=== Compiling feedback ===\"\n\t@python scripts/compile_feedback.py\n\t@echo \"\"\n\t@echo \"=== Factory iteration complete ===\"\n\t@make factory-status\n\nfactory-status: ## Show current iteration count and satisfaction score\n\t@echo \"--- Factory Status ---\"\n\t@if [ -f artifacts/factory/iteration_count.txt ]; then \\\n\t\techo \"Iteration: $$(cat artifacts/factory/iteration_count.txt)\"; \\\n\telse \\\n\t\techo \"Iteration: 0 (not started)\"; \\\n\tfi\n\t@if [ -f artifacts/factory/scenario_results.json ]; then \\\n\t\tpython -c \"import json; r=json.load(open('artifacts/factory/scenario_results.json')); print(f'Satisfaction: {r.get(\\\"satisfaction_score\\\", 0):.0%} ({r.get(\\\"passed\\\", 0)}/{r.get(\\\"total\\\", 0)} scenarios)')\"; \\\n\telse \\\n\t\techo \"Satisfaction: N/A (no results yet)\"; \\\n\tfi\n"
    },
    "docs/decisions/decision_log.json": {
      "additions": 53,
      "deletions": 0,
      "status": "added",
      "binary": false,
      "diff": "diff --git a/docs/decisions/decision_log.json b/docs/decisions/decision_log.json\nnew file mode 100644\nindex 0000000..1f89c9f\n--- /dev/null\n+++ b/docs/decisions/decision_log.json\n@@ -0,0 +1,53 @@\n+{\n+  \"version\": 1,\n+  \"decisions\": [\n+    {\n+      \"id\": \"PR6-1\",\n+      \"globalSeq\": 1,\n+      \"prNumber\": 6,\n+      \"title\": \"Wire existing record_video() rather than rewriting\",\n+      \"rationale\": \"The video recording function was already implemented and tested \u2014 it just wasn't called from the training loop.\",\n+      \"body\": \"Rather than creating a new video recording mechanism or modifying the evaluation flow, we simply imported the existing <code>record_video()</code> function and called it at the same point where checkpoints and metrics are already saved. This is the minimal change that fixes the scenario failure.\",\n+      \"zones\": [\n+        \"training\"\n+      ],\n+      \"files\": [\n+        {\n+          \"path\": \"src/train/train_dqn.py\",\n+          \"change\": \"Added import and call to record_video() in eval block\"\n+        },\n+        {\n+          \"path\": \"src/train/record_video.py\",\n+          \"change\": \"Added frame_stack parameter for config compatibility\"\n+        }\n+      ],\n+      \"verified\": true,\n+      \"mergedAt\": \"2026-02-26T04:26:25Z\",\n+      \"prUrl\": \"https://github.com/joeyfezster/building_ai_w_ai/pull/6\",\n+      \"headSha\": \"bce032a\",\n+      \"status\": \"active\"\n+    },\n+    {\n+      \"id\": \"PR6-2\",\n+      \"globalSeq\": 2,\n+      \"prNumber\": 6,\n+      \"title\": \"Parameterize frame_stack instead of hardcoding\",\n+      \"rationale\": \"Hardcoded frame_stack=4 caused shape mismatches when training config used a different value.\",\n+      \"body\": \"The original <code>record_video()</code> hardcoded <code>frame_stack=4</code>. When the test suite runs with <code>frame_stack=2</code>, loading a checkpoint into a model with mismatched input channels causes a RuntimeError. Adding the parameter with default=4 maintains backward compatibility while allowing the training loop to pass the correct value.\",\n+      \"zones\": [\n+        \"training\"\n+      ],\n+      \"files\": [\n+        {\n+          \"path\": \"src/train/record_video.py\",\n+          \"change\": \"Added frame_stack parameter with default=4\"\n+        }\n+      ],\n+      \"verified\": true,\n+      \"mergedAt\": \"2026-02-26T04:26:25Z\",\n+      \"prUrl\": \"https://github.com/joeyfezster/building_ai_w_ai/pull/6\",\n+      \"headSha\": \"bce032a\",\n+      \"status\": \"active\"\n+    }\n+  ]\n+}\n",
      "raw": "{\n  \"version\": 1,\n  \"decisions\": [\n    {\n      \"id\": \"PR6-1\",\n      \"globalSeq\": 1,\n      \"prNumber\": 6,\n      \"title\": \"Wire existing record_video() rather than rewriting\",\n      \"rationale\": \"The video recording function was already implemented and tested \u2014 it just wasn't called from the training loop.\",\n      \"body\": \"Rather than creating a new video recording mechanism or modifying the evaluation flow, we simply imported the existing <code>record_video()</code> function and called it at the same point where checkpoints and metrics are already saved. This is the minimal change that fixes the scenario failure.\",\n      \"zones\": [\n        \"training\"\n      ],\n      \"files\": [\n        {\n          \"path\": \"src/train/train_dqn.py\",\n          \"change\": \"Added import and call to record_video() in eval block\"\n        },\n        {\n          \"path\": \"src/train/record_video.py\",\n          \"change\": \"Added frame_stack parameter for config compatibility\"\n        }\n      ],\n      \"verified\": true,\n      \"mergedAt\": \"2026-02-26T04:26:25Z\",\n      \"prUrl\": \"https://github.com/joeyfezster/building_ai_w_ai/pull/6\",\n      \"headSha\": \"bce032a\",\n      \"status\": \"active\"\n    },\n    {\n      \"id\": \"PR6-2\",\n      \"globalSeq\": 2,\n      \"prNumber\": 6,\n      \"title\": \"Parameterize frame_stack instead of hardcoding\",\n      \"rationale\": \"Hardcoded frame_stack=4 caused shape mismatches when training config used a different value.\",\n      \"body\": \"The original <code>record_video()</code> hardcoded <code>frame_stack=4</code>. When the test suite runs with <code>frame_stack=2</code>, loading a checkpoint into a model with mismatched input channels causes a RuntimeError. Adding the parameter with default=4 maintains backward compatibility while allowing the training loop to pass the correct value.\",\n      \"zones\": [\n        \"training\"\n      ],\n      \"files\": [\n        {\n          \"path\": \"src/train/record_video.py\",\n          \"change\": \"Added frame_stack parameter with default=4\"\n        }\n      ],\n      \"verified\": true,\n      \"mergedAt\": \"2026-02-26T04:26:25Z\",\n      \"prUrl\": \"https://github.com/joeyfezster/building_ai_w_ai/pull/6\",\n      \"headSha\": \"bce032a\",\n      \"status\": \"active\"\n    }\n  ]\n}\n",
      "base": ""
    },
    "scripts/persist_decisions.py": {
      "additions": 241,
      "deletions": 0,
      "status": "added",
      "binary": false,
      "diff": "diff --git a/scripts/persist_decisions.py b/scripts/persist_decisions.py\nnew file mode 100644\nindex 0000000..2aec4d1\n--- /dev/null\n+++ b/scripts/persist_decisions.py\n@@ -0,0 +1,241 @@\n+#!/usr/bin/env python3\n+\"\"\"Persist PR review pack decisions to the cumulative decision log.\n+\n+Extracts decisions from ReviewPackData JSON (or from rendered HTML as fallback)\n+and appends them to docs/decisions/decision_log.json.\n+\n+Usage:\n+    python scripts/persist_decisions.py --pr 6                           # persist from HTML\n+    python scripts/persist_decisions.py --pr 6 --data /tmp/pr6_data.json # persist from JSON\n+    python scripts/persist_decisions.py --pr 6 --dry-run                 # preview only\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+import argparse\n+import json\n+import re\n+import subprocess\n+import sys\n+from pathlib import Path\n+\n+REPO_ROOT = Path(__file__).resolve().parent.parent\n+DEFAULT_LOG = REPO_ROOT / \"docs\" / \"decisions\" / \"decision_log.json\"\n+REPO_SLUG = \"joeyfezster/building_ai_w_ai\"\n+\n+\n+def load_decision_log(path: Path) -> dict:\n+    \"\"\"Load the existing decision log, or create the initial structure.\"\"\"\n+    if path.exists():\n+        return json.loads(path.read_text())\n+    return {\"version\": 1, \"decisions\": []}\n+\n+\n+def next_global_seq(log: dict) -> int:\n+    \"\"\"Compute the next globalSeq from the existing log.\"\"\"\n+    if not log[\"decisions\"]:\n+        return 1\n+    return max(d[\"globalSeq\"] for d in log[\"decisions\"]) + 1\n+\n+\n+def existing_ids(log: dict) -> set[str]:\n+    \"\"\"Return the set of decision IDs already in the log.\"\"\"\n+    return {d[\"id\"] for d in log[\"decisions\"]}\n+\n+\n+def extract_decisions_from_json(path: Path) -> tuple[list[dict], dict]:\n+    \"\"\"Extract decisions and header from a ReviewPackData JSON file.\"\"\"\n+    data = json.loads(path.read_text())\n+    return data.get(\"decisions\", []), data.get(\"header\", {})\n+\n+\n+def extract_decisions_from_html(path: Path) -> tuple[list[dict], dict]:\n+    \"\"\"Extract decisions from rendered HTML by parsing the embedded DATA object.\n+\n+    The review pack HTML contains a `const DATA = {...};` block with the full\n+    ReviewPackData JSON. We extract it with a regex and parse it.\n+    \"\"\"\n+    html = path.read_text()\n+    match = re.search(r\"const DATA = ({.*?});\\s*\\n\", html, re.DOTALL)\n+    if not match:\n+        print(\"ERROR: Could not find 'const DATA = {...}' in HTML file.\")\n+        sys.exit(1)\n+\n+    # The embedded JSON may contain <\\/script> escapes from the renderer.\n+    raw = match.group(1).replace(r\"<\\/script\", \"</script\")\n+\n+    data = json.loads(raw)\n+    return data.get(\"decisions\", []), data.get(\"header\", {})\n+\n+\n+def get_merge_timestamp(pr_number: int) -> str:\n+    \"\"\"Get the merge timestamp for a PR via gh CLI.\n+\n+    Fails explicitly if the timestamp cannot be determined \u2014 never\n+    fabricates a timestamp, as that would corrupt the decision log's\n+    chronology and auditability.\n+    \"\"\"\n+    try:\n+        result = subprocess.run(\n+            [\"gh\", \"pr\", \"view\", str(pr_number), \"--json\", \"mergedAt\", \"-q\", \".mergedAt\"],\n+            capture_output=True,\n+            text=True,\n+            timeout=15,\n+        )\n+        if result.returncode == 0 and result.stdout.strip():\n+            return result.stdout.strip()\n+    except Exception:\n+        pass\n+\n+    # PR may not be merged yet \u2014 use HEAD commit timestamp as deterministic fallback\n+    try:\n+        result = subprocess.run(\n+            [\"git\", \"log\", \"-1\", \"--format=%aI\"],\n+            capture_output=True,\n+            text=True,\n+            timeout=10,\n+        )\n+        if result.returncode == 0 and result.stdout.strip():\n+            return result.stdout.strip()\n+    except Exception:\n+        pass\n+\n+    print(\"ERROR: Could not determine merge timestamp from gh or git log.\")\n+    print(\"  Ensure 'gh' is authenticated or run from within the git repo.\")\n+    sys.exit(1)\n+\n+\n+def get_pr_url(pr_number: int) -> str:\n+    \"\"\"Build the PR URL.\"\"\"\n+    return f\"https://github.com/{REPO_SLUG}/pull/{pr_number}\"\n+\n+\n+def build_persisted_decision(\n+    raw: dict,\n+    pr_number: int,\n+    global_seq: int,\n+    merged_at: str,\n+    head_sha: str,\n+) -> dict:\n+    \"\"\"Convert a raw Decision (from review pack) to the persisted format.\"\"\"\n+    local_seq = raw[\"number\"]\n+    zones_raw = raw.get(\"zones\", \"\")\n+    zones = zones_raw.split() if isinstance(zones_raw, str) else zones_raw\n+\n+    return {\n+        \"id\": f\"PR{pr_number}-{local_seq}\",\n+        \"globalSeq\": global_seq,\n+        \"prNumber\": pr_number,\n+        \"title\": raw[\"title\"],\n+        \"rationale\": raw.get(\"rationale\", \"\"),\n+        \"body\": raw.get(\"body\", \"\"),\n+        \"zones\": zones,\n+        \"files\": raw.get(\"files\", []),\n+        \"verified\": raw.get(\"verified\", False),\n+        \"mergedAt\": merged_at,\n+        \"prUrl\": get_pr_url(pr_number),\n+        \"headSha\": head_sha,\n+        \"status\": \"active\",\n+    }\n+\n+\n+def main() -> int:\n+    parser = argparse.ArgumentParser(\n+        description=\"Persist PR review pack decisions to the decision log\"\n+    )\n+    parser.add_argument(\n+        \"--pr\", type=int, required=True, help=\"PR number whose decisions to persist\"\n+    )\n+    parser.add_argument(\n+        \"--data\",\n+        type=str,\n+        default=None,\n+        help=\"Path to ReviewPackData JSON file (falls back to rendered HTML)\",\n+    )\n+    parser.add_argument(\n+        \"--log\",\n+        type=str,\n+        default=None,\n+        help=f\"Path to decision log (default: {DEFAULT_LOG})\",\n+    )\n+    parser.add_argument(\n+        \"--dry-run\", action=\"store_true\", help=\"Preview without modifying the log\"\n+    )\n+    args = parser.parse_args()\n+\n+    log_path = Path(args.log) if args.log else DEFAULT_LOG\n+\n+    # --- Load decisions from source ---\n+    decisions: list[dict]\n+    header: dict\n+\n+    if args.data:\n+        data_path = Path(args.data)\n+        if not data_path.exists():\n+            print(f\"ERROR: Data file not found: {data_path}\")\n+            return 1\n+        decisions, header = extract_decisions_from_json(data_path)\n+    else:\n+        # Fall back to rendered HTML\n+        html_path = REPO_ROOT / \"docs\" / f\"pr{args.pr}_review_pack.html\"\n+        if not html_path.exists():\n+            print(f\"ERROR: No data file provided and no HTML found at {html_path}\")\n+            print(f\"  Provide --data /path/to/pr{args.pr}_review_pack_data.json\")\n+            return 1\n+        print(f\"No --data provided, extracting from HTML: {html_path}\")\n+        decisions, header = extract_decisions_from_html(html_path)\n+\n+    if not decisions:\n+        print(f\"No decisions found for PR #{args.pr}. Nothing to persist.\")\n+        return 0\n+\n+    # --- Load existing log ---\n+    log = load_decision_log(log_path)\n+    known = existing_ids(log)\n+    seq = next_global_seq(log)\n+\n+    # --- Get metadata ---\n+    merged_at = get_merge_timestamp(args.pr)\n+    head_sha = header.get(\"headSha\", \"unknown\")\n+\n+    # --- Build and append ---\n+    added = 0\n+    skipped = 0\n+    for raw in decisions:\n+        local_seq = raw[\"number\"]\n+        decision_id = f\"PR{args.pr}-{local_seq}\"\n+\n+        if decision_id in known:\n+            print(f\"  SKIP: {decision_id} already exists in log\")\n+            skipped += 1\n+            continue\n+\n+        persisted = build_persisted_decision(raw, args.pr, seq, merged_at, head_sha)\n+\n+        if args.dry_run:\n+            print(f\"\\n  WOULD ADD: {decision_id} (globalSeq={seq})\")\n+            print(f\"    Title: {persisted['title']}\")\n+            print(f\"    Zones: {persisted['zones']}\")\n+            print(f\"    Files: {len(persisted['files'])}\")\n+        else:\n+            log[\"decisions\"].append(persisted)\n+            print(f\"  ADD: {decision_id} (globalSeq={seq}) \u2014 {persisted['title']}\")\n+\n+        seq += 1\n+        added += 1\n+\n+    # --- Write ---\n+    if not args.dry_run and added > 0:\n+        log_path.parent.mkdir(parents=True, exist_ok=True)\n+        log_path.write_text(json.dumps(log, indent=2, ensure_ascii=False) + \"\\n\")\n+        print(f\"\\nPersisted {added} decisions from PR #{args.pr} to {log_path}\")\n+    elif args.dry_run:\n+        print(f\"\\nDry run: {added} decisions would be added, {skipped} skipped\")\n+    else:\n+        print(f\"\\nNo new decisions to add ({skipped} already in log)\")\n+\n+    return 0\n+\n+\n+if __name__ == \"__main__\":\n+    sys.exit(main())\n",
      "raw": "#!/usr/bin/env python3\n\"\"\"Persist PR review pack decisions to the cumulative decision log.\n\nExtracts decisions from ReviewPackData JSON (or from rendered HTML as fallback)\nand appends them to docs/decisions/decision_log.json.\n\nUsage:\n    python scripts/persist_decisions.py --pr 6                           # persist from HTML\n    python scripts/persist_decisions.py --pr 6 --data /tmp/pr6_data.json # persist from JSON\n    python scripts/persist_decisions.py --pr 6 --dry-run                 # preview only\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport json\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nREPO_ROOT = Path(__file__).resolve().parent.parent\nDEFAULT_LOG = REPO_ROOT / \"docs\" / \"decisions\" / \"decision_log.json\"\nREPO_SLUG = \"joeyfezster/building_ai_w_ai\"\n\n\ndef load_decision_log(path: Path) -> dict:\n    \"\"\"Load the existing decision log, or create the initial structure.\"\"\"\n    if path.exists():\n        return json.loads(path.read_text())\n    return {\"version\": 1, \"decisions\": []}\n\n\ndef next_global_seq(log: dict) -> int:\n    \"\"\"Compute the next globalSeq from the existing log.\"\"\"\n    if not log[\"decisions\"]:\n        return 1\n    return max(d[\"globalSeq\"] for d in log[\"decisions\"]) + 1\n\n\ndef existing_ids(log: dict) -> set[str]:\n    \"\"\"Return the set of decision IDs already in the log.\"\"\"\n    return {d[\"id\"] for d in log[\"decisions\"]}\n\n\ndef extract_decisions_from_json(path: Path) -> tuple[list[dict], dict]:\n    \"\"\"Extract decisions and header from a ReviewPackData JSON file.\"\"\"\n    data = json.loads(path.read_text())\n    return data.get(\"decisions\", []), data.get(\"header\", {})\n\n\ndef extract_decisions_from_html(path: Path) -> tuple[list[dict], dict]:\n    \"\"\"Extract decisions from rendered HTML by parsing the embedded DATA object.\n\n    The review pack HTML contains a `const DATA = {...};` block with the full\n    ReviewPackData JSON. We extract it with a regex and parse it.\n    \"\"\"\n    html = path.read_text()\n    match = re.search(r\"const DATA = ({.*?});\\s*\\n\", html, re.DOTALL)\n    if not match:\n        print(\"ERROR: Could not find 'const DATA = {...}' in HTML file.\")\n        sys.exit(1)\n\n    # The embedded JSON may contain <\\/script> escapes from the renderer.\n    raw = match.group(1).replace(r\"<\\/script\", \"</script\")\n\n    data = json.loads(raw)\n    return data.get(\"decisions\", []), data.get(\"header\", {})\n\n\ndef get_merge_timestamp(pr_number: int) -> str:\n    \"\"\"Get the merge timestamp for a PR via gh CLI.\n\n    Fails explicitly if the timestamp cannot be determined \u2014 never\n    fabricates a timestamp, as that would corrupt the decision log's\n    chronology and auditability.\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"gh\", \"pr\", \"view\", str(pr_number), \"--json\", \"mergedAt\", \"-q\", \".mergedAt\"],\n            capture_output=True,\n            text=True,\n            timeout=15,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            return result.stdout.strip()\n    except Exception:\n        pass\n\n    # PR may not be merged yet \u2014 use HEAD commit timestamp as deterministic fallback\n    try:\n        result = subprocess.run(\n            [\"git\", \"log\", \"-1\", \"--format=%aI\"],\n            capture_output=True,\n            text=True,\n            timeout=10,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            return result.stdout.strip()\n    except Exception:\n        pass\n\n    print(\"ERROR: Could not determine merge timestamp from gh or git log.\")\n    print(\"  Ensure 'gh' is authenticated or run from within the git repo.\")\n    sys.exit(1)\n\n\ndef get_pr_url(pr_number: int) -> str:\n    \"\"\"Build the PR URL.\"\"\"\n    return f\"https://github.com/{REPO_SLUG}/pull/{pr_number}\"\n\n\ndef build_persisted_decision(\n    raw: dict,\n    pr_number: int,\n    global_seq: int,\n    merged_at: str,\n    head_sha: str,\n) -> dict:\n    \"\"\"Convert a raw Decision (from review pack) to the persisted format.\"\"\"\n    local_seq = raw[\"number\"]\n    zones_raw = raw.get(\"zones\", \"\")\n    zones = zones_raw.split() if isinstance(zones_raw, str) else zones_raw\n\n    return {\n        \"id\": f\"PR{pr_number}-{local_seq}\",\n        \"globalSeq\": global_seq,\n        \"prNumber\": pr_number,\n        \"title\": raw[\"title\"],\n        \"rationale\": raw.get(\"rationale\", \"\"),\n        \"body\": raw.get(\"body\", \"\"),\n        \"zones\": zones,\n        \"files\": raw.get(\"files\", []),\n        \"verified\": raw.get(\"verified\", False),\n        \"mergedAt\": merged_at,\n        \"prUrl\": get_pr_url(pr_number),\n        \"headSha\": head_sha,\n        \"status\": \"active\",\n    }\n\n\ndef main() -> int:\n    parser = argparse.ArgumentParser(\n        description=\"Persist PR review pack decisions to the decision log\"\n    )\n    parser.add_argument(\n        \"--pr\", type=int, required=True, help=\"PR number whose decisions to persist\"\n    )\n    parser.add_argument(\n        \"--data\",\n        type=str,\n        default=None,\n        help=\"Path to ReviewPackData JSON file (falls back to rendered HTML)\",\n    )\n    parser.add_argument(\n        \"--log\",\n        type=str,\n        default=None,\n        help=f\"Path to decision log (default: {DEFAULT_LOG})\",\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\", help=\"Preview without modifying the log\"\n    )\n    args = parser.parse_args()\n\n    log_path = Path(args.log) if args.log else DEFAULT_LOG\n\n    # --- Load decisions from source ---\n    decisions: list[dict]\n    header: dict\n\n    if args.data:\n        data_path = Path(args.data)\n        if not data_path.exists():\n            print(f\"ERROR: Data file not found: {data_path}\")\n            return 1\n        decisions, header = extract_decisions_from_json(data_path)\n    else:\n        # Fall back to rendered HTML\n        html_path = REPO_ROOT / \"docs\" / f\"pr{args.pr}_review_pack.html\"\n        if not html_path.exists():\n            print(f\"ERROR: No data file provided and no HTML found at {html_path}\")\n            print(f\"  Provide --data /path/to/pr{args.pr}_review_pack_data.json\")\n            return 1\n        print(f\"No --data provided, extracting from HTML: {html_path}\")\n        decisions, header = extract_decisions_from_html(html_path)\n\n    if not decisions:\n        print(f\"No decisions found for PR #{args.pr}. Nothing to persist.\")\n        return 0\n\n    # --- Load existing log ---\n    log = load_decision_log(log_path)\n    known = existing_ids(log)\n    seq = next_global_seq(log)\n\n    # --- Get metadata ---\n    merged_at = get_merge_timestamp(args.pr)\n    head_sha = header.get(\"headSha\", \"unknown\")\n\n    # --- Build and append ---\n    added = 0\n    skipped = 0\n    for raw in decisions:\n        local_seq = raw[\"number\"]\n        decision_id = f\"PR{args.pr}-{local_seq}\"\n\n        if decision_id in known:\n            print(f\"  SKIP: {decision_id} already exists in log\")\n            skipped += 1\n            continue\n\n        persisted = build_persisted_decision(raw, args.pr, seq, merged_at, head_sha)\n\n        if args.dry_run:\n            print(f\"\\n  WOULD ADD: {decision_id} (globalSeq={seq})\")\n            print(f\"    Title: {persisted['title']}\")\n            print(f\"    Zones: {persisted['zones']}\")\n            print(f\"    Files: {len(persisted['files'])}\")\n        else:\n            log[\"decisions\"].append(persisted)\n            print(f\"  ADD: {decision_id} (globalSeq={seq}) \u2014 {persisted['title']}\")\n\n        seq += 1\n        added += 1\n\n    # --- Write ---\n    if not args.dry_run and added > 0:\n        log_path.parent.mkdir(parents=True, exist_ok=True)\n        log_path.write_text(json.dumps(log, indent=2, ensure_ascii=False) + \"\\n\")\n        print(f\"\\nPersisted {added} decisions from PR #{args.pr} to {log_path}\")\n    elif args.dry_run:\n        print(f\"\\nDry run: {added} decisions would be added, {skipped} skipped\")\n    else:\n        print(f\"\\nNo new decisions to add ({skipped} already in log)\")\n\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n",
      "base": ""
    }
  }
};
</script>
<script>
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// DATA INJECTION POINT
// Replace this empty object with the ReviewPackData JSON
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
const DATA = {
  "header": {
    "title": "PR #10: Decision persistence: cumulative log after merge acceptance",
    "prNumber": 10,
    "prUrl": "https://github.com/joeyfezster/building_ai_w_ai/pull/10",
    "headBranch": "worktree-decisions-persistence",
    "baseBranch": "main",
    "headSha": "babed4d",
    "additions": 338,
    "deletions": 7,
    "filesChanged": 6,
    "commits": 2,
    "statusBadges": [
      {
        "label": "CI 4/4",
        "type": "pass",
        "icon": "\u2713"
      },
      {
        "label": "No Scenarios",
        "type": "info",
        "icon": "\u2139"
      },
      {
        "label": "2/2 comments resolved",
        "type": "pass",
        "icon": "\u2713"
      },
      {
        "label": "Factory internals",
        "type": "info",
        "icon": "\u2699"
      }
    ],
    "generatedAt": "2026-02-27T18:10:00Z",
    "generatedBy": "Claude Code review agent"
  },
  "architecture": {
    "zones": [
      {
        "id": "factory",
        "label": "Factory",
        "sublabel": "Convergence loop",
        "category": "factory",
        "fileCount": 5,
        "position": {
          "x": 20,
          "y": 20,
          "width": 120,
          "height": 80
        },
        "specs": [],
        "isModified": true
      },
      {
        "id": "environment",
        "label": "Environment",
        "sublabel": "MiniPong env",
        "category": "product",
        "fileCount": 0,
        "position": {
          "x": 20,
          "y": 130,
          "width": 120,
          "height": 80
        },
        "specs": [
          "specs/env.md"
        ],
        "isModified": false
      },
      {
        "id": "rl-core",
        "label": "RL Core",
        "sublabel": "DQN components",
        "category": "product",
        "fileCount": 0,
        "position": {
          "x": 160,
          "y": 130,
          "width": 120,
          "height": 80
        },
        "specs": [
          "specs/rl.md"
        ],
        "isModified": false
      },
      {
        "id": "agent",
        "label": "Agent",
        "sublabel": "DQN agent",
        "category": "product",
        "fileCount": 0,
        "position": {
          "x": 300,
          "y": 130,
          "width": 120,
          "height": 80
        },
        "specs": [
          "specs/rl.md"
        ],
        "isModified": false
      },
      {
        "id": "training",
        "label": "Training",
        "sublabel": "Pipeline, eval, video",
        "category": "product",
        "fileCount": 0,
        "position": {
          "x": 440,
          "y": 130,
          "width": 120,
          "height": 80
        },
        "specs": [
          "specs/training.md",
          "specs/proof.md"
        ],
        "isModified": false
      },
      {
        "id": "observability",
        "label": "Observability",
        "sublabel": "Logging, metrics",
        "category": "product",
        "fileCount": 0,
        "position": {
          "x": 580,
          "y": 130,
          "width": 120,
          "height": 80
        },
        "specs": [],
        "isModified": false
      },
      {
        "id": "dashboard",
        "label": "Dashboard",
        "sublabel": "Streamlit app",
        "category": "product",
        "fileCount": 0,
        "position": {
          "x": 20,
          "y": 240,
          "width": 120,
          "height": 80
        },
        "specs": [
          "specs/dashboard.md"
        ],
        "isModified": false
      },
      {
        "id": "tests",
        "label": "Tests",
        "sublabel": "pytest suite",
        "category": "product",
        "fileCount": 0,
        "position": {
          "x": 160,
          "y": 240,
          "width": 120,
          "height": 80
        },
        "specs": [],
        "isModified": false
      },
      {
        "id": "config",
        "label": "Config",
        "sublabel": "Build, deps",
        "category": "infra",
        "fileCount": 1,
        "position": {
          "x": 300,
          "y": 240,
          "width": 120,
          "height": 80
        },
        "specs": [],
        "isModified": true
      },
      {
        "id": "docker",
        "label": "Docker/Infra",
        "sublabel": "Containers",
        "category": "infra",
        "fileCount": 0,
        "position": {
          "x": 440,
          "y": 240,
          "width": 120,
          "height": 80
        },
        "specs": [],
        "isModified": false
      }
    ],
    "arrows": [
      {
        "from": {
          "x": 80,
          "y": 100
        },
        "to": {
          "x": 80,
          "y": 130
        }
      },
      {
        "from": {
          "x": 80,
          "y": 210
        },
        "to": {
          "x": 160,
          "y": 170
        }
      },
      {
        "from": {
          "x": 280,
          "y": 170
        },
        "to": {
          "x": 300,
          "y": 170
        }
      },
      {
        "from": {
          "x": 420,
          "y": 170
        },
        "to": {
          "x": 440,
          "y": 170
        }
      },
      {
        "from": {
          "x": 560,
          "y": 170
        },
        "to": {
          "x": 580,
          "y": 170
        }
      }
    ],
    "rowLabels": [
      {
        "text": "Factory Infrastructure",
        "position": {
          "x": 700,
          "y": 60
        }
      },
      {
        "text": "Product Code",
        "position": {
          "x": 700,
          "y": 170
        }
      },
      {
        "text": "Infrastructure",
        "position": {
          "x": 700,
          "y": 280
        }
      }
    ]
  },
  "specs": [
    {
      "path": "docs/dark_factory.md",
      "icon": "\ud83c\udfed",
      "description": "Dark factory operating model, gates, and convergence loop documentation"
    }
  ],
  "scenarios": [
    {
      "name": "No Scenarios (Factory Internals PR)",
      "category": "pipeline",
      "status": "advisory",
      "zone": "factory",
      "detail": {
        "what": "This PR modifies factory infrastructure only \u2014 no product code was changed, so no behavioral scenarios apply.",
        "how": "N/A \u2014 no holdout evaluation was run for this PR.",
        "result": "Advisory: factory-internal changes are validated by CI (lint, typecheck, test) and adversarial review, not by holdout scenarios."
      }
    }
  ],
  "whatChanged": {
    "defaultSummary": {
      "infrastructure": "New decision persistence infrastructure: <code>scripts/persist_decisions.py</code> extracts decisions from review pack data and appends them to <code>docs/decisions/decision_log.json</code>, a cumulative append-only archive. Factory orchestration skill updated with Step 13 (post-merge persistence). Codex prompt restructured to separate read-only context (specs, decisions) from truly prohibited files. Makefile gains <code>persist-decisions</code> target.",
      "product": "No product code changes. All modifications are factory infrastructure."
    },
    "zoneDetails": [
      {
        "zoneId": "factory",
        "title": "Factory",
        "description": "<strong>New script:</strong> <code>scripts/persist_decisions.py</code> (~170 lines) \u2014 deterministic extraction of decisions from review pack JSON or rendered HTML, with idempotent append to the cumulative log. Uses <code>gh pr view</code> for merge timestamps with <code>git log</code> fallback, hard-fails rather than fabricating timestamps.<br><br><strong>Decision log:</strong> <code>docs/decisions/decision_log.json</code> \u2014 append-only JSON with version field, backfilled with PR #6's 2 decisions. Each decision gets a compound ID (<code>PR{N}-{seq}</code>), global sequence number, zone mapping, verification status, and lifecycle status (<code>active</code>/<code>superseded</code>/<code>retracted</code>).<br><br><strong>SKILL.md:</strong> Added Step 13 (post-merge persistence) to factory orchestration workflow \u2014 persist decisions, create post-merge issues, commit, cleanup.<br><br><strong>factory_fix.md:</strong> Restructured constraints to separate read-only context (specs, decisions, agents) from truly prohibited files. Added decision log to Codex's context sources.<br><br><strong>CLAUDE.md:</strong> Added <code>docs/decisions/</code> and <code>scripts/persist_decisions.py</code> to factory-protected file list."
      },
      {
        "zoneId": "config",
        "title": "Config",
        "description": "<strong>Makefile:</strong> Added <code>persist-decisions</code> target (<code>make persist-decisions PR=N</code>) for convenient post-merge invocation."
      }
    ]
  },
  "adversarialReview": {
    "overallGrade": "A",
    "reviewMethod": "main-agent",
    "findings": [
      {
        "file": "scripts/persist_decisions.py",
        "grade": "A",
        "zones": "factory",
        "notable": "Clean deterministic script following established patterns",
        "detail": "Follows the exact same CLI pattern as <code>create_postmerge_issues.py</code>. No security concerns \u2014 reads local files, calls <code>gh</code> CLI, writes local JSON. Idempotent via ID set check. HTML extraction uses regex on a known structure (not arbitrary HTML parsing). Hard-fails on missing timestamps rather than fabricating data. No subprocess injection risk \u2014 all subprocess args are positional, not shell-interpolated.",
        "gradeSortOrder": 3
      },
      {
        "file": "docs/decisions/decision_log.json",
        "grade": "A",
        "zones": "factory",
        "notable": "Well-structured seed data from PR #6 backfill",
        "detail": "Contains 2 decisions from PR #6, both verified. Compound IDs (<code>PR6-1</code>, <code>PR6-2</code>), global sequence numbers, merge timestamps from actual GitHub data, correct PR URL and SHA. Schema matches the plan design.",
        "gradeSortOrder": 3
      },
      {
        "file": ".claude/skills/factory-orchestrate/SKILL.md",
        "grade": "A",
        "zones": "factory",
        "notable": "Clean Step 13 addition with no disruption to existing workflow",
        "detail": "Post-merge persistence step added between review pack generation (Step 12) and stall protocol. Clear sequencing: persist decisions \u2192 create issues \u2192 commit \u2192 cleanup. No changes to existing steps 1-12.",
        "gradeSortOrder": 3
      },
      {
        "file": ".github/codex/prompts/factory_fix.md",
        "grade": "A",
        "zones": "factory",
        "notable": "Fixed pre-existing read/prohibit contradiction for specs",
        "detail": "Restructured the constraints section into two clear categories: read-only context (specs, decisions, agents) and truly prohibited files (scenarios, factory scripts). This fixes a pre-existing contradiction where <code>/specs/</code> was listed under 'NEVER read' while the file simultaneously told Codex to read specs. The decision log addition was the trigger, but the fix is broader.",
        "gradeSortOrder": 3
      },
      {
        "file": "CLAUDE.md",
        "grade": "A",
        "zones": "factory",
        "notable": "Minimal additions to factory-protected file list",
        "detail": "Added 2 entries: <code>/docs/decisions/</code> (Codex reads but never modifies) and <code>/scripts/persist_decisions.py</code>. Consistent with existing list format. Also added <code>persist-decisions</code> to Quick Commands section.",
        "gradeSortOrder": 3
      },
      {
        "file": "Makefile",
        "grade": "A",
        "zones": "config",
        "notable": "Simple target addition following existing patterns",
        "detail": "Added <code>persist-decisions</code> target using the same <code>python scripts/...</code> pattern as other targets. Added to <code>.PHONY</code> list. Uses <code>$(PR)</code> variable consistent with how other parameterized targets would work.",
        "gradeSortOrder": 3
      }
    ]
  },
  "ciPerformance": [
    {
      "name": "factory-self-test",
      "trigger": "(push)",
      "status": "pass",
      "time": "17s",
      "timeSeconds": 17,
      "healthTag": "normal",
      "detail": {
        "coverage": "Factory script validation \u2014 lint, typecheck, and unit tests for factory infrastructure scripts",
        "gates": "Gate 1 (factory scripts)",
        "zones": [
          "factory"
        ],
        "specRefs": [],
        "checks": [
          {
            "label": "Lint factory scripts (ruff check)",
            "detail": "All factory scripts pass ruff linting",
            "zones": [
              "factory"
            ]
          },
          {
            "label": "Typecheck factory scripts (mypy)",
            "detail": "mypy passes on all factory script modules",
            "zones": [
              "factory"
            ]
          }
        ],
        "notes": null
      }
    },
    {
      "name": "factory-self-test",
      "trigger": "(PR)",
      "status": "pass",
      "time": "19s",
      "timeSeconds": 19,
      "healthTag": "normal",
      "detail": {
        "coverage": "Factory script validation on PR merge ref",
        "gates": "Gate 1 (factory scripts)",
        "zones": [
          "factory"
        ],
        "specRefs": [],
        "checks": [
          {
            "label": "Factory scripts lint + typecheck on PR ref",
            "detail": "Same checks as push trigger, run against the PR merge commit",
            "zones": [
              "factory"
            ]
          }
        ],
        "notes": null
      }
    },
    {
      "name": "validate",
      "trigger": "(push)",
      "status": "pass",
      "time": "5m 33s",
      "timeSeconds": 333,
      "healthTag": "watch",
      "detail": {
        "coverage": "Full product validation: lint, typecheck, pytest, docker builds, env smoke tests",
        "gates": "Gate 1 (deterministic)",
        "zones": [
          "environment",
          "rl-core",
          "agent",
          "training",
          "tests",
          "config",
          "docker"
        ],
        "specRefs": [
          "specs/env.md",
          "specs/rl.md",
          "specs/training.md"
        ],
        "checks": [
          {
            "label": "Lint (ruff check .)",
            "detail": "All Python files pass ruff linting",
            "zones": [
              "environment",
              "rl-core",
              "agent",
              "training"
            ]
          },
          {
            "label": "Typecheck (mypy src)",
            "detail": "mypy passes on all source modules",
            "zones": [
              "environment",
              "rl-core",
              "agent",
              "training"
            ]
          },
          {
            "label": "Tests (pytest -q)",
            "detail": "Full test suite passes",
            "zones": [
              "tests"
            ]
          },
          {
            "label": "Docker builds",
            "detail": "Both train and demo images build successfully",
            "zones": [
              "docker"
            ]
          },
          {
            "label": "Environment smoke test",
            "detail": "MiniPong env creates, resets, and returns correct observation shape",
            "zones": [
              "environment"
            ]
          }
        ],
        "notes": "5m33s is in 'watch' territory (300-600s). Docker builds dominate runtime."
      }
    },
    {
      "name": "validate",
      "trigger": "(PR)",
      "status": "pass",
      "time": "5m 38s",
      "timeSeconds": 338,
      "healthTag": "watch",
      "detail": {
        "coverage": "Same as validate (push), run against PR merge commit",
        "gates": "Gate 1 (deterministic)",
        "zones": [
          "environment",
          "rl-core",
          "agent",
          "training",
          "tests",
          "config",
          "docker"
        ],
        "specRefs": [],
        "checks": [
          {
            "label": "Full validation suite on PR merge ref",
            "detail": "Lint + typecheck + test + docker + env-smoke on the PR merge commit",
            "zones": [
              "environment",
              "rl-core",
              "agent",
              "training",
              "tests",
              "config",
              "docker"
            ]
          }
        ],
        "notes": null
      }
    }
  ],
  "decisions": [
    {
      "number": 1,
      "title": "Single append-only JSON file over individual ADR files",
      "rationale": "Decisions are small machine-generated records, not long-form human prose. A single file enables O(1) loading for both the scaffold script and Codex prompt assembly.",
      "body": "Considered three options: (1) single JSON log, (2) individual ADR-style markdown files, (3) GitHub issues. The single-file approach wins because: decisions are ~200 bytes each, so even 100 decisions is ~20KB. Individual files create filesystem noise (40+ files after 20 PRs, each under 1KB). GitHub issues live outside git, violating the trust hierarchy (git > external services). The append-only constraint ensures the log is a clean audit trail via <code>git log -- docs/decisions/decision_log.json</code>.",
      "zones": "factory",
      "files": [
        {
          "path": "docs/decisions/decision_log.json",
          "change": "Created initial log with version field and empty decisions array, then backfilled PR #6 decisions"
        },
        {
          "path": "scripts/persist_decisions.py",
          "change": "Script writes to this file with idempotent append logic"
        }
      ],
      "verified": true
    },
    {
      "number": 2,
      "title": "Codex reads the decision log (not stripped with holdout)",
      "rationale": "Decisions describe why choices were made \u2014 architectural context, not evaluation criteria. Stripping them forces Codex to re-derive context, risking contradictory decisions across cranks.",
      "body": "The holdout stripping mechanism (<code>strip_holdout.py</code>) exists to prevent Codex from seeing its evaluation criteria (scenarios). Decisions are categorically different \u2014 they're analogous to specs (which Codex reads). Hiding past architectural decisions means each crank starts from zero context on <em>why</em> the system is the way it is. This was a deliberate design choice discussed with the project lead during planning.",
      "zones": "factory",
      "files": [
        {
          "path": ".github/codex/prompts/factory_fix.md",
          "change": "Added decision log to Codex's context sources, restructured constraints to allow reading"
        }
      ],
      "verified": true
    },
    {
      "number": 3,
      "title": "Separate read-only context from prohibited files in Codex prompt",
      "rationale": "The existing factory_fix.md had a pre-existing contradiction: /specs/ was listed under 'NEVER read' while also instructing Codex to read specs.",
      "body": "Bot reviewer (codex-connector) flagged that adding <code>/docs/decisions/</code> to the 'NEVER read, modify, or delete' section while telling Codex to read it was contradictory. Investigation revealed the same bug already existed for <code>/specs/</code>. Fixed by splitting into two sections: 'NEVER modify or delete' (read-only context: specs, decisions, agents) and 'NEVER read, modify, or delete' (truly prohibited: scenarios, factory scripts).",
      "zones": "factory",
      "files": [
        {
          "path": ".github/codex/prompts/factory_fix.md",
          "change": "Restructured constraints section into read-only vs prohibited categories"
        }
      ],
      "verified": true
    }
  ],
  "convergence": {
    "gates": [
      {
        "name": "Gate 0 \u2014 Adversarial Review",
        "status": "passing",
        "statusText": "CLEAN",
        "summary": "6 files reviewed, all grade A. No critical or warning findings.",
        "detail": "All changes are factory infrastructure \u2014 new script follows established patterns, SKILL.md/CLAUDE.md/Makefile additions are mechanical. Bot reviewer found 2 legitimate issues (timestamp fallback, constraint contradiction) which were fixed in commit babed4d before review pack generation."
      },
      {
        "name": "Gate 1 \u2014 Deterministic",
        "status": "passing",
        "statusText": "ALL PASS",
        "summary": "4/4 CI checks pass: factory-self-test (push/PR) + validate (push/PR)",
        "detail": "<strong>factory-self-test:</strong> 17-19s, both pass<br><strong>validate:</strong> 5m33-38s, both pass<br>ruff clean, mypy clean, pytest passes. No product code changes so no behavioral risk."
      },
      {
        "name": "Gate 2 \u2014 NFR",
        "status": "passing",
        "statusText": "N/A",
        "summary": "NFR checks not run separately \u2014 no product code changes.",
        "detail": "This PR only modifies factory infrastructure files. Gate 2 NFR checks (code quality, complexity, dead code, security) target product code in <code>src/</code>. The new script (<code>scripts/persist_decisions.py</code>) passes ruff + mypy individually."
      },
      {
        "name": "Gate 3 \u2014 Scenarios",
        "status": "passing",
        "statusText": "N/A",
        "summary": "No holdout scenarios apply \u2014 factory internals PR.",
        "detail": "Holdout scenarios evaluate product behavior (environment, training, pipeline). This PR makes zero changes to product code, so no scenarios were run. CI's full test suite passing confirms no regressions."
      }
    ],
    "overall": {
      "status": "passing",
      "statusText": "READY",
      "summary": "Factory-internal PR. CI green, adversarial review clean, bot findings addressed.",
      "detail": "All applicable gates pass. This is a factory infrastructure change \u2014 the decision persistence mechanism \u2014 with no product code impact. Safe to merge."
    }
  },
  "postMergeItems": [
    {
      "priority": "low",
      "title": "Phase 2: Cross-PR decision context in future review packs",
      "description": "The decision log is now being populated, but future review packs don't yet consume it. Phase 2 would add a <code>decisionHistory</code> field to ReviewPackData so the Pass 2 agent can surface relevant prior decisions when generating a new review pack.",
      "codeSnippet": null,
      "failureScenario": "Without Phase 2, the decision log grows but review packs don't reference it. Joey has to manually check the log to understand decision lineage across PRs.",
      "successScenario": "Each review pack shows 'Related prior decisions' within decision cards, linking back to the PR that introduced them. Joey sees continuity without manual lookup.",
      "zones": [
        "factory"
      ]
    },
    {
      "priority": "low",
      "title": "Phase 3: Decision lifecycle management (retract/supersede)",
      "description": "The <code>status</code> field supports <code>active</code>/<code>superseded</code>/<code>retracted</code> but there's no CLI interface to change status. Currently requires manual JSON editing.",
      "codeSnippet": null,
      "failureScenario": "If Joey wants to retract a decision, he has to manually edit decision_log.json \u2014 error-prone and not self-documenting.",
      "successScenario": "<code>python scripts/persist_decisions.py --retract PR6-1 --reason 'Replaced by PR12 approach'</code> updates the log cleanly with audit trail.",
      "zones": [
        "factory"
      ]
    }
  ],
  "factoryHistory": null
};

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Theme switching (Light / Dark / System)
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
(function initTheme() {
  const stored = localStorage.getItem('pr-pack-theme') || 'system';
  applyTheme(stored);
  updateThemeButtons(stored);
})();

function setTheme(theme) {
  localStorage.setItem('pr-pack-theme', theme);
  applyTheme(theme);
  updateThemeButtons(theme);
}

function applyTheme(theme) {
  if (theme === 'system') {
    const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
    document.documentElement.setAttribute('data-theme', prefersDark ? 'dark' : 'light');
  } else {
    document.documentElement.setAttribute('data-theme', theme);
  }
}

function updateThemeButtons(theme) {
  document.querySelectorAll('.theme-toggle button').forEach(btn => {
    btn.classList.toggle('active', btn.getAttribute('data-theme-btn') === theme);
  });
}

window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', () => {
  const stored = localStorage.getItem('pr-pack-theme') || 'system';
  if (stored === 'system') applyTheme('system');
});

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Tab switching
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function switchTab(tab) {
  document.querySelectorAll('.tab-content').forEach(t => t.classList.remove('active'));
  document.querySelectorAll('.tab-btn').forEach(b => b.classList.remove('active'));
  document.getElementById('tab-' + tab).classList.add('active');
  event.target.classList.add('active');
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// CI job detail toggle
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function toggleCIDetail(row) {
  const detail = row.nextElementSibling;
  if (detail && detail.classList.contains('detail-row')) {
    detail.classList.toggle('open');
    row.classList.toggle('ci-open');
  }
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Decision card toggle + zone highlighting
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function toggleDecision(card) {
  const wasOpen = card.classList.contains('open');
  document.querySelectorAll('.decision-card').forEach(c => c.classList.remove('open'));
  if (!wasOpen) {
    card.classList.add('open');
    const zones = card.dataset.zones.split(' ');
    highlightZones(zones);
  } else {
    resetZones();
  }
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Adversarial review row toggle
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function toggleAdvDetail(row) {
  const detail = row.nextElementSibling;
  if (detail && detail.classList.contains('adv-detail-row')) {
    detail.classList.toggle('open');
  }
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Architecture zone highlighting (cross-section filtering)
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
let currentActiveZones = null;

function highlightZones(activeZones) {
  currentActiveZones = activeZones;

  // 1. Highlight zones in main and floating diagrams
  ['#arch-diagram', '#arch-floating'].forEach(sel => {
    document.querySelectorAll(sel + ' .zone-box').forEach(box => {
      const zone = box.dataset.zone;
      if (activeZones.includes(zone)) {
        box.classList.remove('dimmed');
        box.classList.add('highlighted');
      } else {
        box.classList.add('dimmed');
        box.classList.remove('highlighted');
      }
    });
  });

  const info = document.getElementById('zone-filter-info');
  info.textContent = 'Showing zones: ' + activeZones.join(', ');
  info.style.display = 'block';

  // 2. Filter adversarial review rows
  let anyMatch = false;
  document.querySelectorAll('.adv-row').forEach(row => {
    const rowZones = row.dataset.zones.split(' ');
    const match = rowZones.some(z => activeZones.includes(z));
    row.classList.toggle('collapsed-row', !match);
    if (match) anyMatch = true;
    const detailRow = row.nextElementSibling;
    if (detailRow && detailRow.classList.contains('adv-detail-row')) {
      if (!match) {
        detailRow.style.display = 'none';
        detailRow.classList.remove('open');
      } else {
        detailRow.style.display = '';
      }
    }
  });
  const noMatch = document.getElementById('adv-no-match');
  if (noMatch) noMatch.classList.toggle('visible', !anyMatch);

  // 3. Filter scenario cards
  document.querySelectorAll('.scenario-card[data-zone]').forEach(card => {
    const cardZones = card.dataset.zone.split(' ');
    const match = cardZones.some(z => activeZones.includes(z));
    card.classList.toggle('zone-dimmed', !match);
    card.classList.toggle('zone-glow', match);
  });

  // 4. Filter What Changed section
  const wcDefault = document.getElementById('wc-default');
  if (wcDefault) wcDefault.style.display = 'none';
  document.querySelectorAll('.wc-zone-detail').forEach(d => {
    d.classList.toggle('active', activeZones.includes(d.dataset.zone));
  });
  if (!document.querySelector('.wc-zone-detail.active') && wcDefault) {
    wcDefault.style.display = '';
  }
}

function resetZones() {
  currentActiveZones = null;
  document.querySelectorAll('.zone-box').forEach(box => box.classList.remove('dimmed', 'highlighted'));
  document.getElementById('zone-filter-info').style.display = 'none';
  document.querySelectorAll('.adv-row').forEach(row => row.classList.remove('collapsed-row'));
  document.querySelectorAll('.adv-detail-row').forEach(row => row.style.display = '');
  const noMatch = document.getElementById('adv-no-match');
  if (noMatch) noMatch.classList.remove('visible');
  document.querySelectorAll('.scenario-card[data-zone]').forEach(card => card.classList.remove('zone-dimmed', 'zone-glow'));
  const wcDefault = document.getElementById('wc-default');
  if (wcDefault) wcDefault.style.display = '';
  document.querySelectorAll('.wc-zone-detail').forEach(d => d.classList.remove('active'));
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Zone click handlers
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function attachZoneClickHandlers(container) {
  container.querySelectorAll('.zone-box').forEach(box => {
    box.addEventListener('click', (e) => {
      e.stopPropagation();
      const zone = box.dataset.zone;
      if (currentActiveZones && currentActiveZones.length === 1 && currentActiveZones[0] === zone) {
        resetZones();
      } else {
        highlightZones([zone]);
      }
    });
  });
}

// Attach to main diagram
const mainDiagram = document.getElementById('arch-diagram');
if (mainDiagram) {
  attachZoneClickHandlers(mainDiagram);
  mainDiagram.addEventListener('click', (e) => {
    if (e.target.tagName === 'svg' || (e.target.tagName === 'text' && e.target.classList.contains('arch-row-label'))) {
      resetZones();
      document.querySelectorAll('.decision-card').forEach(c => c.classList.remove('open'));
    }
  });
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Architecture view toggle
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function setArchView(view, btn) {
  document.querySelectorAll('.arch-toggle').forEach(b => b.classList.remove('active'));
  btn.classList.add('active');
  if (view === 'baseline') {
    document.querySelectorAll('.zone-box').forEach(box => { box.style.opacity = '0.25'; });
    document.getElementById('zone-filter-info').textContent = 'Baseline view: before merge';
    document.getElementById('zone-filter-info').style.display = 'block';
  } else {
    document.querySelectorAll('.zone-box').forEach(box => {
      box.style.opacity = '1';
      box.classList.remove('dimmed', 'highlighted');
    });
    document.getElementById('zone-filter-info').style.display = 'none';
  }
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Sticky floating architecture diagram
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
let floatingDismissed = false;

(function initFloatingDiagram() {
  const archSection = document.getElementById('arch-diagram');
  const floatingContainer = document.getElementById('arch-floating');
  const floatingContent = document.getElementById('arch-floating-content');
  if (!archSection || !floatingContainer) return;

  const svgClone = archSection.cloneNode(true);
  svgClone.removeAttribute('id');
  svgClone.style.width = '100%';
  svgClone.style.maxWidth = 'none';
  floatingContent.appendChild(svgClone);

  attachZoneClickHandlers(floatingContainer);
  svgClone.addEventListener('click', (e) => {
    if (e.target.tagName === 'svg' || (e.target.tagName === 'text' && e.target.classList.contains('arch-row-label'))) {
      resetZones();
    }
  });

  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (floatingDismissed) return;
      floatingContainer.classList.toggle('visible', !entry.isIntersecting);
    });
  }, { threshold: 0.1 });
  observer.observe(archSection);
})();

function dismissFloatingDiagram() {
  floatingDismissed = true;
  document.getElementById('arch-floating').classList.remove('visible');
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Diff data cache
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
let diffDataCache = null;
let diffDataLoading = false;
let diffDataCallbacks = [];

function loadDiffData(cb) {
  if (diffDataCache) { cb(diffDataCache); return; }
  diffDataCallbacks.push(cb);
  if (diffDataLoading) return;
  diffDataLoading = true;
  Promise.resolve(new Response(JSON.stringify(DIFF_DATA_INLINE)))
    .then(r => { if (!r.ok) throw new Error(r.status); return r.json(); })
    .then(data => {
      diffDataCache = data;
      diffDataCallbacks.forEach(fn => fn(data));
      diffDataCallbacks = [];
    })
    .catch(err => {
      diffDataCallbacks.forEach(fn => fn(null, err));
      diffDataCallbacks = [];
    })
    .finally(() => { diffDataLoading = false; });
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// File diff modal
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
let currentFilePath = null;
let currentFileData = null;
let currentView = 'side-by-side';

function openFileModal(path) {
  currentFilePath = path;
  const overlay = document.getElementById('file-modal-overlay');
  const pathEl = document.getElementById('file-modal-path');
  const statsEl = document.getElementById('file-modal-stats');
  const link = document.getElementById('file-modal-github-link');
  const body = document.getElementById('file-modal-body');

  pathEl.textContent = path;
  // Build GitHub URL from DATA if available
  const prUrl = (DATA.header && DATA.header.prUrl) || '';
  const headBranch = (DATA.header && DATA.header.headBranch) || 'main';
  const repoUrl = prUrl.replace(/\/pull\/\d+$/, '');
  link.href = repoUrl + '/blob/' + headBranch + '/' + path;

  document.querySelectorAll('.file-modal-tab').forEach(t => t.classList.remove('active'));
  const activeTab = document.querySelector('.file-modal-tab[data-view="' + currentView + '"]');
  if (activeTab) activeTab.classList.add('active');

  statsEl.innerHTML = '';
  body.innerHTML = '<div class="diff-loading">Loading diff data&hellip;</div>';
  overlay.classList.add('visible');
  document.body.style.overflow = 'hidden';

  loadDiffData((data, err) => {
    if (err || !data) {
      body.innerHTML = '<div class="diff-error">Failed to load diff data.</div>';
      return;
    }
    currentFileData = data.files[path] || null;
    if (!currentFileData) {
      // Check for embedded reference file content (spec files, etc.)
      var refContent = (typeof REFERENCE_FILES !== 'undefined') && REFERENCE_FILES[path];
      if (refContent) {
        currentFileData = { raw: refContent, diff: '', additions: 0, deletions: 0 };
        statsEl.innerHTML = '<span style="color:var(--text-secondary);font-size:12px">' +
          'Reference file &mdash; not modified in this PR</span>';
        // Default to raw view for reference files
        currentView = 'raw';
        document.querySelectorAll('.file-modal-tab').forEach(function(t) { t.classList.remove('active'); });
        var rawTab = document.querySelector('.file-modal-tab[data-view="raw"]');
        if (rawTab) rawTab.classList.add('active');
        renderDiffView('raw');
        return;
      }
      var ghLink = link.href;
      body.innerHTML = '<div style="text-align:center;padding:40px 20px">' +
        '<div style="font-size:14px;color:var(--text-secondary);margin-bottom:16px">' +
        'This file was not modified in this PR.</div>' +
        '<a href="' + escapeHtml(ghLink) + '" target="_blank" ' +
        'style="display:inline-block;padding:10px 24px;background:var(--blue);color:white;' +
        'border-radius:8px;text-decoration:none;font-weight:600;font-size:14px">' +
        'View on GitHub &rarr;</a></div>';
      return;
    }
    statsEl.innerHTML = '<span class="fm-add">+' + currentFileData.additions + '</span> <span class="fm-del">-' + currentFileData.deletions + '</span>';
    renderDiffView(currentView);
  });
}

function closeFileModal() {
  document.getElementById('file-modal-overlay').classList.remove('visible');
  document.body.style.overflow = '';
  currentFilePath = null;
  currentFileData = null;
}

function setFileModalTab(btn, view) {
  document.querySelectorAll('.file-modal-tab').forEach(t => t.classList.remove('active'));
  btn.classList.add('active');
  currentView = view;
  if (currentFileData) renderDiffView(view);
}

function escapeHtml(s) {
  const div = document.createElement('div');
  div.textContent = s;
  return div.innerHTML;
}

function renderDiffView(view) {
  const body = document.getElementById('file-modal-body');
  if (!currentFileData) return;
  if (view === 'raw') renderRawView(body);
  else if (view === 'integrated') renderUnifiedView(body);
  else renderSplitView(body);
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Syntax highlighting (lightweight, no deps)
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function detectLanguage(filePath) {
  if (!filePath) return 'text';
  const ext = filePath.split('.').pop().toLowerCase();
  const map = {
    'py': 'python', 'yaml': 'yaml', 'yml': 'yaml', 'md': 'markdown',
    'sh': 'shell', 'bash': 'shell', 'js': 'javascript', 'ts': 'javascript',
    'jsx': 'javascript', 'tsx': 'javascript',
  };
  return map[ext] || 'text';
}

function highlightCode(text, language) {
  if (language === 'text') return text;

  if (language === 'python') {
    text = text.replace(/(&#39;&#39;&#39;[\s\S]*?&#39;&#39;&#39;|&quot;&quot;&quot;[\s\S]*?&quot;&quot;&quot;)/g, '<span style="color:#ce9178">$1</span>');
    text = text.replace(/((?<!\\)&#39;(?:[^\\]|\\.)*?&#39;|(?<!\\)&quot;(?:[^\\]|\\.)*?&quot;)/g, function(m) {
      if (m.indexOf('style=') !== -1) return m;
      return '<span style="color:#ce9178">' + m + '</span>';
    });
    text = text.replace(/(#[^\n]*)/g, function(m) {
      if (m.indexOf('style=') !== -1) return m;
      return '<span style="color:#6a9955">' + m + '</span>';
    });
    text = text.replace(/(@\w+)/g, '<span style="color:#dcdcaa">$1</span>');
    text = text.replace(/\b(True|False|None)\b/g, '<span style="color:#569cd6">$1</span>');
    text = text.replace(/\b(def|class|import|from|if|else|elif|for|while|return|yield|with|as|try|except|finally|raise|not|and|or|in|is|pass|break|continue|lambda|global|nonlocal|async|await|self)\b/g, function(m) {
      return '<span style="color:#c586c0">' + m + '</span>';
    });
    text = text.replace(/\b(\d+\.?\d*(?:e[+-]?\d+)?)\b/g, '<span style="color:#b5cea8">$1</span>');
    return text;
  }

  if (language === 'yaml') {
    text = text.replace(/(#[^\n]*)/g, '<span style="color:#6a9955">$1</span>');
    text = text.replace(/\b(true|false|yes|no|on|off)\b/gi, '<span style="color:#569cd6">$1</span>');
    text = text.replace(/^(\s*)([\w][\w.-]*?)(:)/gm, '$1<span style="color:#9cdcfe">$2</span>$3');
    text = text.replace(/(&#39;[^]*?&#39;|&quot;[^]*?&quot;)/g, function(m) {
      if (m.indexOf('style=') !== -1) return m;
      return '<span style="color:#ce9178">' + m + '</span>';
    });
    return text;
  }

  if (language === 'markdown') {
    text = text.replace(/^(#{1,6}\s.*)$/gm, '<span style="color:#569cd6">$1</span>');
    text = text.replace(/(\*\*[^*]+\*\*)/g, '<span style="color:#dcdcaa;font-weight:bold">$1</span>');
    text = text.replace(/(`[^`]+`)/g, '<span style="color:#ce9178">$1</span>');
    return text;
  }

  if (language === 'shell') {
    text = text.replace(/(#[^\n]*)/g, '<span style="color:#6a9955">$1</span>');
    text = text.replace(/(&#39;[^]*?&#39;|&quot;[^]*?&quot;)/g, function(m) {
      if (m.indexOf('style=') !== -1) return m;
      return '<span style="color:#ce9178">' + m + '</span>';
    });
    text = text.replace(/(\$\{?\w+\}?)/g, '<span style="color:#9cdcfe">$1</span>');
    text = text.replace(/\b(if|then|else|elif|fi|for|do|done|while|case|esac|echo|export|set|source|local|readonly|declare|unset|shift|eval|exec|trap|exit|return|function)\b/g, '<span style="color:#c586c0">$1</span>');
    return text;
  }

  if (language === 'javascript') {
    text = text.replace(/(&#39;[^]*?&#39;|&quot;[^]*?&quot;|`[^]*?`)/g, function(m) {
      if (m.indexOf('style=') !== -1) return m;
      return '<span style="color:#ce9178">' + m + '</span>';
    });
    text = text.replace(/(\/\/[^\n]*)/g, function(m) {
      if (m.indexOf('style=') !== -1) return m;
      return '<span style="color:#6a9955">' + m + '</span>';
    });
    text = text.replace(/\b(true|false|null|undefined|NaN|Infinity)\b/g, '<span style="color:#569cd6">$1</span>');
    text = text.replace(/\b(const|let|var|function|class|if|else|for|while|do|switch|case|break|continue|return|import|export|from|default|new|this|typeof|instanceof|in|of|try|catch|finally|throw|async|await|yield)\b/g, '<span style="color:#c586c0">$1</span>');
    return text;
  }

  return text;
}

// ‚îÄ‚îÄ Raw file view ‚îÄ‚îÄ
function renderRawView(container) {
  const raw = currentFileData.raw || '';
  if (!raw) {
    container.innerHTML = '<div class="diff-error">File was deleted or is binary.</div>';
    return;
  }
  const lang = detectLanguage(currentFilePath);
  const lines = raw.split('\n');
  let html = '<div class="diff-view diff-raw"><table>';
  for (let i = 0; i < lines.length; i++) {
    const escaped = escapeHtml(lines[i]);
    const highlighted = highlightCode(escaped, lang);
    html += '<tr><td class="diff-ln">' + (i + 1) + '</td><td>' + highlighted + '</td></tr>';
  }
  html += '</table></div>';
  container.innerHTML = html;
}

// ‚îÄ‚îÄ Unified (integrated) diff view ‚îÄ‚îÄ
function renderUnifiedView(container) {
  const diff = currentFileData.diff || '';
  if (!diff) { container.innerHTML = '<div class="diff-error">No diff available.</div>'; return; }
  const lines = diff.split('\n');
  let html = '<div class="diff-view"><table class="diff-unified">';
  let oldLn = 0, newLn = 0;

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    if (line.startsWith('diff --git') || line.startsWith('index ') || line.startsWith('---') || line.startsWith('+++')) continue;
    if (isDiffMetaLine(line)) continue;
    if (line.startsWith('@@')) {
      const m = line.match(/@@ -(\d+)(?:,\d+)? \+(\d+)(?:,\d+)? @@(.*)/);
      if (m) { oldLn = parseInt(m[1]); newLn = parseInt(m[2]); html += '<tr><td class="diff-ln" colspan="2"></td><td class="diff-hunk">' + escapeHtml(line) + '</td></tr>'; }
      continue;
    }
    if (line.startsWith('+')) { html += '<tr class="diff-add"><td class="diff-ln"></td><td class="diff-ln">' + newLn + '</td><td>' + escapeHtml(line.slice(1)) + '</td></tr>'; newLn++; continue; }
    if (line.startsWith('-')) { html += '<tr class="diff-del"><td class="diff-ln">' + oldLn + '</td><td class="diff-ln"></td><td>' + escapeHtml(line.slice(1)) + '</td></tr>'; oldLn++; continue; }
    if (line.startsWith(' ') || line === '') { html += '<tr class="diff-ctx"><td class="diff-ln">' + oldLn + '</td><td class="diff-ln">' + newLn + '</td><td>' + escapeHtml(line.slice(1)) + '</td></tr>'; oldLn++; newLn++; }
  }
  html += '</table></div>';
  container.innerHTML = html;
}

const DIFF_SKIP_PATTERNS = [/^new file mode/, /^deleted file mode/, /^old mode/, /^new mode/, /^similarity index/, /^rename from/, /^rename to/, /^Binary files/];
function isDiffMetaLine(line) { return DIFF_SKIP_PATTERNS.some(p => p.test(line)); }

// ‚îÄ‚îÄ Side-by-side diff view ‚îÄ‚îÄ
function renderSplitView(container) {
  const diff = currentFileData.diff || '';
  if (!diff) { container.innerHTML = '<div class="diff-error">No diff available.</div>'; return; }

  const isNewFile = currentFileData.status === 'added' || (currentFileData.deletions === 0 && currentFileData.additions > 0);
  const isDeletedFile = currentFileData.status === 'deleted' || (currentFileData.additions === 0 && currentFileData.deletions > 0);

  if (isNewFile || isDeletedFile) {
    const bannerClass = isNewFile ? 'diff-new-file-banner' : 'diff-deleted-file-banner';
    const bannerText = isNewFile ? 'New file &mdash; showing additions' : 'Deleted file &mdash; showing deletions';
    const lines = diff.split('\n');
    let html = '<div class="' + bannerClass + '">' + bannerText + '</div><div class="diff-view diff-split-wrapper"><table class="diff-unified">';
    let ln = 0;
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i];
      if (line.startsWith('diff --git') || line.startsWith('index ') || line.startsWith('---') || line.startsWith('+++')) continue;
      if (isDiffMetaLine(line)) continue;
      if (line.startsWith('@@')) { const m = line.match(/@@ -(\d+)(?:,\d+)? \+(\d+)(?:,\d+)? @@(.*)/); if (m) { ln = isNewFile ? parseInt(m[2]) : parseInt(m[1]); html += '<tr><td class="diff-ln"></td><td class="diff-hunk">' + escapeHtml(line) + '</td></tr>'; } continue; }
      if (isNewFile && line.startsWith('+')) { html += '<tr class="diff-add"><td class="diff-ln">' + ln + '</td><td>' + escapeHtml(line.slice(1)) + '</td></tr>'; ln++; }
      else if (isDeletedFile && line.startsWith('-')) { html += '<tr class="diff-del"><td class="diff-ln">' + ln + '</td><td>' + escapeHtml(line.slice(1)) + '</td></tr>'; ln++; }
      else if (line.startsWith(' ') || line === '') { html += '<tr class="diff-ctx"><td class="diff-ln">' + ln + '</td><td>' + escapeHtml(line.slice(1)) + '</td></tr>'; ln++; }
    }
    html += '</table></div>';
    container.innerHTML = html;
    return;
  }

  // Parse unified diff into side-by-side pairs
  const lines = diff.split('\n');
  const pairs = [];
  let oldLn = 0, newLn = 0;
  const addBuffer = [], delBuffer = [];

  function flushBuffers() {
    const max = Math.max(addBuffer.length, delBuffer.length);
    for (let j = 0; j < max; j++) {
      const hasOld = j < delBuffer.length, hasNew = j < addBuffer.length;
      pairs.push({ type: hasOld && hasNew ? 'change' : hasNew ? 'add' : 'del', oldLn: hasOld ? delBuffer[j].ln : null, newLn: hasNew ? addBuffer[j].ln : null, oldText: hasOld ? delBuffer[j].text : '', newText: hasNew ? addBuffer[j].text : '' });
    }
    addBuffer.length = 0; delBuffer.length = 0;
  }

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    if (line.startsWith('diff --git') || line.startsWith('index ') || line.startsWith('---') || line.startsWith('+++')) continue;
    if (isDiffMetaLine(line)) continue;
    if (line.startsWith('@@')) { flushBuffers(); const m = line.match(/@@ -(\d+)(?:,\d+)? \+(\d+)(?:,\d+)? @@(.*)/); if (m) { oldLn = parseInt(m[1]); newLn = parseInt(m[2]); pairs.push({ type: 'hunk', hunkText: line }); } continue; }
    if (line.startsWith('+')) { addBuffer.push({ ln: newLn, text: line.slice(1) }); newLn++; }
    else if (line.startsWith('-')) { delBuffer.push({ ln: oldLn, text: line.slice(1) }); oldLn++; }
    else { flushBuffers(); pairs.push({ type: 'ctx', oldLn: oldLn, newLn: newLn, oldText: line.slice(1), newText: line.slice(1) }); oldLn++; newLn++; }
  }
  flushBuffers();

  let html = '<div class="diff-view diff-split-wrapper"><table class="diff-split">';
  for (const p of pairs) {
    if (p.type === 'hunk') { html += '<tr class="diff-hunk"><td colspan="5" style="padding:4px 8px;background:rgba(56,139,253,0.08);color:#58a6ff;font-style:italic;font-size:11px">' + escapeHtml(p.hunkText) + '</td></tr>'; continue; }
    const leftCls = p.type === 'del' || p.type === 'change' ? ' diff-del' : p.type === 'add' ? ' diff-empty' : ' diff-ctx';
    const rightCls = p.type === 'add' || p.type === 'change' ? ' diff-add' : p.type === 'del' ? ' diff-empty' : ' diff-ctx';
    html += '<tr><td class="diff-ln' + leftCls + '">' + (p.oldLn != null ? p.oldLn : '') + '</td><td class="diff-code-left' + leftCls + '">' + (p.type === 'add' ? '' : escapeHtml(p.oldText)) + '</td><td class="diff-sep"></td><td class="diff-ln' + rightCls + '">' + (p.newLn != null ? p.newLn : '') + '</td><td class="diff-code-right' + rightCls + '">' + (p.type === 'del' ? '' : escapeHtml(p.newText)) + '</td></tr>';
  }
  html += '</table></div>';
  container.innerHTML = html;
}

// Close modal on Escape
document.addEventListener('keydown', (e) => {
  if (e.key === 'Escape') { closeFileModal(); hideGatePopover(); }
});

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Gate findings popover
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function showGatePopover(event, text) {
  event.stopPropagation();
  const popover = document.getElementById('gate-popover');
  popover.textContent = '';
  const lines = text.split('\\n');
  lines.forEach((line, i) => {
    popover.appendChild(document.createTextNode(line));
    if (i < lines.length - 1) popover.appendChild(document.createElement('br'));
  });
  const rect = event.target.getBoundingClientRect();
  popover.style.left = rect.left + 'px';
  popover.style.top = (rect.bottom + 6) + 'px';
  popover.classList.add('visible');
  setTimeout(() => { hideGatePopover(); }, 5000);
}

function hideGatePopover() {
  document.getElementById('gate-popover').classList.remove('visible');
}

document.addEventListener('click', (e) => {
  if (!e.target.classList.contains('gate-clickable')) hideGatePopover();
});
</script>
</body>
</html>
